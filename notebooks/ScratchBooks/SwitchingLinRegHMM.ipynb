{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We can model our control/switching problem as a switching linear regression (w/HMM) model\n",
    "\n",
    "In this problem, we want to model the output dynamics:\n",
    "$x_t = Ax_{t-1} + Bu_{t-1} + N(0,sigma)$\n",
    "\n",
    "We assume that the joystick/state dynamics are fixed.\n",
    "\n",
    "That is, $A$ is time invariant\n",
    "\n",
    "Therefore, we can use a switching linear regression by noting the residuals can be written as:\n",
    "$x_t - Ax_{t-1} = Bu_{t-1} + N(0,sigma)$\n",
    "\n",
    "This means, are output variables of the switching regression:\n",
    "$y_t | x_t, z_t ~ N(H(z_t)x_t+F(z_t),Sigma)$\n",
    "Where $H(z_t)$ are regression weights that change according to the state\n",
    "\n",
    "can actually be written as:\n",
    "$y_t = x_t - Ax_{t-1}$\n",
    "\n",
    "In terms of kinematics, these difference terms equate to either velocity or velocity and acceleration in N-cartesian coordinates\n",
    "\n",
    "*What matters is choosing the correct $x_{t-1}$ combinations.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HMM Steps:\n",
    "Initiate\n",
    "Fit\n",
    "Filter\n",
    "Smooth\n",
    "Decode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Import libraries for HMM\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "from itertools import count\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\")\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy\n",
    "from dynamax.hidden_markov_model import LinearRegressionHMM\n",
    "from dynamax.utils.plotting import CMAP, COLORS, white_to_color_cmap\n",
    "#Import data handling of monkey pac-man\n",
    "import PacTimeOrig.DataHandling as DH\n",
    "import PacTimeOrig.Methods.utils as pacutils\n",
    "\n",
    "#Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Helper functions for plotting\n",
    "def plot_gaussian_hmm(hmm, params, emissions, states,  title=\"Emission Distributions\", alpha=0.25):\n",
    "    lim = 1.1 * abs(emissions).max()\n",
    "    XX, YY = jnp.meshgrid(jnp.linspace(-lim, lim, 100), jnp.linspace(-lim, lim, 100))\n",
    "    grid = jnp.column_stack((XX.ravel(), YY.ravel()))\n",
    "\n",
    "    plt.figure()\n",
    "    for k in range(hmm.num_states):\n",
    "        lls = hmm.emission_distribution(params, k).log_prob(grid)\n",
    "        plt.contour(XX, YY, jnp.exp(lls).reshape(XX.shape), cmap=white_to_color_cmap(COLORS[k]))\n",
    "        plt.plot(emissions[states == k, 0], emissions[states == k, 1], \"o\", mfc=COLORS[k], mec=\"none\", ms=3, alpha=alpha)\n",
    "\n",
    "    plt.plot(emissions[:, 0], emissions[:, 1], \"-k\", lw=1, alpha=alpha)\n",
    "    plt.xlabel(\"$y_1$\")\n",
    "    plt.ylabel(\"$y_2$\")\n",
    "    plt.title(title)\n",
    "    plt.gca().set_aspect(1.0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def plot_gaussian_hmm_data(hmm, params, emissions, states, xlim=None):\n",
    "    num_timesteps = len(emissions)\n",
    "    emission_dim = hmm.emission_dim\n",
    "    means = params.emissions.means[states]\n",
    "    lim = 1.05 * abs(emissions).max()\n",
    "\n",
    "    # Plot the data superimposed on the generating state sequence\n",
    "    fig, axs = plt.subplots(emission_dim, 1, sharex=True)\n",
    "\n",
    "    for d in range(emission_dim):\n",
    "        axs[d].imshow(states[None, :], aspect=\"auto\", interpolation=\"none\", cmap=CMAP,\n",
    "                      vmin=0, vmax=len(COLORS) - 1, extent=(0, num_timesteps, -lim, lim))\n",
    "        axs[d].plot(emissions[:, d], \"-k\")\n",
    "        axs[d].plot(means[:, d], \":k\")\n",
    "        axs[d].set_ylabel(\"$y_{{t,{} }}$\".format(d+1))\n",
    "\n",
    "    if xlim is None:\n",
    "        plt.xlim(0, num_timesteps)\n",
    "    else:\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "    axs[-1].set_xlabel(\"time\")\n",
    "    axs[0].set_title(\"Simulated data from an HMM\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def dat_simulator(most_likely_states,vel,inputs,params):\n",
    "    '''Compute the predicted data under the model'''\n",
    "    emit=params.emissions\n",
    "    tmp=[]\n",
    "    for i in range(len(vel)):\n",
    "        tmp.append(np.dot(emit.weights[most_likely_states[i],:,:],inputs[i,:])+emit.biases[most_likely_states[i],:])\n",
    "\n",
    "    tmp=np.stack(tmp)\n",
    "    return tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      " 12%|█▎        | 1/8 [00:00<00:05,  1.26it/s]\u001B[A\n",
      " 25%|██▌       | 2/8 [00:01<00:04,  1.32it/s]\u001B[A\n",
      " 38%|███▊      | 3/8 [00:02<00:03,  1.28it/s]\u001B[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.25it/s]\u001B[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.12it/s]\u001B[A\n",
      " 75%|███████▌  | 6/8 [00:05<00:01,  1.01it/s]\u001B[A\n",
      " 88%|████████▊ | 7/8 [00:06<00:01,  1.04s/it]\u001B[A\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.04it/s]\u001B[A\n",
      " 20%|██        | 1/5 [00:07<00:30,  7.68s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      " 12%|█▎        | 1/8 [00:00<00:05,  1.35it/s]\u001B[A\n",
      " 25%|██▌       | 2/8 [00:01<00:04,  1.35it/s]\u001B[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.20it/s]\u001B[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.20it/s]\u001B[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.22it/s]\u001B[A\n",
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.22it/s]\u001B[A\n",
      " 88%|████████▊ | 7/8 [00:05<00:00,  1.21it/s]\u001B[A\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\u001B[A\n",
      " 40%|████      | 2/5 [00:14<00:21,  7.01s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      " 12%|█▎        | 1/8 [00:00<00:05,  1.25it/s]\u001B[A\n",
      " 25%|██▌       | 2/8 [00:01<00:04,  1.29it/s]\u001B[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.23it/s]\u001B[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.20it/s]\u001B[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.19it/s]\u001B[A\n",
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.18it/s]\u001B[A\n",
      " 88%|████████▊ | 7/8 [00:05<00:00,  1.18it/s]\u001B[A\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\u001B[A\n",
      " 60%|██████    | 3/5 [00:20<00:13,  6.83s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      " 12%|█▎        | 1/8 [00:00<00:05,  1.26it/s]\u001B[A\n",
      " 25%|██▌       | 2/8 [00:01<00:05,  1.12it/s]\u001B[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.13it/s]\u001B[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.13it/s]\u001B[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.14it/s]\u001B[A\n",
      " 75%|███████▌  | 6/8 [00:05<00:01,  1.14it/s]\u001B[A\n",
      " 88%|████████▊ | 7/8 [00:06<00:00,  1.15it/s]\u001B[A\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.16it/s]\u001B[A\n",
      " 80%|████████  | 4/5 [00:27<00:06,  6.86s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      " 12%|█▎        | 1/8 [00:00<00:05,  1.28it/s]\u001B[A\n",
      " 25%|██▌       | 2/8 [00:01<00:04,  1.30it/s]\u001B[A\n",
      " 38%|███▊      | 3/8 [00:02<00:03,  1.26it/s]\u001B[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.22it/s]\u001B[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.20it/s]\u001B[A\n",
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.18it/s]\u001B[A\n",
      " 88%|████████▊ | 7/8 [00:05<00:00,  1.19it/s]\u001B[A\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\u001B[A\n",
      "100%|██████████| 5/5 [00:34<00:00,  6.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# May need to try rescaling everything....\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# LOAD DATA STRUCTURE\n",
    "\n",
    "dat = loadmat('/Users/user/PycharmProjects/PacManMain/data/Simulation/datout.mat')\n",
    "accel=0\n",
    "r2=np.zeros([5,8])\n",
    "mcorr=np.zeros([5,8])\n",
    "LLdat=np.zeros([5,8])\n",
    "deltaW=np.zeros([5,8])\n",
    "for switype in tqdm(range(5)):\n",
    "    for trial in tqdm(range(8)):\n",
    "        x=dat['datout'][0][0]['x'][trial][switype]\n",
    "        A=dat['datout'][0][0]['A'][trial][switype]\n",
    "        B=dat['datout'][0][0]['B'][trial][switype]\n",
    "        shift=dat['datout'][0][0]['shiftfunc'][trial][switype]\n",
    "\n",
    "        erA = A - x\n",
    "        erB = B - x\n",
    "        vel = np.array([np.gradient(x[:, 0], 1), np.gradient(x[:, 1], 1)]).transpose()\n",
    "\n",
    "        if accel ==1:\n",
    "            vel = np.array([np.gradient(vel[:, 0], 1), np.gradient(vel[:, 1], 1)]).transpose()\n",
    "\n",
    "        erA = jnp.array(erA)\n",
    "        erB = jnp.array(erB)\n",
    "\n",
    "        vel = jnp.array(vel)\n",
    "        inputs = np.hstack([erA, erB])\n",
    "        keys=jr.PRNGKey(np.random.randint(1,100+1))\n",
    "        #keys = map(jr.PRNGKey, count())\n",
    "        hmm = LinearRegressionHMM(2, 4, 2)\n",
    "        #test_params, param_props = hmm.initialize(next(keys))\n",
    "        test_params, param_props = hmm.initialize(keys)\n",
    "\n",
    "        test_params, lps = hmm.fit_em(test_params, param_props, vel, inputs=inputs,num_iters=300,verbose=False)\n",
    "\n",
    "        most_likely_states = hmm.most_likely_states(test_params, vel, inputs=inputs)\n",
    "\n",
    "        stateposterior = hmm.filter(test_params, vel, inputs=inputs)\n",
    "        smoothposterior = hmm.smoother(test_params,vel,inputs=inputs)\n",
    "\n",
    "        #Simulate data\n",
    "        simvel=dat_simulator(most_likely_states,vel,inputs,test_params)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        ax1.plot(shift[1,:].transpose())\n",
    "        ax1.plot(smoothposterior.smoothed_probs, linestyle='dashed')\n",
    "        plt.title('type:'+str(switype)+'_'+'trial:'+str(trial))\n",
    "        ax2.plot(vel)\n",
    "        ax2.plot(simvel,linestyle='dashed')\n",
    "        fig.tight_layout()\n",
    "        fig.savefig('/Users/user/PycharmProjects/PacManMain/data/HMMOUTPUT/'+'type:'+str(switype)+'_'+'trial:'+str(trial)+'.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "        reshaped_X = vel.transpose().reshape(-1, 1)\n",
    "        reshaped_Y = simvel.transpose().reshape(-1, 1)\n",
    "        if np.sum(np.isnan(reshaped_Y))>0:\n",
    "            r2[switype,trial]=np.nan\n",
    "        else:\n",
    "            r2[switype,trial] = r2_score(reshaped_Y, reshaped_X)\n",
    "\n",
    "\n",
    "        #Find best matching posterior state to switch and correlate and square\n",
    "        s1corr=np.corrcoef(smoothposterior.smoothed_probs[:,0],shift[1,:].transpose())[0,1]\n",
    "        s2corr=np.corrcoef(smoothposterior.smoothed_probs[:,1],shift[1,:].transpose())[0,1]\n",
    "        if np.sum(np.isnan(reshaped_Y))>0:\n",
    "            mcorr[switype,trial]=np.nan\n",
    "        else:\n",
    "            mcorr[switype,trial]=np.max([s1corr,s2corr])\n",
    "\n",
    "        if np.max([s1corr,s2corr])==s1corr:\n",
    "            probout=smoothposterior.smoothed_probs[:,0]\n",
    "\n",
    "            deltaW[switype,trial]=np.mean(np.power((smoothposterior.smoothed_probs[:,0]-shift[1,:].transpose()),2))\n",
    "        else:\n",
    "            probout=smoothposterior.smoothed_probs[:,1]\n",
    "            deltaW[switype,trial]=np.mean(np.power((smoothposterior.smoothed_probs[:,1]-shift[1,:].transpose()),2))\n",
    "\n",
    "        LLdat[switype,trial]=-lps[-1]\n",
    "        mdic = {'probout':[probout]}\n",
    "        DataFold='/Users/user/PycharmProjects/PacManMain/data/HMMOUTPUT/'\n",
    "        savemat(DataFold+'/HMMprob'+str(switype)+'_'+str(trial)+'.mat',mdic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "mdic = {'S1corr':[s1corr],'S2corr':[s2corr],'mcorr': [mcorr],'Rsquared': [r2],'LLdat' :[LLdat], 'deltaW':[deltaW]}\n",
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/HMMOUTPUT/'\n",
    "savemat(DataFold+'/HMMOUTPUT.mat',mdic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan], dtype=float32)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
