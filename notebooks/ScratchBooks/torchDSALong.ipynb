{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "color_names = [\"windows blue\", \"red\", \"amber\", \"faded green\"]\n",
    "colors = sns.xkcd_palette(color_names)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "\n",
    "def frobenius_norm(tensor):\n",
    "    return torch.norm(tensor, 'fro')\n",
    "\n",
    "\n",
    "def loss_function(X, Y, C):\n",
    "    return frobenius_norm(X - C @ Y @ C.inverse())\n",
    "\n",
    "\n",
    "def cayley_transform(A):\n",
    "    I = torch.eye(A.size(0), dtype=A.dtype, device=A.device)\n",
    "    return torch.linalg.solve(I + A, I - A)\n",
    "\n",
    "def cayley_numpy(A):\n",
    "    I =np.eye((Aa-Aa.T).shape[0])\n",
    "    return np.linalg.solve(I+A,I-A)\n",
    "\n",
    "learning_rate = 0.01\n",
    "max_iterations = 1500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now do DSA with A~ high components models with ncomps=116 (80% variance in PODs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run DSA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/envs/main/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.9423234462738037\n",
      "Iteration 100, Loss: 1.3587335348129272\n",
      "Iteration 200, Loss: 1.148522973060608\n",
      "Iteration 300, Loss: 1.0370972156524658\n",
      "Iteration 400, Loss: 0.9621788263320923\n",
      "Iteration 500, Loss: 0.9103868007659912\n",
      "Iteration 600, Loss: 0.8693132400512695\n",
      "Iteration 700, Loss: 0.8358630537986755\n",
      "Iteration 800, Loss: 0.8070039749145508\n",
      "Iteration 900, Loss: 0.7812249064445496\n",
      "Iteration 1000, Loss: 0.7585174441337585\n",
      "Iteration 1100, Loss: 0.739311158657074\n",
      "Iteration 1200, Loss: 0.7236678004264832\n",
      "Iteration 1300, Loss: 0.7058394551277161\n",
      "Iteration 1400, Loss: 0.6933740973472595\n",
      "Iteration 1500, Loss: 0.6800132989883423\n",
      "Iteration 1600, Loss: 0.6685836315155029\n",
      "Iteration 1700, Loss: 0.6560708284378052\n",
      "Iteration 1800, Loss: 0.6435085535049438\n",
      "Iteration 1900, Loss: 0.6355312466621399\n",
      "Iteration 2000, Loss: 0.6235182285308838\n",
      "Iteration 2100, Loss: 0.6170229315757751\n",
      "Iteration 2200, Loss: 0.6062996983528137\n",
      "Iteration 2300, Loss: 0.5995985269546509\n",
      "Iteration 2400, Loss: 0.5928190350532532\n",
      "Iteration 2500, Loss: 0.5867927074432373\n",
      "Iteration 2600, Loss: 0.5817146897315979\n",
      "Iteration 2700, Loss: 0.5753734707832336\n",
      "Iteration 2800, Loss: 0.5687658190727234\n",
      "Iteration 2900, Loss: 0.5619593262672424\n"
     ]
    }
   ],
   "source": [
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin.mat')['XA']\n",
    "Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_fullwin.mat')['YA']\n",
    "\n",
    "\n",
    "X=torch.from_numpy(np.float32(Xall))\n",
    "Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "\n",
    "max_iterations=3000\n",
    "\n",
    "n = X.size(0)\n",
    "\n",
    "# Initialize a skew-symmetric matrix A\n",
    "\n",
    "A = torch.randn((n, n), requires_grad=True)\n",
    "A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "# Use ADAM optimizer\n",
    "optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "    C = cayley_transform(A)\n",
    "    loss = loss_function(X, Y, C)\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update A using gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration % 100 == 0:\n",
    "        print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "# Final optimized C\n",
    "C_optimized = cayley_transform(A)\n",
    "C_optimized=C_optimized.detach().numpy()\n",
    "Optimized_loss=loss.detach().numpy()\n",
    "\n",
    "#compute angular\n",
    "num = np.trace(X.detach().numpy().T @ C_optimized @ Y.detach().numpy() @ np.linalg.inv(C_optimized))\n",
    "\n",
    "\n",
    "denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "denom=denom.detach().numpy()\n",
    "angoptimalscore = np.cos(np.arccos(num/denom))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perm with random x 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 2.814499616622925\n",
      "Iteration 100, Loss: 2.695152759552002\n",
      "Iteration 200, Loss: 2.6193981170654297\n",
      "Iteration 300, Loss: 2.5923919677734375\n",
      "Iteration 400, Loss: 2.57241153717041\n",
      "Iteration 500, Loss: 2.5563366413116455\n",
      "Iteration 600, Loss: 2.5441765785217285\n",
      "Iteration 700, Loss: 2.533590793609619\n",
      "Iteration 800, Loss: 2.5256547927856445\n",
      "Iteration 900, Loss: 2.518123149871826\n",
      "Iteration 1000, Loss: 2.511741876602173\n",
      "Iteration 1100, Loss: 2.506168842315674\n",
      "Iteration 1200, Loss: 2.500749349594116\n",
      "Iteration 1300, Loss: 2.4972872734069824\n",
      "Iteration 1400, Loss: 2.4928553104400635\n",
      "Iteration 1500, Loss: 2.4894542694091797\n",
      "Iteration 1600, Loss: 2.487091064453125\n",
      "Iteration 1700, Loss: 2.483168363571167\n",
      "Iteration 1800, Loss: 2.4805798530578613\n",
      "Iteration 1900, Loss: 2.478231430053711\n",
      "Iteration 2000, Loss: 2.4758238792419434\n",
      "Iteration 2100, Loss: 2.474381685256958\n",
      "Iteration 2200, Loss: 2.471341133117676\n",
      "Iteration 2300, Loss: 2.470160722732544\n",
      "Iteration 2400, Loss: 2.46897029876709\n",
      "Iteration 2500, Loss: 2.4687557220458984\n",
      "Iteration 2600, Loss: 2.46687912940979\n",
      "Iteration 2700, Loss: 2.464144468307495\n",
      "Iteration 2800, Loss: 2.462651252746582\n",
      "Iteration 2900, Loss: 2.461465835571289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/_yg34tj15s306l4m7k_wf0qw0000gq/T/ipykernel_66893/267177544.py:56: RuntimeWarning: invalid value encountered in arccos\n",
      "  angpermscore[perm] = np.cos(np.arccos(num/denom))\n",
      "/var/folders/tv/_yg34tj15s306l4m7k_wf0qw0000gq/T/ipykernel_66893/267177544.py:56: RuntimeWarning: invalid value encountered in cos\n",
      "  angpermscore[perm] = np.cos(np.arccos(num/denom))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 3.003929376602173\n",
      "Iteration 100, Loss: 2.868960380554199\n",
      "Iteration 200, Loss: 2.879561185836792\n",
      "Iteration 300, Loss: 2.8424997329711914\n",
      "Iteration 400, Loss: 2.8255341053009033\n",
      "Iteration 500, Loss: 2.812756061553955\n",
      "Iteration 600, Loss: 2.8197414875030518\n",
      "Iteration 700, Loss: 2.7923316955566406\n",
      "Iteration 800, Loss: 2.7933003902435303\n",
      "Iteration 900, Loss: 2.780036687850952\n",
      "Iteration 1000, Loss: 2.771315574645996\n",
      "Iteration 1100, Loss: 2.7740960121154785\n",
      "Iteration 1200, Loss: 2.758230686187744\n",
      "Iteration 1300, Loss: 2.7564501762390137\n",
      "Iteration 1400, Loss: 2.7601683139801025\n",
      "Iteration 1500, Loss: 2.7563204765319824\n",
      "Iteration 1600, Loss: 2.7418081760406494\n",
      "Iteration 1700, Loss: 2.7385354042053223\n",
      "Iteration 1800, Loss: 2.7335829734802246\n",
      "Iteration 1900, Loss: 2.7298953533172607\n",
      "Iteration 2000, Loss: 2.7265751361846924\n",
      "Iteration 2100, Loss: 2.7245676517486572\n",
      "Iteration 2200, Loss: 2.7302308082580566\n",
      "Iteration 2300, Loss: 2.7196075916290283\n",
      "Iteration 2400, Loss: 2.7163517475128174\n",
      "Iteration 2500, Loss: 2.714843988418579\n",
      "Iteration 2600, Loss: 2.713625192642212\n",
      "Iteration 2700, Loss: 2.710145950317383\n",
      "Iteration 2800, Loss: 2.7077462673187256\n",
      "Iteration 2900, Loss: 2.707397937774658\n",
      "Iteration 0, Loss: 2.945009469985962\n",
      "Iteration 100, Loss: 2.7852632999420166\n",
      "Iteration 200, Loss: 2.7490241527557373\n",
      "Iteration 300, Loss: 2.725973129272461\n",
      "Iteration 400, Loss: 2.7094831466674805\n",
      "Iteration 500, Loss: 2.6971354484558105\n",
      "Iteration 600, Loss: 2.687412977218628\n",
      "Iteration 700, Loss: 2.6783106327056885\n",
      "Iteration 800, Loss: 2.6726889610290527\n",
      "Iteration 900, Loss: 2.6665308475494385\n",
      "Iteration 1000, Loss: 2.6720433235168457\n",
      "Iteration 1100, Loss: 2.6589698791503906\n",
      "Iteration 1200, Loss: 2.655153274536133\n",
      "Iteration 1300, Loss: 2.6501057147979736\n",
      "Iteration 1400, Loss: 2.6482369899749756\n",
      "Iteration 1500, Loss: 2.6450297832489014\n",
      "Iteration 1600, Loss: 2.6415083408355713\n",
      "Iteration 1700, Loss: 2.6411848068237305\n",
      "Iteration 1800, Loss: 2.6370601654052734\n",
      "Iteration 1900, Loss: 2.6359453201293945\n",
      "Iteration 2000, Loss: 2.6344082355499268\n",
      "Iteration 2100, Loss: 2.631885051727295\n",
      "Iteration 2200, Loss: 2.62982177734375\n",
      "Iteration 2300, Loss: 2.6280524730682373\n",
      "Iteration 2400, Loss: 2.6267921924591064\n",
      "Iteration 2500, Loss: 2.62699556350708\n",
      "Iteration 2600, Loss: 2.6240181922912598\n",
      "Iteration 2700, Loss: 2.625640869140625\n",
      "Iteration 2800, Loss: 2.622091293334961\n",
      "Iteration 2900, Loss: 2.6208276748657227\n",
      "Iteration 0, Loss: 2.71315860748291\n",
      "Iteration 100, Loss: 2.5448577404022217\n",
      "Iteration 200, Loss: 2.504885673522949\n",
      "Iteration 300, Loss: 2.4780116081237793\n",
      "Iteration 400, Loss: 2.4555065631866455\n",
      "Iteration 500, Loss: 2.438646078109741\n",
      "Iteration 600, Loss: 2.424755811691284\n",
      "Iteration 700, Loss: 2.413327217102051\n",
      "Iteration 800, Loss: 2.4037692546844482\n",
      "Iteration 900, Loss: 2.396301746368408\n",
      "Iteration 1000, Loss: 2.389949083328247\n",
      "Iteration 1100, Loss: 2.3846538066864014\n",
      "Iteration 1200, Loss: 2.380833387374878\n",
      "Iteration 1300, Loss: 2.375297784805298\n",
      "Iteration 1400, Loss: 2.3720145225524902\n",
      "Iteration 1500, Loss: 2.3686611652374268\n",
      "Iteration 1600, Loss: 2.3673276901245117\n",
      "Iteration 1700, Loss: 2.363880157470703\n",
      "Iteration 1800, Loss: 2.3604736328125\n",
      "Iteration 1900, Loss: 2.3590667247772217\n",
      "Iteration 2000, Loss: 2.355803966522217\n",
      "Iteration 2100, Loss: 2.3543405532836914\n",
      "Iteration 2200, Loss: 2.354746103286743\n",
      "Iteration 2300, Loss: 2.3502445220947266\n",
      "Iteration 2400, Loss: 2.3489575386047363\n",
      "Iteration 2500, Loss: 2.3494150638580322\n",
      "Iteration 2600, Loss: 2.3469185829162598\n",
      "Iteration 2700, Loss: 2.34444522857666\n",
      "Iteration 2800, Loss: 2.3422305583953857\n",
      "Iteration 2900, Loss: 2.3412556648254395\n",
      "Iteration 0, Loss: 2.5738775730133057\n",
      "Iteration 100, Loss: 2.4239377975463867\n",
      "Iteration 200, Loss: 2.389212131500244\n",
      "Iteration 300, Loss: 2.3605008125305176\n",
      "Iteration 400, Loss: 2.3387677669525146\n",
      "Iteration 500, Loss: 2.3328182697296143\n",
      "Iteration 600, Loss: 2.310852527618408\n",
      "Iteration 700, Loss: 2.3007800579071045\n",
      "Iteration 800, Loss: 2.2947301864624023\n",
      "Iteration 900, Loss: 2.287210464477539\n",
      "Iteration 1000, Loss: 2.280494213104248\n",
      "Iteration 1100, Loss: 2.274278163909912\n",
      "Iteration 1200, Loss: 2.270235538482666\n",
      "Iteration 1300, Loss: 2.2656891345977783\n",
      "Iteration 1400, Loss: 2.261284828186035\n",
      "Iteration 1500, Loss: 2.2571353912353516\n",
      "Iteration 1600, Loss: 2.254055976867676\n",
      "Iteration 1700, Loss: 2.250819206237793\n",
      "Iteration 1800, Loss: 2.259556293487549\n",
      "Iteration 1900, Loss: 2.245185375213623\n",
      "Iteration 2000, Loss: 2.243952989578247\n",
      "Iteration 2100, Loss: 2.240382194519043\n",
      "Iteration 2200, Loss: 2.238994598388672\n",
      "Iteration 2300, Loss: 2.2365498542785645\n",
      "Iteration 2400, Loss: 2.2361721992492676\n",
      "Iteration 2500, Loss: 2.2328648567199707\n",
      "Iteration 2600, Loss: 2.2317514419555664\n",
      "Iteration 2700, Loss: 2.2281711101531982\n",
      "Iteration 2800, Loss: 2.229102611541748\n",
      "Iteration 2900, Loss: 2.227794647216797\n",
      "Iteration 0, Loss: 2.699061632156372\n",
      "Iteration 100, Loss: 2.5535833835601807\n",
      "Iteration 200, Loss: 2.508270502090454\n",
      "Iteration 300, Loss: 2.4765889644622803\n",
      "Iteration 400, Loss: 2.453765869140625\n",
      "Iteration 500, Loss: 2.438399314880371\n",
      "Iteration 600, Loss: 2.4268696308135986\n",
      "Iteration 700, Loss: 2.4203078746795654\n",
      "Iteration 800, Loss: 2.4079411029815674\n",
      "Iteration 900, Loss: 2.400902271270752\n",
      "Iteration 1000, Loss: 2.3945412635803223\n",
      "Iteration 1100, Loss: 2.390021324157715\n",
      "Iteration 1200, Loss: 2.3836233615875244\n",
      "Iteration 1300, Loss: 2.380744457244873\n",
      "Iteration 1400, Loss: 2.3740077018737793\n",
      "Iteration 1500, Loss: 2.3716299533843994\n",
      "Iteration 1600, Loss: 2.3680684566497803\n",
      "Iteration 1700, Loss: 2.364715099334717\n",
      "Iteration 1800, Loss: 2.3624348640441895\n",
      "Iteration 1900, Loss: 2.360140562057495\n",
      "Iteration 2000, Loss: 2.3609554767608643\n",
      "Iteration 2100, Loss: 2.355224847793579\n",
      "Iteration 2200, Loss: 2.3539881706237793\n",
      "Iteration 2300, Loss: 2.351726770401001\n",
      "Iteration 2400, Loss: 2.3496992588043213\n",
      "Iteration 2500, Loss: 2.3481552600860596\n",
      "Iteration 2600, Loss: 2.345188617706299\n",
      "Iteration 2700, Loss: 2.3443610668182373\n",
      "Iteration 2800, Loss: 2.3421378135681152\n",
      "Iteration 2900, Loss: 2.3419787883758545\n",
      "Iteration 0, Loss: 2.6684701442718506\n",
      "Iteration 100, Loss: 2.5297465324401855\n",
      "Iteration 200, Loss: 2.48935866355896\n",
      "Iteration 300, Loss: 2.4630770683288574\n",
      "Iteration 400, Loss: 2.4425454139709473\n",
      "Iteration 500, Loss: 2.4245800971984863\n",
      "Iteration 600, Loss: 2.409719705581665\n",
      "Iteration 700, Loss: 2.397278070449829\n",
      "Iteration 800, Loss: 2.3871116638183594\n",
      "Iteration 900, Loss: 2.378417730331421\n",
      "Iteration 1000, Loss: 2.370961904525757\n",
      "Iteration 1100, Loss: 2.379056930541992\n",
      "Iteration 1200, Loss: 2.359858512878418\n",
      "Iteration 1300, Loss: 2.35500168800354\n",
      "Iteration 1400, Loss: 2.3518130779266357\n",
      "Iteration 1500, Loss: 2.350084066390991\n",
      "Iteration 1600, Loss: 2.3438048362731934\n",
      "Iteration 1700, Loss: 2.3408398628234863\n",
      "Iteration 1800, Loss: 2.3383588790893555\n",
      "Iteration 1900, Loss: 2.3353288173675537\n",
      "Iteration 2000, Loss: 2.334023952484131\n",
      "Iteration 2100, Loss: 2.3331518173217773\n",
      "Iteration 2200, Loss: 2.3297083377838135\n",
      "Iteration 2300, Loss: 2.327042818069458\n",
      "Iteration 2400, Loss: 2.3260533809661865\n",
      "Iteration 2500, Loss: 2.3226168155670166\n",
      "Iteration 2600, Loss: 2.3224053382873535\n",
      "Iteration 2700, Loss: 2.320268154144287\n",
      "Iteration 2800, Loss: 2.3180582523345947\n",
      "Iteration 2900, Loss: 2.3177051544189453\n",
      "Iteration 0, Loss: 2.881411075592041\n",
      "Iteration 100, Loss: 2.766738176345825\n",
      "Iteration 200, Loss: 2.7140939235687256\n",
      "Iteration 300, Loss: 2.744135856628418\n",
      "Iteration 400, Loss: 2.6815052032470703\n",
      "Iteration 500, Loss: 2.6672279834747314\n",
      "Iteration 600, Loss: 2.7258167266845703\n",
      "Iteration 700, Loss: 2.6661038398742676\n",
      "Iteration 800, Loss: 2.651623487472534\n",
      "Iteration 900, Loss: 2.6458747386932373\n",
      "Iteration 1000, Loss: 2.642202138900757\n",
      "Iteration 1100, Loss: 2.633485794067383\n",
      "Iteration 1200, Loss: 2.6610848903656006\n",
      "Iteration 1300, Loss: 2.6237404346466064\n",
      "Iteration 1400, Loss: 2.6185262203216553\n",
      "Iteration 1500, Loss: 2.6789369583129883\n",
      "Iteration 1600, Loss: 2.6128721237182617\n",
      "Iteration 1700, Loss: 2.6254172325134277\n",
      "Iteration 1800, Loss: 2.622856855392456\n",
      "Iteration 1900, Loss: 2.6038641929626465\n",
      "Iteration 2000, Loss: 2.5991101264953613\n",
      "Iteration 2100, Loss: 2.6626670360565186\n",
      "Iteration 2200, Loss: 2.5972111225128174\n",
      "Iteration 2300, Loss: 2.5928544998168945\n",
      "Iteration 2400, Loss: 2.5920963287353516\n",
      "Iteration 2500, Loss: 2.6030197143554688\n",
      "Iteration 2600, Loss: 2.648014783859253\n",
      "Iteration 2700, Loss: 2.5838468074798584\n",
      "Iteration 2800, Loss: 2.5874650478363037\n",
      "Iteration 2900, Loss: 2.57991623878479\n",
      "Iteration 0, Loss: 2.899860143661499\n",
      "Iteration 100, Loss: 2.7333829402923584\n",
      "Iteration 200, Loss: 2.701597213745117\n",
      "Iteration 300, Loss: 2.6791720390319824\n",
      "Iteration 400, Loss: 2.6657626628875732\n",
      "Iteration 500, Loss: 2.6470232009887695\n",
      "Iteration 600, Loss: 2.635615110397339\n",
      "Iteration 700, Loss: 2.627474546432495\n",
      "Iteration 800, Loss: 2.6383347511291504\n",
      "Iteration 900, Loss: 2.616849899291992\n",
      "Iteration 1000, Loss: 2.6095359325408936\n",
      "Iteration 1100, Loss: 2.604877233505249\n",
      "Iteration 1200, Loss: 2.6000728607177734\n",
      "Iteration 1300, Loss: 2.5957202911376953\n",
      "Iteration 1400, Loss: 2.5920894145965576\n",
      "Iteration 1500, Loss: 2.589172840118408\n",
      "Iteration 1600, Loss: 2.58658766746521\n",
      "Iteration 1700, Loss: 2.584085702896118\n",
      "Iteration 1800, Loss: 2.580963611602783\n",
      "Iteration 1900, Loss: 2.578129291534424\n",
      "Iteration 2000, Loss: 2.57761812210083\n",
      "Iteration 2100, Loss: 2.575538396835327\n",
      "Iteration 2200, Loss: 2.573410749435425\n",
      "Iteration 2300, Loss: 2.571552038192749\n",
      "Iteration 2400, Loss: 2.570570707321167\n",
      "Iteration 2500, Loss: 2.57682466506958\n",
      "Iteration 2600, Loss: 2.5662357807159424\n",
      "Iteration 2700, Loss: 2.567343235015869\n",
      "Iteration 2800, Loss: 2.5638387203216553\n",
      "Iteration 2900, Loss: 2.565293788909912\n",
      "Iteration 0, Loss: 2.5954530239105225\n",
      "Iteration 100, Loss: 2.5175750255584717\n",
      "Iteration 200, Loss: 2.415926218032837\n",
      "Iteration 300, Loss: 2.3787319660186768\n",
      "Iteration 400, Loss: 2.357123613357544\n",
      "Iteration 500, Loss: 2.34210467338562\n",
      "Iteration 600, Loss: 2.329957962036133\n",
      "Iteration 700, Loss: 2.319817304611206\n",
      "Iteration 800, Loss: 2.3120806217193604\n",
      "Iteration 900, Loss: 2.3053200244903564\n",
      "Iteration 1000, Loss: 2.2981526851654053\n",
      "Iteration 1100, Loss: 2.292982578277588\n",
      "Iteration 1200, Loss: 2.2871997356414795\n",
      "Iteration 1300, Loss: 2.282075881958008\n",
      "Iteration 1400, Loss: 2.278581142425537\n",
      "Iteration 1500, Loss: 2.274181842803955\n",
      "Iteration 1600, Loss: 2.270294189453125\n",
      "Iteration 1700, Loss: 2.2656280994415283\n",
      "Iteration 1800, Loss: 2.2622268199920654\n",
      "Iteration 1900, Loss: 2.259225368499756\n",
      "Iteration 2000, Loss: 2.258000612258911\n",
      "Iteration 2100, Loss: 2.2564759254455566\n",
      "Iteration 2200, Loss: 2.2514123916625977\n",
      "Iteration 2300, Loss: 2.2493557929992676\n",
      "Iteration 2400, Loss: 2.2466323375701904\n",
      "Iteration 2500, Loss: 2.2452476024627686\n",
      "Iteration 2600, Loss: 2.243429183959961\n",
      "Iteration 2700, Loss: 2.2426035404205322\n",
      "Iteration 2800, Loss: 2.239720106124878\n",
      "Iteration 2900, Loss: 2.236074447631836\n",
      "Iteration 0, Loss: 2.816817045211792\n",
      "Iteration 100, Loss: 2.68023943901062\n",
      "Iteration 200, Loss: 2.671036958694458\n",
      "Iteration 300, Loss: 2.6336584091186523\n",
      "Iteration 400, Loss: 2.615330934524536\n",
      "Iteration 500, Loss: 2.609724521636963\n",
      "Iteration 600, Loss: 2.595363140106201\n",
      "Iteration 700, Loss: 2.5849504470825195\n",
      "Iteration 800, Loss: 2.578616142272949\n",
      "Iteration 900, Loss: 2.5867738723754883\n",
      "Iteration 1000, Loss: 2.561643600463867\n",
      "Iteration 1100, Loss: 2.5545976161956787\n",
      "Iteration 1200, Loss: 2.5499343872070312\n",
      "Iteration 1300, Loss: 2.5421457290649414\n",
      "Iteration 1400, Loss: 2.5374462604522705\n",
      "Iteration 1500, Loss: 2.5329391956329346\n",
      "Iteration 1600, Loss: 2.533846139907837\n",
      "Iteration 1700, Loss: 2.5255393981933594\n",
      "Iteration 1800, Loss: 2.5215179920196533\n",
      "Iteration 1900, Loss: 2.5185060501098633\n",
      "Iteration 2000, Loss: 2.516031265258789\n",
      "Iteration 2100, Loss: 2.512644052505493\n",
      "Iteration 2200, Loss: 2.508981704711914\n",
      "Iteration 2300, Loss: 2.510270833969116\n",
      "Iteration 2400, Loss: 2.5054774284362793\n",
      "Iteration 2500, Loss: 2.50308895111084\n",
      "Iteration 2600, Loss: 2.500518560409546\n",
      "Iteration 2700, Loss: 2.5001533031463623\n",
      "Iteration 2800, Loss: 2.497584581375122\n",
      "Iteration 2900, Loss: 2.494187831878662\n",
      "Iteration 0, Loss: 2.573528528213501\n",
      "Iteration 100, Loss: 2.452962875366211\n",
      "Iteration 200, Loss: 2.398561954498291\n",
      "Iteration 300, Loss: 2.372894287109375\n",
      "Iteration 400, Loss: 2.369359016418457\n",
      "Iteration 500, Loss: 2.347791910171509\n",
      "Iteration 600, Loss: 2.3323259353637695\n",
      "Iteration 700, Loss: 2.339447259902954\n",
      "Iteration 800, Loss: 2.3124122619628906\n",
      "Iteration 900, Loss: 2.3030996322631836\n",
      "Iteration 1000, Loss: 2.2968976497650146\n",
      "Iteration 1100, Loss: 2.291114330291748\n",
      "Iteration 1200, Loss: 2.2836618423461914\n",
      "Iteration 1300, Loss: 2.2791600227355957\n",
      "Iteration 1400, Loss: 2.2728326320648193\n",
      "Iteration 1500, Loss: 2.282250165939331\n",
      "Iteration 1600, Loss: 2.2651405334472656\n",
      "Iteration 1700, Loss: 2.262247323989868\n",
      "Iteration 1800, Loss: 2.2575833797454834\n",
      "Iteration 1900, Loss: 2.256568193435669\n",
      "Iteration 2000, Loss: 2.2706735134124756\n",
      "Iteration 2100, Loss: 2.2498779296875\n",
      "Iteration 2200, Loss: 2.246408224105835\n",
      "Iteration 2300, Loss: 2.2488338947296143\n",
      "Iteration 2400, Loss: 2.2425613403320312\n",
      "Iteration 2500, Loss: 2.2402303218841553\n",
      "Iteration 2600, Loss: 2.2394251823425293\n",
      "Iteration 2700, Loss: 2.2361180782318115\n",
      "Iteration 2800, Loss: 2.2336935997009277\n",
      "Iteration 2900, Loss: 2.2355549335479736\n",
      "Iteration 0, Loss: 2.7047171592712402\n",
      "Iteration 100, Loss: 2.545167922973633\n",
      "Iteration 200, Loss: 2.515439748764038\n",
      "Iteration 300, Loss: 2.4942681789398193\n",
      "Iteration 400, Loss: 2.4961414337158203\n",
      "Iteration 500, Loss: 2.4643330574035645\n",
      "Iteration 600, Loss: 2.4586918354034424\n",
      "Iteration 700, Loss: 2.4411909580230713\n",
      "Iteration 800, Loss: 2.4322593212127686\n",
      "Iteration 900, Loss: 2.423947811126709\n",
      "Iteration 1000, Loss: 2.4184179306030273\n",
      "Iteration 1100, Loss: 2.410400390625\n",
      "Iteration 1200, Loss: 2.405021905899048\n",
      "Iteration 1300, Loss: 2.398815870285034\n",
      "Iteration 1400, Loss: 2.3942935466766357\n",
      "Iteration 1500, Loss: 2.3901267051696777\n",
      "Iteration 1600, Loss: 2.3866398334503174\n",
      "Iteration 1700, Loss: 2.3830411434173584\n",
      "Iteration 1800, Loss: 2.3809845447540283\n",
      "Iteration 1900, Loss: 2.3788514137268066\n",
      "Iteration 2000, Loss: 2.3747076988220215\n",
      "Iteration 2100, Loss: 2.3716981410980225\n",
      "Iteration 2200, Loss: 2.3705339431762695\n",
      "Iteration 2300, Loss: 2.3670811653137207\n",
      "Iteration 2400, Loss: 2.3658246994018555\n",
      "Iteration 2500, Loss: 2.362642765045166\n",
      "Iteration 2600, Loss: 2.3611509799957275\n",
      "Iteration 2700, Loss: 2.358180284500122\n",
      "Iteration 2800, Loss: 2.3571462631225586\n",
      "Iteration 2900, Loss: 2.3566582202911377\n",
      "Iteration 0, Loss: 2.7272937297821045\n",
      "Iteration 100, Loss: 2.586041212081909\n",
      "Iteration 200, Loss: 2.543253183364868\n",
      "Iteration 300, Loss: 2.5197641849517822\n",
      "Iteration 400, Loss: 2.5051214694976807\n",
      "Iteration 500, Loss: 2.503859519958496\n",
      "Iteration 600, Loss: 2.478545904159546\n",
      "Iteration 700, Loss: 2.4780161380767822\n",
      "Iteration 800, Loss: 2.4616456031799316\n",
      "Iteration 900, Loss: 2.4535772800445557\n",
      "Iteration 1000, Loss: 2.4474329948425293\n",
      "Iteration 1100, Loss: 2.4420459270477295\n",
      "Iteration 1200, Loss: 2.4374938011169434\n",
      "Iteration 1300, Loss: 2.433912515640259\n",
      "Iteration 1400, Loss: 2.432515859603882\n",
      "Iteration 1500, Loss: 2.4254379272460938\n",
      "Iteration 1600, Loss: 2.4227750301361084\n",
      "Iteration 1700, Loss: 2.419950008392334\n",
      "Iteration 1800, Loss: 2.4157724380493164\n",
      "Iteration 1900, Loss: 2.413424015045166\n",
      "Iteration 2000, Loss: 2.4106240272521973\n",
      "Iteration 2100, Loss: 2.4086010456085205\n",
      "Iteration 2200, Loss: 2.40539288520813\n",
      "Iteration 2300, Loss: 2.403313159942627\n",
      "Iteration 2400, Loss: 2.4016189575195312\n",
      "Iteration 2500, Loss: 2.3979909420013428\n",
      "Iteration 2600, Loss: 2.3965225219726562\n",
      "Iteration 2700, Loss: 2.3946452140808105\n",
      "Iteration 2800, Loss: 2.392429828643799\n",
      "Iteration 2900, Loss: 2.3910789489746094\n",
      "Iteration 0, Loss: 2.7218596935272217\n",
      "Iteration 100, Loss: 2.55119252204895\n",
      "Iteration 200, Loss: 2.510411024093628\n",
      "Iteration 300, Loss: 2.481428861618042\n",
      "Iteration 400, Loss: 2.4612369537353516\n",
      "Iteration 500, Loss: 2.445469379425049\n",
      "Iteration 600, Loss: 2.438401222229004\n",
      "Iteration 700, Loss: 2.4237849712371826\n",
      "Iteration 800, Loss: 2.415087938308716\n",
      "Iteration 900, Loss: 2.407954216003418\n",
      "Iteration 1000, Loss: 2.402459144592285\n",
      "Iteration 1100, Loss: 2.3977303504943848\n",
      "Iteration 1200, Loss: 2.3933660984039307\n",
      "Iteration 1300, Loss: 2.389439105987549\n",
      "Iteration 1400, Loss: 2.3855183124542236\n",
      "Iteration 1500, Loss: 2.3817214965820312\n",
      "Iteration 1600, Loss: 2.3790464401245117\n",
      "Iteration 1700, Loss: 2.376575231552124\n",
      "Iteration 1800, Loss: 2.3739511966705322\n",
      "Iteration 1900, Loss: 2.3711414337158203\n",
      "Iteration 2000, Loss: 2.368917942047119\n",
      "Iteration 2100, Loss: 2.367100238800049\n",
      "Iteration 2200, Loss: 2.364821672439575\n",
      "Iteration 2300, Loss: 2.364193916320801\n",
      "Iteration 2400, Loss: 2.361908435821533\n",
      "Iteration 2500, Loss: 2.361610174179077\n",
      "Iteration 2600, Loss: 2.3570010662078857\n",
      "Iteration 2700, Loss: 2.3555774688720703\n",
      "Iteration 2800, Loss: 2.3546946048736572\n",
      "Iteration 2900, Loss: 2.3526296615600586\n",
      "Iteration 0, Loss: 2.822608470916748\n",
      "Iteration 100, Loss: 2.683326482772827\n",
      "Iteration 200, Loss: 2.6508867740631104\n",
      "Iteration 300, Loss: 2.62744140625\n",
      "Iteration 400, Loss: 2.6162467002868652\n",
      "Iteration 500, Loss: 2.5986080169677734\n",
      "Iteration 600, Loss: 2.5891830921173096\n",
      "Iteration 700, Loss: 2.5991156101226807\n",
      "Iteration 800, Loss: 2.5726358890533447\n",
      "Iteration 900, Loss: 2.565483570098877\n",
      "Iteration 1000, Loss: 2.5598232746124268\n",
      "Iteration 1100, Loss: 2.5549020767211914\n",
      "Iteration 1200, Loss: 2.5503368377685547\n",
      "Iteration 1300, Loss: 2.5486326217651367\n",
      "Iteration 1400, Loss: 2.546982526779175\n",
      "Iteration 1500, Loss: 2.539236307144165\n",
      "Iteration 1600, Loss: 2.5370736122131348\n",
      "Iteration 1700, Loss: 2.5333564281463623\n",
      "Iteration 1800, Loss: 2.5298593044281006\n",
      "Iteration 1900, Loss: 2.529135227203369\n",
      "Iteration 2000, Loss: 2.525587558746338\n",
      "Iteration 2100, Loss: 2.5239243507385254\n",
      "Iteration 2200, Loss: 2.521056652069092\n",
      "Iteration 2300, Loss: 2.519371747970581\n",
      "Iteration 2400, Loss: 2.517730474472046\n",
      "Iteration 2500, Loss: 2.5316965579986572\n",
      "Iteration 2600, Loss: 2.513078451156616\n",
      "Iteration 2700, Loss: 2.5113322734832764\n",
      "Iteration 2800, Loss: 2.510721206665039\n",
      "Iteration 2900, Loss: 2.5086164474487305\n",
      "Iteration 0, Loss: 2.8567216396331787\n",
      "Iteration 100, Loss: 2.71942138671875\n",
      "Iteration 200, Loss: 2.6743226051330566\n",
      "Iteration 300, Loss: 2.647679328918457\n",
      "Iteration 400, Loss: 2.628242015838623\n",
      "Iteration 500, Loss: 2.6133172512054443\n",
      "Iteration 600, Loss: 2.6009819507598877\n",
      "Iteration 700, Loss: 2.590991973876953\n",
      "Iteration 800, Loss: 2.582566499710083\n",
      "Iteration 900, Loss: 2.575117826461792\n",
      "Iteration 1000, Loss: 2.570706605911255\n",
      "Iteration 1100, Loss: 2.5656282901763916\n",
      "Iteration 1200, Loss: 2.5607690811157227\n",
      "Iteration 1300, Loss: 2.5589828491210938\n",
      "Iteration 1400, Loss: 2.5519254207611084\n",
      "Iteration 1500, Loss: 2.5499744415283203\n",
      "Iteration 1600, Loss: 2.546351194381714\n",
      "Iteration 1700, Loss: 2.5446784496307373\n",
      "Iteration 1800, Loss: 2.54001522064209\n",
      "Iteration 1900, Loss: 2.5380265712738037\n",
      "Iteration 2000, Loss: 2.5361287593841553\n",
      "Iteration 2100, Loss: 2.534043073654175\n",
      "Iteration 2200, Loss: 2.5320053100585938\n",
      "Iteration 2300, Loss: 2.5318524837493896\n",
      "Iteration 2400, Loss: 2.5283150672912598\n",
      "Iteration 2500, Loss: 2.526071786880493\n",
      "Iteration 2600, Loss: 2.524787425994873\n",
      "Iteration 2700, Loss: 2.523381233215332\n",
      "Iteration 2800, Loss: 2.52181339263916\n",
      "Iteration 2900, Loss: 2.522529125213623\n",
      "Iteration 0, Loss: 2.985707998275757\n",
      "Iteration 100, Loss: 2.823392391204834\n",
      "Iteration 200, Loss: 2.782172203063965\n",
      "Iteration 300, Loss: 2.7585432529449463\n",
      "Iteration 400, Loss: 2.7464101314544678\n",
      "Iteration 500, Loss: 2.74893856048584\n",
      "Iteration 600, Loss: 2.7213447093963623\n",
      "Iteration 700, Loss: 2.7142281532287598\n",
      "Iteration 800, Loss: 2.7065541744232178\n",
      "Iteration 900, Loss: 2.6996212005615234\n",
      "Iteration 1000, Loss: 2.693859577178955\n",
      "Iteration 1100, Loss: 2.689408779144287\n",
      "Iteration 1200, Loss: 2.685232162475586\n",
      "Iteration 1300, Loss: 2.6817336082458496\n",
      "Iteration 1400, Loss: 2.6788671016693115\n",
      "Iteration 1500, Loss: 2.6761868000030518\n",
      "Iteration 1600, Loss: 2.6745848655700684\n",
      "Iteration 1700, Loss: 2.669288396835327\n",
      "Iteration 1800, Loss: 2.6665172576904297\n",
      "Iteration 1900, Loss: 2.6654856204986572\n",
      "Iteration 2000, Loss: 2.6644680500030518\n",
      "Iteration 2100, Loss: 2.6618478298187256\n",
      "Iteration 2200, Loss: 2.6593732833862305\n",
      "Iteration 2300, Loss: 2.656686305999756\n",
      "Iteration 2400, Loss: 2.655616521835327\n",
      "Iteration 2500, Loss: 2.653031587600708\n",
      "Iteration 2600, Loss: 2.6519196033477783\n",
      "Iteration 2700, Loss: 2.649731397628784\n",
      "Iteration 2800, Loss: 2.6480226516723633\n",
      "Iteration 2900, Loss: 2.6469345092773438\n",
      "Iteration 0, Loss: 2.8606019020080566\n",
      "Iteration 100, Loss: 2.6766602993011475\n",
      "Iteration 200, Loss: 2.6385657787323\n",
      "Iteration 300, Loss: 2.6085681915283203\n",
      "Iteration 400, Loss: 2.589869737625122\n",
      "Iteration 500, Loss: 2.5757815837860107\n",
      "Iteration 600, Loss: 2.5649821758270264\n",
      "Iteration 700, Loss: 2.5573537349700928\n",
      "Iteration 800, Loss: 2.5505471229553223\n",
      "Iteration 900, Loss: 2.545194149017334\n",
      "Iteration 1000, Loss: 2.539853572845459\n",
      "Iteration 1100, Loss: 2.5356411933898926\n",
      "Iteration 1200, Loss: 2.5318784713745117\n",
      "Iteration 1300, Loss: 2.5286970138549805\n",
      "Iteration 1400, Loss: 2.5264666080474854\n",
      "Iteration 1500, Loss: 2.5235648155212402\n",
      "Iteration 1600, Loss: 2.520219087600708\n",
      "Iteration 1700, Loss: 2.519355535507202\n",
      "Iteration 1800, Loss: 2.5161612033843994\n",
      "Iteration 1900, Loss: 2.5143840312957764\n",
      "Iteration 2000, Loss: 2.5129928588867188\n",
      "Iteration 2100, Loss: 2.510226011276245\n",
      "Iteration 2200, Loss: 2.509394645690918\n",
      "Iteration 2300, Loss: 2.509554624557495\n",
      "Iteration 2400, Loss: 2.506455183029175\n",
      "Iteration 2500, Loss: 2.5042245388031006\n",
      "Iteration 2600, Loss: 2.5028023719787598\n",
      "Iteration 2700, Loss: 2.5028555393218994\n",
      "Iteration 2800, Loss: 2.500117778778076\n",
      "Iteration 2900, Loss: 2.499194622039795\n",
      "Iteration 0, Loss: 2.820037603378296\n",
      "Iteration 100, Loss: 2.6761722564697266\n",
      "Iteration 200, Loss: 2.638718843460083\n",
      "Iteration 300, Loss: 2.621103525161743\n",
      "Iteration 400, Loss: 2.6250085830688477\n",
      "Iteration 500, Loss: 2.5902607440948486\n",
      "Iteration 600, Loss: 2.5796966552734375\n",
      "Iteration 700, Loss: 2.5706701278686523\n",
      "Iteration 800, Loss: 2.561819076538086\n",
      "Iteration 900, Loss: 2.5552496910095215\n",
      "Iteration 1000, Loss: 2.548830270767212\n",
      "Iteration 1100, Loss: 2.546675205230713\n",
      "Iteration 1200, Loss: 2.538433313369751\n",
      "Iteration 1300, Loss: 2.5329999923706055\n",
      "Iteration 1400, Loss: 2.54267954826355\n",
      "Iteration 1500, Loss: 2.5248525142669678\n",
      "Iteration 1600, Loss: 2.520967721939087\n",
      "Iteration 1700, Loss: 2.517904043197632\n",
      "Iteration 1800, Loss: 2.5159730911254883\n",
      "Iteration 1900, Loss: 2.5116019248962402\n",
      "Iteration 2000, Loss: 2.5091636180877686\n",
      "Iteration 2100, Loss: 2.5067224502563477\n",
      "Iteration 2200, Loss: 2.5050032138824463\n",
      "Iteration 2300, Loss: 2.5028069019317627\n",
      "Iteration 2400, Loss: 2.4995346069335938\n",
      "Iteration 2500, Loss: 2.5017497539520264\n",
      "Iteration 2600, Loss: 2.4972586631774902\n",
      "Iteration 2700, Loss: 2.4943320751190186\n",
      "Iteration 2800, Loss: 2.4920620918273926\n",
      "Iteration 2900, Loss: 2.4950685501098633\n",
      "Iteration 0, Loss: 3.1028683185577393\n",
      "Iteration 100, Loss: 2.9559407234191895\n",
      "Iteration 200, Loss: 2.9112472534179688\n",
      "Iteration 300, Loss: 2.8815438747406006\n",
      "Iteration 400, Loss: 2.859013319015503\n",
      "Iteration 500, Loss: 2.8424930572509766\n",
      "Iteration 600, Loss: 2.8305821418762207\n",
      "Iteration 700, Loss: 2.8206117153167725\n",
      "Iteration 800, Loss: 2.813415288925171\n",
      "Iteration 900, Loss: 2.8056247234344482\n",
      "Iteration 1000, Loss: 2.8002769947052\n",
      "Iteration 1100, Loss: 2.7945799827575684\n",
      "Iteration 1200, Loss: 2.7904999256134033\n",
      "Iteration 1300, Loss: 2.786266803741455\n",
      "Iteration 1400, Loss: 2.782700777053833\n",
      "Iteration 1500, Loss: 2.7808947563171387\n",
      "Iteration 1600, Loss: 2.7772250175476074\n",
      "Iteration 1700, Loss: 2.774660110473633\n",
      "Iteration 1800, Loss: 2.7723824977874756\n",
      "Iteration 1900, Loss: 2.770519971847534\n",
      "Iteration 2000, Loss: 2.7671988010406494\n",
      "Iteration 2100, Loss: 2.7653372287750244\n",
      "Iteration 2200, Loss: 2.7641189098358154\n",
      "Iteration 2300, Loss: 2.7620081901550293\n",
      "Iteration 2400, Loss: 2.7608413696289062\n",
      "Iteration 2500, Loss: 2.7596421241760254\n",
      "Iteration 2600, Loss: 2.7570855617523193\n",
      "Iteration 2700, Loss: 2.756045341491699\n",
      "Iteration 2800, Loss: 2.75498628616333\n",
      "Iteration 2900, Loss: 2.7529397010803223\n",
      "Iteration 0, Loss: 3.0098886489868164\n",
      "Iteration 100, Loss: 2.8728904724121094\n",
      "Iteration 200, Loss: 2.826810121536255\n",
      "Iteration 300, Loss: 2.801870822906494\n",
      "Iteration 400, Loss: 2.783616304397583\n",
      "Iteration 500, Loss: 2.771109104156494\n",
      "Iteration 600, Loss: 2.7612674236297607\n",
      "Iteration 700, Loss: 2.7525100708007812\n",
      "Iteration 800, Loss: 2.759812593460083\n",
      "Iteration 900, Loss: 2.738401174545288\n",
      "Iteration 1000, Loss: 2.734165906906128\n",
      "Iteration 1100, Loss: 2.7268028259277344\n",
      "Iteration 1200, Loss: 2.7220425605773926\n",
      "Iteration 1300, Loss: 2.717465400695801\n",
      "Iteration 1400, Loss: 2.713322162628174\n",
      "Iteration 1500, Loss: 2.709639549255371\n",
      "Iteration 1600, Loss: 2.705764055252075\n",
      "Iteration 1700, Loss: 2.7029008865356445\n",
      "Iteration 1800, Loss: 2.6995179653167725\n",
      "Iteration 1900, Loss: 2.696678638458252\n",
      "Iteration 2000, Loss: 2.694267988204956\n",
      "Iteration 2100, Loss: 2.691511869430542\n",
      "Iteration 2200, Loss: 2.6892383098602295\n",
      "Iteration 2300, Loss: 2.687350273132324\n",
      "Iteration 2400, Loss: 2.686000108718872\n",
      "Iteration 2500, Loss: 2.6864895820617676\n",
      "Iteration 2600, Loss: 2.6821157932281494\n",
      "Iteration 2700, Loss: 2.6815385818481445\n",
      "Iteration 2800, Loss: 2.6793112754821777\n",
      "Iteration 2900, Loss: 2.677612543106079\n",
      "Iteration 0, Loss: 2.7705159187316895\n",
      "Iteration 100, Loss: 2.618147134780884\n",
      "Iteration 200, Loss: 2.6699397563934326\n",
      "Iteration 300, Loss: 2.5952088832855225\n",
      "Iteration 400, Loss: 2.5721986293792725\n",
      "Iteration 500, Loss: 2.5538132190704346\n",
      "Iteration 600, Loss: 2.5390005111694336\n",
      "Iteration 700, Loss: 2.5265004634857178\n",
      "Iteration 800, Loss: 2.5239484310150146\n",
      "Iteration 900, Loss: 2.5088138580322266\n",
      "Iteration 1000, Loss: 2.5203187465667725\n",
      "Iteration 1100, Loss: 2.495288610458374\n",
      "Iteration 1200, Loss: 2.489262580871582\n",
      "Iteration 1300, Loss: 2.4909627437591553\n",
      "Iteration 1400, Loss: 2.4798717498779297\n",
      "Iteration 1500, Loss: 2.4757540225982666\n",
      "Iteration 1600, Loss: 2.4733965396881104\n",
      "Iteration 1700, Loss: 2.480445384979248\n",
      "Iteration 1800, Loss: 2.465061664581299\n",
      "Iteration 1900, Loss: 2.4613051414489746\n",
      "Iteration 2000, Loss: 2.457136869430542\n",
      "Iteration 2100, Loss: 2.4550399780273438\n",
      "Iteration 2200, Loss: 2.453505039215088\n",
      "Iteration 2300, Loss: 2.4488611221313477\n",
      "Iteration 2400, Loss: 2.447051525115967\n",
      "Iteration 2500, Loss: 2.4447038173675537\n",
      "Iteration 2600, Loss: 2.443455934524536\n",
      "Iteration 2700, Loss: 2.440556764602661\n",
      "Iteration 2800, Loss: 2.43985915184021\n",
      "Iteration 2900, Loss: 2.439131736755371\n",
      "Iteration 0, Loss: 3.104950428009033\n",
      "Iteration 100, Loss: 2.9585790634155273\n",
      "Iteration 200, Loss: 2.913344144821167\n",
      "Iteration 300, Loss: 2.8785953521728516\n",
      "Iteration 400, Loss: 2.8580539226531982\n",
      "Iteration 500, Loss: 2.8456015586853027\n",
      "Iteration 600, Loss: 2.833817720413208\n",
      "Iteration 700, Loss: 2.825263261795044\n",
      "Iteration 800, Loss: 2.820403575897217\n",
      "Iteration 900, Loss: 2.812568426132202\n",
      "Iteration 1000, Loss: 2.8065896034240723\n",
      "Iteration 1100, Loss: 2.8022191524505615\n",
      "Iteration 1200, Loss: 2.79714298248291\n",
      "Iteration 1300, Loss: 2.793011426925659\n",
      "Iteration 1400, Loss: 2.789450168609619\n",
      "Iteration 1500, Loss: 2.7850141525268555\n",
      "Iteration 1600, Loss: 2.7815945148468018\n",
      "Iteration 1700, Loss: 2.77858567237854\n",
      "Iteration 1800, Loss: 2.7756049633026123\n",
      "Iteration 1900, Loss: 2.772836446762085\n",
      "Iteration 2000, Loss: 2.770340919494629\n",
      "Iteration 2100, Loss: 2.7684478759765625\n",
      "Iteration 2200, Loss: 2.765933036804199\n",
      "Iteration 2300, Loss: 2.7636895179748535\n",
      "Iteration 2400, Loss: 2.762226104736328\n",
      "Iteration 2500, Loss: 2.760570526123047\n",
      "Iteration 2600, Loss: 2.7600793838500977\n",
      "Iteration 2700, Loss: 2.7572224140167236\n",
      "Iteration 2800, Loss: 2.758251190185547\n",
      "Iteration 2900, Loss: 2.755162239074707\n",
      "Iteration 0, Loss: 2.8760111331939697\n",
      "Iteration 100, Loss: 2.7111034393310547\n",
      "Iteration 200, Loss: 2.679708242416382\n",
      "Iteration 300, Loss: 2.6561765670776367\n",
      "Iteration 400, Loss: 2.637617588043213\n",
      "Iteration 500, Loss: 2.620521306991577\n",
      "Iteration 600, Loss: 2.606935739517212\n",
      "Iteration 700, Loss: 2.5965027809143066\n",
      "Iteration 800, Loss: 2.5857045650482178\n",
      "Iteration 900, Loss: 2.5780680179595947\n",
      "Iteration 1000, Loss: 2.571664810180664\n",
      "Iteration 1100, Loss: 2.565086603164673\n",
      "Iteration 1200, Loss: 2.560380220413208\n",
      "Iteration 1300, Loss: 2.55483341217041\n",
      "Iteration 1400, Loss: 2.5509326457977295\n",
      "Iteration 1500, Loss: 2.5458621978759766\n",
      "Iteration 1600, Loss: 2.542768955230713\n",
      "Iteration 1700, Loss: 2.539469003677368\n",
      "Iteration 1800, Loss: 2.5360448360443115\n",
      "Iteration 1900, Loss: 2.534005641937256\n",
      "Iteration 2000, Loss: 2.5330398082733154\n",
      "Iteration 2100, Loss: 2.5292932987213135\n",
      "Iteration 2200, Loss: 2.5275449752807617\n",
      "Iteration 2300, Loss: 2.5265114307403564\n",
      "Iteration 2400, Loss: 2.5230982303619385\n",
      "Iteration 2500, Loss: 2.522336006164551\n",
      "Iteration 2600, Loss: 2.5203258991241455\n",
      "Iteration 2700, Loss: 2.5217745304107666\n",
      "Iteration 2800, Loss: 2.5177388191223145\n",
      "Iteration 2900, Loss: 2.517261028289795\n",
      "Iteration 0, Loss: 2.718749761581421\n",
      "Iteration 100, Loss: 2.5817785263061523\n",
      "Iteration 200, Loss: 2.5319015979766846\n",
      "Iteration 300, Loss: 2.502901315689087\n",
      "Iteration 400, Loss: 2.483752965927124\n",
      "Iteration 500, Loss: 2.4677932262420654\n",
      "Iteration 600, Loss: 2.4536759853363037\n",
      "Iteration 700, Loss: 2.4415056705474854\n",
      "Iteration 800, Loss: 2.4334304332733154\n",
      "Iteration 900, Loss: 2.424119234085083\n",
      "Iteration 1000, Loss: 2.4171290397644043\n",
      "Iteration 1100, Loss: 2.4095776081085205\n",
      "Iteration 1200, Loss: 2.404850721359253\n",
      "Iteration 1300, Loss: 2.398789405822754\n",
      "Iteration 1400, Loss: 2.393860340118408\n",
      "Iteration 1500, Loss: 2.390793561935425\n",
      "Iteration 1600, Loss: 2.385390520095825\n",
      "Iteration 1700, Loss: 2.3827402591705322\n",
      "Iteration 1800, Loss: 2.3788037300109863\n",
      "Iteration 1900, Loss: 2.3753480911254883\n",
      "Iteration 2000, Loss: 2.3729567527770996\n",
      "Iteration 2100, Loss: 2.3705880641937256\n",
      "Iteration 2200, Loss: 2.368335247039795\n",
      "Iteration 2300, Loss: 2.369575023651123\n",
      "Iteration 2400, Loss: 2.362480640411377\n",
      "Iteration 2500, Loss: 2.3608322143554688\n",
      "Iteration 2600, Loss: 2.3588600158691406\n",
      "Iteration 2700, Loss: 2.3579671382904053\n",
      "Iteration 2800, Loss: 2.3568413257598877\n",
      "Iteration 2900, Loss: 2.353663206100464\n",
      "Iteration 0, Loss: 2.8948757648468018\n",
      "Iteration 100, Loss: 2.7516849040985107\n",
      "Iteration 200, Loss: 2.7248470783233643\n",
      "Iteration 300, Loss: 2.705031633377075\n",
      "Iteration 400, Loss: 2.690919876098633\n",
      "Iteration 500, Loss: 2.682762384414673\n",
      "Iteration 600, Loss: 2.6793947219848633\n",
      "Iteration 700, Loss: 2.670423746109009\n",
      "Iteration 800, Loss: 2.6539735794067383\n",
      "Iteration 900, Loss: 2.6470870971679688\n",
      "Iteration 1000, Loss: 2.6438918113708496\n",
      "Iteration 1100, Loss: 2.634024143218994\n",
      "Iteration 1200, Loss: 2.6288092136383057\n",
      "Iteration 1300, Loss: 2.644918203353882\n",
      "Iteration 1400, Loss: 2.6385035514831543\n",
      "Iteration 1500, Loss: 2.6343820095062256\n",
      "Iteration 1600, Loss: 2.613907814025879\n",
      "Iteration 1700, Loss: 2.607577323913574\n",
      "Iteration 1800, Loss: 2.6041829586029053\n",
      "Iteration 1900, Loss: 2.6014766693115234\n",
      "Iteration 2000, Loss: 2.6040380001068115\n",
      "Iteration 2100, Loss: 2.5988786220550537\n",
      "Iteration 2200, Loss: 2.5936431884765625\n",
      "Iteration 2300, Loss: 2.591679096221924\n",
      "Iteration 2400, Loss: 2.591118812561035\n",
      "Iteration 2500, Loss: 2.586404800415039\n",
      "Iteration 2600, Loss: 2.6126158237457275\n",
      "Iteration 2700, Loss: 2.5842247009277344\n",
      "Iteration 2800, Loss: 2.581766128540039\n",
      "Iteration 2900, Loss: 2.5843183994293213\n",
      "Iteration 0, Loss: 2.786891460418701\n",
      "Iteration 100, Loss: 2.6425559520721436\n",
      "Iteration 200, Loss: 2.6103923320770264\n",
      "Iteration 300, Loss: 2.586919069290161\n",
      "Iteration 400, Loss: 2.5670626163482666\n",
      "Iteration 500, Loss: 2.547675848007202\n",
      "Iteration 600, Loss: 2.5332021713256836\n",
      "Iteration 700, Loss: 2.5263237953186035\n",
      "Iteration 800, Loss: 2.5143566131591797\n",
      "Iteration 900, Loss: 2.5081589221954346\n",
      "Iteration 1000, Loss: 2.5013926029205322\n",
      "Iteration 1100, Loss: 2.4958066940307617\n",
      "Iteration 1200, Loss: 2.4900457859039307\n",
      "Iteration 1300, Loss: 2.485443353652954\n",
      "Iteration 1400, Loss: 2.484609365463257\n",
      "Iteration 1500, Loss: 2.478222131729126\n",
      "Iteration 1600, Loss: 2.474684715270996\n",
      "Iteration 1700, Loss: 2.471280813217163\n",
      "Iteration 1800, Loss: 2.4685821533203125\n",
      "Iteration 1900, Loss: 2.465904712677002\n",
      "Iteration 2000, Loss: 2.4629249572753906\n",
      "Iteration 2100, Loss: 2.459444999694824\n",
      "Iteration 2200, Loss: 2.4584219455718994\n",
      "Iteration 2300, Loss: 2.455648422241211\n",
      "Iteration 2400, Loss: 2.453329563140869\n",
      "Iteration 2500, Loss: 2.4510767459869385\n",
      "Iteration 2600, Loss: 2.449260711669922\n",
      "Iteration 2700, Loss: 2.450683832168579\n",
      "Iteration 2800, Loss: 2.44563364982605\n",
      "Iteration 2900, Loss: 2.443814754486084\n",
      "Iteration 0, Loss: 3.0834391117095947\n",
      "Iteration 100, Loss: 2.938682794570923\n",
      "Iteration 200, Loss: 2.9116039276123047\n",
      "Iteration 300, Loss: 2.8891594409942627\n",
      "Iteration 400, Loss: 2.8725898265838623\n",
      "Iteration 500, Loss: 2.8585047721862793\n",
      "Iteration 600, Loss: 2.8486955165863037\n",
      "Iteration 700, Loss: 2.837869167327881\n",
      "Iteration 800, Loss: 2.831298351287842\n",
      "Iteration 900, Loss: 2.824166774749756\n",
      "Iteration 1000, Loss: 2.818732500076294\n",
      "Iteration 1100, Loss: 2.8153111934661865\n",
      "Iteration 1200, Loss: 2.8101727962493896\n",
      "Iteration 1300, Loss: 2.806180953979492\n",
      "Iteration 1400, Loss: 2.803877353668213\n",
      "Iteration 1500, Loss: 2.800212860107422\n",
      "Iteration 1600, Loss: 2.79753041267395\n",
      "Iteration 1700, Loss: 2.795790910720825\n",
      "Iteration 1800, Loss: 2.7920897006988525\n",
      "Iteration 1900, Loss: 2.789989471435547\n",
      "Iteration 2000, Loss: 2.7869372367858887\n",
      "Iteration 2100, Loss: 2.785090923309326\n",
      "Iteration 2200, Loss: 2.784757375717163\n",
      "Iteration 2300, Loss: 2.7817578315734863\n",
      "Iteration 2400, Loss: 2.780057191848755\n",
      "Iteration 2500, Loss: 2.7790896892547607\n",
      "Iteration 2600, Loss: 2.77614164352417\n",
      "Iteration 2700, Loss: 2.7742860317230225\n",
      "Iteration 2800, Loss: 2.773125410079956\n",
      "Iteration 2900, Loss: 2.779439687728882\n",
      "Iteration 0, Loss: 2.7500789165496826\n",
      "Iteration 100, Loss: 2.604987621307373\n",
      "Iteration 200, Loss: 2.584987163543701\n",
      "Iteration 300, Loss: 2.562256097793579\n",
      "Iteration 400, Loss: 2.543666362762451\n",
      "Iteration 500, Loss: 2.5291976928710938\n",
      "Iteration 600, Loss: 2.517631769180298\n",
      "Iteration 700, Loss: 2.5072386264801025\n",
      "Iteration 800, Loss: 2.498483657836914\n",
      "Iteration 900, Loss: 2.490521192550659\n",
      "Iteration 1000, Loss: 2.4836294651031494\n",
      "Iteration 1100, Loss: 2.477163076400757\n",
      "Iteration 1200, Loss: 2.4721412658691406\n",
      "Iteration 1300, Loss: 2.4666051864624023\n",
      "Iteration 1400, Loss: 2.4614596366882324\n",
      "Iteration 1500, Loss: 2.458142042160034\n",
      "Iteration 1600, Loss: 2.4541590213775635\n",
      "Iteration 1700, Loss: 2.451085090637207\n",
      "Iteration 1800, Loss: 2.447009563446045\n",
      "Iteration 1900, Loss: 2.4448556900024414\n",
      "Iteration 2000, Loss: 2.4422104358673096\n",
      "Iteration 2100, Loss: 2.439225435256958\n",
      "Iteration 2200, Loss: 2.435891628265381\n",
      "Iteration 2300, Loss: 2.433835983276367\n",
      "Iteration 2400, Loss: 2.4310286045074463\n",
      "Iteration 2500, Loss: 2.4300003051757812\n",
      "Iteration 2600, Loss: 2.427499532699585\n",
      "Iteration 2700, Loss: 2.4270646572113037\n",
      "Iteration 2800, Loss: 2.423692226409912\n",
      "Iteration 2900, Loss: 2.4219329357147217\n",
      "Iteration 0, Loss: 2.8290085792541504\n",
      "Iteration 100, Loss: 2.651811122894287\n",
      "Iteration 200, Loss: 2.6055221557617188\n",
      "Iteration 300, Loss: 2.580747127532959\n",
      "Iteration 400, Loss: 2.566887140274048\n",
      "Iteration 500, Loss: 2.5516762733459473\n",
      "Iteration 600, Loss: 2.5421817302703857\n",
      "Iteration 700, Loss: 2.5367918014526367\n",
      "Iteration 800, Loss: 2.5369908809661865\n",
      "Iteration 900, Loss: 2.522244691848755\n",
      "Iteration 1000, Loss: 2.5165951251983643\n",
      "Iteration 1100, Loss: 2.5136144161224365\n",
      "Iteration 1200, Loss: 2.5076634883880615\n",
      "Iteration 1300, Loss: 2.5037007331848145\n",
      "Iteration 1400, Loss: 2.4992403984069824\n",
      "Iteration 1500, Loss: 2.4962055683135986\n",
      "Iteration 1600, Loss: 2.4929656982421875\n",
      "Iteration 1700, Loss: 2.4912056922912598\n",
      "Iteration 1800, Loss: 2.4907476902008057\n",
      "Iteration 1900, Loss: 2.485764980316162\n",
      "Iteration 2000, Loss: 2.4831159114837646\n",
      "Iteration 2100, Loss: 2.4828691482543945\n",
      "Iteration 2200, Loss: 2.480013608932495\n",
      "Iteration 2300, Loss: 2.478564739227295\n",
      "Iteration 2400, Loss: 2.47617769241333\n",
      "Iteration 2500, Loss: 2.4741036891937256\n",
      "Iteration 2600, Loss: 2.472369909286499\n",
      "Iteration 2700, Loss: 2.4716579914093018\n",
      "Iteration 2800, Loss: 2.470078945159912\n",
      "Iteration 2900, Loss: 2.4677250385284424\n",
      "Iteration 0, Loss: 3.054147481918335\n",
      "Iteration 100, Loss: 2.9025912284851074\n",
      "Iteration 200, Loss: 2.862867832183838\n",
      "Iteration 300, Loss: 2.83699369430542\n",
      "Iteration 400, Loss: 2.819070339202881\n",
      "Iteration 500, Loss: 2.803788661956787\n",
      "Iteration 600, Loss: 2.7935571670532227\n",
      "Iteration 700, Loss: 2.7858223915100098\n",
      "Iteration 800, Loss: 2.7778637409210205\n",
      "Iteration 900, Loss: 2.771902322769165\n",
      "Iteration 1000, Loss: 2.7681615352630615\n",
      "Iteration 1100, Loss: 2.7619826793670654\n",
      "Iteration 1200, Loss: 2.7577016353607178\n",
      "Iteration 1300, Loss: 2.753782272338867\n",
      "Iteration 1400, Loss: 2.7497682571411133\n",
      "Iteration 1500, Loss: 2.7472355365753174\n",
      "Iteration 1600, Loss: 2.743945837020874\n",
      "Iteration 1700, Loss: 2.7418808937072754\n",
      "Iteration 1800, Loss: 2.7387280464172363\n",
      "Iteration 1900, Loss: 2.7381539344787598\n",
      "Iteration 2000, Loss: 2.7353129386901855\n",
      "Iteration 2100, Loss: 2.7336580753326416\n",
      "Iteration 2200, Loss: 2.73116397857666\n",
      "Iteration 2300, Loss: 2.730649948120117\n",
      "Iteration 2400, Loss: 2.7282705307006836\n",
      "Iteration 2500, Loss: 2.7265052795410156\n",
      "Iteration 2600, Loss: 2.7263731956481934\n",
      "Iteration 2700, Loss: 2.723975658416748\n",
      "Iteration 2800, Loss: 2.7231972217559814\n",
      "Iteration 2900, Loss: 2.7215800285339355\n",
      "Iteration 0, Loss: 2.72615385055542\n",
      "Iteration 100, Loss: 2.5614571571350098\n",
      "Iteration 200, Loss: 2.522477865219116\n",
      "Iteration 300, Loss: 2.5034284591674805\n",
      "Iteration 400, Loss: 2.483118772506714\n",
      "Iteration 500, Loss: 2.4826033115386963\n",
      "Iteration 600, Loss: 2.4657413959503174\n",
      "Iteration 700, Loss: 2.4544308185577393\n",
      "Iteration 800, Loss: 2.446474313735962\n",
      "Iteration 900, Loss: 2.4384031295776367\n",
      "Iteration 1000, Loss: 2.4350085258483887\n",
      "Iteration 1100, Loss: 2.4271535873413086\n",
      "Iteration 1200, Loss: 2.4445011615753174\n",
      "Iteration 1300, Loss: 2.4167723655700684\n",
      "Iteration 1400, Loss: 2.4131128787994385\n",
      "Iteration 1500, Loss: 2.4098174571990967\n",
      "Iteration 1600, Loss: 2.4059436321258545\n",
      "Iteration 1700, Loss: 2.4019265174865723\n",
      "Iteration 1800, Loss: 2.3984100818634033\n",
      "Iteration 1900, Loss: 2.3964905738830566\n",
      "Iteration 2000, Loss: 2.393040418624878\n",
      "Iteration 2100, Loss: 2.4187204837799072\n",
      "Iteration 2200, Loss: 2.3877131938934326\n",
      "Iteration 2300, Loss: 2.3872928619384766\n",
      "Iteration 2400, Loss: 2.3975837230682373\n",
      "Iteration 2500, Loss: 2.383512258529663\n",
      "Iteration 2600, Loss: 2.379877805709839\n",
      "Iteration 2700, Loss: 2.3770692348480225\n",
      "Iteration 2800, Loss: 2.3763351440429688\n",
      "Iteration 2900, Loss: 2.375354766845703\n",
      "Iteration 0, Loss: 2.6335415840148926\n",
      "Iteration 100, Loss: 2.4938032627105713\n",
      "Iteration 200, Loss: 2.510080337524414\n",
      "Iteration 300, Loss: 2.449958086013794\n",
      "Iteration 400, Loss: 2.4645495414733887\n",
      "Iteration 500, Loss: 2.423643112182617\n",
      "Iteration 600, Loss: 2.4063048362731934\n",
      "Iteration 700, Loss: 2.3925530910491943\n",
      "Iteration 800, Loss: 2.3808486461639404\n",
      "Iteration 900, Loss: 2.371628999710083\n",
      "Iteration 1000, Loss: 2.363004207611084\n",
      "Iteration 1100, Loss: 2.3582379817962646\n",
      "Iteration 1200, Loss: 2.353304147720337\n",
      "Iteration 1300, Loss: 2.3465235233306885\n",
      "Iteration 1400, Loss: 2.3385655879974365\n",
      "Iteration 1500, Loss: 2.3350396156311035\n",
      "Iteration 1600, Loss: 2.3320512771606445\n",
      "Iteration 1700, Loss: 2.3258559703826904\n",
      "Iteration 1800, Loss: 2.325110673904419\n",
      "Iteration 1900, Loss: 2.318969488143921\n",
      "Iteration 2000, Loss: 2.314502477645874\n",
      "Iteration 2100, Loss: 2.325580596923828\n",
      "Iteration 2200, Loss: 2.3087069988250732\n",
      "Iteration 2300, Loss: 2.3120367527008057\n",
      "Iteration 2400, Loss: 2.3030965328216553\n",
      "Iteration 2500, Loss: 2.30090069770813\n",
      "Iteration 2600, Loss: 2.300206184387207\n",
      "Iteration 2700, Loss: 2.2965197563171387\n",
      "Iteration 2800, Loss: 2.298617362976074\n",
      "Iteration 2900, Loss: 2.2933502197265625\n",
      "Iteration 0, Loss: 2.7182767391204834\n",
      "Iteration 100, Loss: 2.558117628097534\n",
      "Iteration 200, Loss: 2.5253117084503174\n",
      "Iteration 300, Loss: 2.5092530250549316\n",
      "Iteration 400, Loss: 2.4892454147338867\n",
      "Iteration 500, Loss: 2.473046064376831\n",
      "Iteration 600, Loss: 2.4649085998535156\n",
      "Iteration 700, Loss: 2.4487037658691406\n",
      "Iteration 800, Loss: 2.4437503814697266\n",
      "Iteration 900, Loss: 2.433870553970337\n",
      "Iteration 1000, Loss: 2.4282853603363037\n",
      "Iteration 1100, Loss: 2.4201643466949463\n",
      "Iteration 1200, Loss: 2.4161252975463867\n",
      "Iteration 1300, Loss: 2.410194158554077\n",
      "Iteration 1400, Loss: 2.4055302143096924\n",
      "Iteration 1500, Loss: 2.4009785652160645\n",
      "Iteration 1600, Loss: 2.397411823272705\n",
      "Iteration 1700, Loss: 2.3942151069641113\n",
      "Iteration 1800, Loss: 2.398311138153076\n",
      "Iteration 1900, Loss: 2.3879873752593994\n",
      "Iteration 2000, Loss: 2.38512921333313\n",
      "Iteration 2100, Loss: 2.3824849128723145\n",
      "Iteration 2200, Loss: 2.3802404403686523\n",
      "Iteration 2300, Loss: 2.378310441970825\n",
      "Iteration 2400, Loss: 2.375673294067383\n",
      "Iteration 2500, Loss: 2.3759050369262695\n",
      "Iteration 2600, Loss: 2.371825695037842\n",
      "Iteration 2700, Loss: 2.3802456855773926\n",
      "Iteration 2800, Loss: 2.3684120178222656\n",
      "Iteration 2900, Loss: 2.3662149906158447\n",
      "Iteration 0, Loss: 2.8477065563201904\n",
      "Iteration 100, Loss: 2.7223565578460693\n",
      "Iteration 200, Loss: 2.6647651195526123\n",
      "Iteration 300, Loss: 2.6401727199554443\n",
      "Iteration 400, Loss: 2.6216766834259033\n",
      "Iteration 500, Loss: 2.60762357711792\n",
      "Iteration 600, Loss: 2.596926689147949\n",
      "Iteration 700, Loss: 2.5879509449005127\n",
      "Iteration 800, Loss: 2.58161997795105\n",
      "Iteration 900, Loss: 2.5750198364257812\n",
      "Iteration 1000, Loss: 2.5712451934814453\n",
      "Iteration 1100, Loss: 2.563483476638794\n",
      "Iteration 1200, Loss: 2.559156894683838\n",
      "Iteration 1300, Loss: 2.5546820163726807\n",
      "Iteration 1400, Loss: 2.5505383014678955\n",
      "Iteration 1500, Loss: 2.548072099685669\n",
      "Iteration 1600, Loss: 2.5441601276397705\n",
      "Iteration 1700, Loss: 2.5452427864074707\n",
      "Iteration 1800, Loss: 2.53844952583313\n",
      "Iteration 1900, Loss: 2.535719633102417\n",
      "Iteration 2000, Loss: 2.5339467525482178\n",
      "Iteration 2100, Loss: 2.5311050415039062\n",
      "Iteration 2200, Loss: 2.5284721851348877\n",
      "Iteration 2300, Loss: 2.5270044803619385\n",
      "Iteration 2400, Loss: 2.5246331691741943\n",
      "Iteration 2500, Loss: 2.5223679542541504\n",
      "Iteration 2600, Loss: 2.5198190212249756\n",
      "Iteration 2700, Loss: 2.518862724304199\n",
      "Iteration 2800, Loss: 2.516319513320923\n",
      "Iteration 2900, Loss: 2.515180826187134\n",
      "Iteration 0, Loss: 2.8743362426757812\n",
      "Iteration 100, Loss: 2.7235333919525146\n",
      "Iteration 200, Loss: 2.6803226470947266\n",
      "Iteration 300, Loss: 2.664134979248047\n",
      "Iteration 400, Loss: 2.6439270973205566\n",
      "Iteration 500, Loss: 2.643679618835449\n",
      "Iteration 600, Loss: 2.6184287071228027\n",
      "Iteration 700, Loss: 2.621846914291382\n",
      "Iteration 800, Loss: 2.6039116382598877\n",
      "Iteration 900, Loss: 2.595996618270874\n",
      "Iteration 1000, Loss: 2.589909553527832\n",
      "Iteration 1100, Loss: 2.5844476222991943\n",
      "Iteration 1200, Loss: 2.582941770553589\n",
      "Iteration 1300, Loss: 2.5846996307373047\n",
      "Iteration 1400, Loss: 2.590398073196411\n",
      "Iteration 1500, Loss: 2.5681073665618896\n",
      "Iteration 1600, Loss: 2.565916061401367\n",
      "Iteration 1700, Loss: 2.56181263923645\n",
      "Iteration 1800, Loss: 2.5598466396331787\n",
      "Iteration 1900, Loss: 2.564951181411743\n",
      "Iteration 2000, Loss: 2.5664336681365967\n",
      "Iteration 2100, Loss: 2.5537538528442383\n",
      "Iteration 2200, Loss: 2.5506927967071533\n",
      "Iteration 2300, Loss: 2.5523970127105713\n",
      "Iteration 2400, Loss: 2.5472283363342285\n",
      "Iteration 2500, Loss: 2.5528571605682373\n",
      "Iteration 2600, Loss: 2.544987440109253\n",
      "Iteration 2700, Loss: 2.5452091693878174\n",
      "Iteration 2800, Loss: 2.541435718536377\n",
      "Iteration 2900, Loss: 2.541466474533081\n",
      "Iteration 0, Loss: 2.838355779647827\n",
      "Iteration 100, Loss: 2.6671347618103027\n",
      "Iteration 200, Loss: 2.631521701812744\n",
      "Iteration 300, Loss: 2.623002767562866\n",
      "Iteration 400, Loss: 2.6034491062164307\n",
      "Iteration 500, Loss: 2.589928150177002\n",
      "Iteration 600, Loss: 2.5806338787078857\n",
      "Iteration 700, Loss: 2.5705857276916504\n",
      "Iteration 800, Loss: 2.5606377124786377\n",
      "Iteration 900, Loss: 2.5545129776000977\n",
      "Iteration 1000, Loss: 2.547268867492676\n",
      "Iteration 1100, Loss: 2.5413153171539307\n",
      "Iteration 1200, Loss: 2.536299705505371\n",
      "Iteration 1300, Loss: 2.5325615406036377\n",
      "Iteration 1400, Loss: 2.5284583568573\n",
      "Iteration 1500, Loss: 2.5263209342956543\n",
      "Iteration 1600, Loss: 2.5225961208343506\n",
      "Iteration 1700, Loss: 2.5192337036132812\n",
      "Iteration 1800, Loss: 2.5174551010131836\n",
      "Iteration 1900, Loss: 2.514430046081543\n",
      "Iteration 2000, Loss: 2.5118961334228516\n",
      "Iteration 2100, Loss: 2.5098869800567627\n",
      "Iteration 2200, Loss: 2.5091514587402344\n",
      "Iteration 2300, Loss: 2.5061910152435303\n",
      "Iteration 2400, Loss: 2.5042688846588135\n",
      "Iteration 2500, Loss: 2.5022614002227783\n",
      "Iteration 2600, Loss: 2.5014679431915283\n",
      "Iteration 2700, Loss: 2.50052547454834\n",
      "Iteration 2800, Loss: 2.498258352279663\n",
      "Iteration 2900, Loss: 2.4960389137268066\n",
      "Iteration 0, Loss: 2.569035530090332\n",
      "Iteration 100, Loss: 2.481389045715332\n",
      "Iteration 200, Loss: 2.417692184448242\n",
      "Iteration 300, Loss: 2.385096311569214\n",
      "Iteration 400, Loss: 2.372401475906372\n",
      "Iteration 500, Loss: 2.3602442741394043\n",
      "Iteration 600, Loss: 2.3672266006469727\n",
      "Iteration 700, Loss: 2.3344786167144775\n",
      "Iteration 800, Loss: 2.3261878490448\n",
      "Iteration 900, Loss: 2.3198893070220947\n",
      "Iteration 1000, Loss: 2.3130595684051514\n",
      "Iteration 1100, Loss: 2.327815055847168\n",
      "Iteration 1200, Loss: 2.301285982131958\n",
      "Iteration 1300, Loss: 2.2987940311431885\n",
      "Iteration 1400, Loss: 2.290266513824463\n",
      "Iteration 1500, Loss: 2.326899290084839\n",
      "Iteration 1600, Loss: 2.287379264831543\n",
      "Iteration 1700, Loss: 2.2802202701568604\n",
      "Iteration 1800, Loss: 2.276782512664795\n",
      "Iteration 1900, Loss: 2.2713663578033447\n",
      "Iteration 2000, Loss: 2.2785134315490723\n",
      "Iteration 2100, Loss: 2.2690236568450928\n",
      "Iteration 2200, Loss: 2.270047664642334\n",
      "Iteration 2300, Loss: 2.2593870162963867\n",
      "Iteration 2400, Loss: 2.260852098464966\n",
      "Iteration 2500, Loss: 2.255596876144409\n",
      "Iteration 2600, Loss: 2.252896547317505\n",
      "Iteration 2700, Loss: 2.2509396076202393\n",
      "Iteration 2800, Loss: 2.2508387565612793\n",
      "Iteration 2900, Loss: 2.2497308254241943\n",
      "Iteration 0, Loss: 2.8514678478240967\n",
      "Iteration 100, Loss: 2.7014036178588867\n",
      "Iteration 200, Loss: 2.6568727493286133\n",
      "Iteration 300, Loss: 2.631387948989868\n",
      "Iteration 400, Loss: 2.612133741378784\n",
      "Iteration 500, Loss: 2.597726821899414\n",
      "Iteration 600, Loss: 2.5869791507720947\n",
      "Iteration 700, Loss: 2.5824615955352783\n",
      "Iteration 800, Loss: 2.5722243785858154\n",
      "Iteration 900, Loss: 2.5662221908569336\n",
      "Iteration 1000, Loss: 2.559715509414673\n",
      "Iteration 1100, Loss: 2.555211305618286\n",
      "Iteration 1200, Loss: 2.550968885421753\n",
      "Iteration 1300, Loss: 2.5475287437438965\n",
      "Iteration 1400, Loss: 2.5438015460968018\n",
      "Iteration 1500, Loss: 2.5405614376068115\n",
      "Iteration 1600, Loss: 2.5375120639801025\n",
      "Iteration 1700, Loss: 2.534011125564575\n",
      "Iteration 1800, Loss: 2.5310704708099365\n",
      "Iteration 1900, Loss: 2.5291059017181396\n",
      "Iteration 2000, Loss: 2.526198148727417\n",
      "Iteration 2100, Loss: 2.5235633850097656\n",
      "Iteration 2200, Loss: 2.5216410160064697\n",
      "Iteration 2300, Loss: 2.519214391708374\n",
      "Iteration 2400, Loss: 2.516798973083496\n",
      "Iteration 2500, Loss: 2.516073226928711\n",
      "Iteration 2600, Loss: 2.5136260986328125\n",
      "Iteration 2700, Loss: 2.512817859649658\n",
      "Iteration 2800, Loss: 2.5111324787139893\n",
      "Iteration 2900, Loss: 2.509444236755371\n",
      "Iteration 0, Loss: 2.9825284481048584\n",
      "Iteration 100, Loss: 2.812059164047241\n",
      "Iteration 200, Loss: 2.7721688747406006\n",
      "Iteration 300, Loss: 2.746612310409546\n",
      "Iteration 400, Loss: 2.7280874252319336\n",
      "Iteration 500, Loss: 2.7140889167785645\n",
      "Iteration 600, Loss: 2.7037296295166016\n",
      "Iteration 700, Loss: 2.700324058532715\n",
      "Iteration 800, Loss: 2.6874380111694336\n",
      "Iteration 900, Loss: 2.681729555130005\n",
      "Iteration 1000, Loss: 2.679077625274658\n",
      "Iteration 1100, Loss: 2.676121234893799\n",
      "Iteration 1200, Loss: 2.6686081886291504\n",
      "Iteration 1300, Loss: 2.6654164791107178\n",
      "Iteration 1400, Loss: 2.6625661849975586\n",
      "Iteration 1500, Loss: 2.6608073711395264\n",
      "Iteration 1600, Loss: 2.657825469970703\n",
      "Iteration 1700, Loss: 2.6550791263580322\n",
      "Iteration 1800, Loss: 2.6527903079986572\n",
      "Iteration 1900, Loss: 2.6518139839172363\n",
      "Iteration 2000, Loss: 2.6495237350463867\n",
      "Iteration 2100, Loss: 2.6501200199127197\n",
      "Iteration 2200, Loss: 2.644777774810791\n",
      "Iteration 2300, Loss: 2.6464626789093018\n",
      "Iteration 2400, Loss: 2.642862558364868\n",
      "Iteration 2500, Loss: 2.642289400100708\n",
      "Iteration 2600, Loss: 2.6392557621002197\n",
      "Iteration 2700, Loss: 2.637221336364746\n",
      "Iteration 2800, Loss: 2.636155605316162\n",
      "Iteration 2900, Loss: 2.635140895843506\n",
      "Iteration 0, Loss: 2.7525556087493896\n",
      "Iteration 100, Loss: 2.6127469539642334\n",
      "Iteration 200, Loss: 2.5680387020111084\n",
      "Iteration 300, Loss: 2.5438249111175537\n",
      "Iteration 400, Loss: 2.5254552364349365\n",
      "Iteration 500, Loss: 2.5118486881256104\n",
      "Iteration 600, Loss: 2.5006871223449707\n",
      "Iteration 700, Loss: 2.493781328201294\n",
      "Iteration 800, Loss: 2.4946110248565674\n",
      "Iteration 900, Loss: 2.479860544204712\n",
      "Iteration 1000, Loss: 2.477965831756592\n",
      "Iteration 1100, Loss: 2.4789040088653564\n",
      "Iteration 1200, Loss: 2.4699935913085938\n",
      "Iteration 1300, Loss: 2.4594132900238037\n",
      "Iteration 1400, Loss: 2.456575632095337\n",
      "Iteration 1500, Loss: 2.4619274139404297\n",
      "Iteration 1600, Loss: 2.44930362701416\n",
      "Iteration 1700, Loss: 2.4479751586914062\n",
      "Iteration 1800, Loss: 2.443676710128784\n",
      "Iteration 1900, Loss: 2.4394404888153076\n",
      "Iteration 2000, Loss: 2.4368250370025635\n",
      "Iteration 2100, Loss: 2.4361984729766846\n",
      "Iteration 2200, Loss: 2.433671236038208\n",
      "Iteration 2300, Loss: 2.4332008361816406\n",
      "Iteration 2400, Loss: 2.4294140338897705\n",
      "Iteration 2500, Loss: 2.4272212982177734\n",
      "Iteration 2600, Loss: 2.4249346256256104\n",
      "Iteration 2700, Loss: 2.4240171909332275\n",
      "Iteration 2800, Loss: 2.423109292984009\n",
      "Iteration 2900, Loss: 2.4203109741210938\n",
      "Iteration 0, Loss: 2.742504119873047\n",
      "Iteration 100, Loss: 2.561589241027832\n",
      "Iteration 200, Loss: 2.5237860679626465\n",
      "Iteration 300, Loss: 2.4986236095428467\n",
      "Iteration 400, Loss: 2.483154296875\n",
      "Iteration 500, Loss: 2.4720990657806396\n",
      "Iteration 600, Loss: 2.4589200019836426\n",
      "Iteration 700, Loss: 2.449185848236084\n",
      "Iteration 800, Loss: 2.4420790672302246\n",
      "Iteration 900, Loss: 2.4346811771392822\n",
      "Iteration 1000, Loss: 2.4291656017303467\n",
      "Iteration 1100, Loss: 2.425783634185791\n",
      "Iteration 1200, Loss: 2.4202122688293457\n",
      "Iteration 1300, Loss: 2.4152159690856934\n",
      "Iteration 1400, Loss: 2.4125046730041504\n",
      "Iteration 1500, Loss: 2.4094815254211426\n",
      "Iteration 1600, Loss: 2.4058597087860107\n",
      "Iteration 1700, Loss: 2.4032366275787354\n",
      "Iteration 1800, Loss: 2.400730609893799\n",
      "Iteration 1900, Loss: 2.3979809284210205\n",
      "Iteration 2000, Loss: 2.395087480545044\n",
      "Iteration 2100, Loss: 2.398012161254883\n",
      "Iteration 2200, Loss: 2.3917179107666016\n",
      "Iteration 2300, Loss: 2.389678955078125\n",
      "Iteration 2400, Loss: 2.3899598121643066\n",
      "Iteration 2500, Loss: 2.3861641883850098\n",
      "Iteration 2600, Loss: 2.3880727291107178\n",
      "Iteration 2700, Loss: 2.384425640106201\n",
      "Iteration 2800, Loss: 2.3822238445281982\n",
      "Iteration 2900, Loss: 2.380610704421997\n",
      "Iteration 0, Loss: 2.8467676639556885\n",
      "Iteration 100, Loss: 2.671154260635376\n",
      "Iteration 200, Loss: 2.627016544342041\n",
      "Iteration 300, Loss: 2.6055872440338135\n",
      "Iteration 400, Loss: 2.586136817932129\n",
      "Iteration 500, Loss: 2.573505163192749\n",
      "Iteration 600, Loss: 2.5627665519714355\n",
      "Iteration 700, Loss: 2.5546700954437256\n",
      "Iteration 800, Loss: 2.5492584705352783\n",
      "Iteration 900, Loss: 2.542163372039795\n",
      "Iteration 1000, Loss: 2.5385303497314453\n",
      "Iteration 1100, Loss: 2.532972574234009\n",
      "Iteration 1200, Loss: 2.529747724533081\n",
      "Iteration 1300, Loss: 2.526031255722046\n",
      "Iteration 1400, Loss: 2.5220134258270264\n",
      "Iteration 1500, Loss: 2.5190069675445557\n",
      "Iteration 1600, Loss: 2.5171568393707275\n",
      "Iteration 1700, Loss: 2.516160011291504\n",
      "Iteration 1800, Loss: 2.5118463039398193\n",
      "Iteration 1900, Loss: 2.509688138961792\n",
      "Iteration 2000, Loss: 2.5084328651428223\n",
      "Iteration 2100, Loss: 2.50557279586792\n",
      "Iteration 2200, Loss: 2.509779691696167\n",
      "Iteration 2300, Loss: 2.5030293464660645\n",
      "Iteration 2400, Loss: 2.500591993331909\n",
      "Iteration 2500, Loss: 2.4989326000213623\n",
      "Iteration 2600, Loss: 2.498497247695923\n",
      "Iteration 2700, Loss: 2.496769428253174\n",
      "Iteration 2800, Loss: 2.495603322982788\n",
      "Iteration 2900, Loss: 2.494013786315918\n",
      "Iteration 0, Loss: 2.8412163257598877\n",
      "Iteration 100, Loss: 2.67655611038208\n",
      "Iteration 200, Loss: 2.632035493850708\n",
      "Iteration 300, Loss: 2.6051576137542725\n",
      "Iteration 400, Loss: 2.585616111755371\n",
      "Iteration 500, Loss: 2.571791172027588\n",
      "Iteration 600, Loss: 2.5617599487304688\n",
      "Iteration 700, Loss: 2.5534958839416504\n",
      "Iteration 800, Loss: 2.5467469692230225\n",
      "Iteration 900, Loss: 2.5400514602661133\n",
      "Iteration 1000, Loss: 2.5353517532348633\n",
      "Iteration 1100, Loss: 2.530749797821045\n",
      "Iteration 1200, Loss: 2.5267930030822754\n",
      "Iteration 1300, Loss: 2.5221898555755615\n",
      "Iteration 1400, Loss: 2.517242193222046\n",
      "Iteration 1500, Loss: 2.514622926712036\n",
      "Iteration 1600, Loss: 2.512110471725464\n",
      "Iteration 1700, Loss: 2.509009838104248\n",
      "Iteration 1800, Loss: 2.506439447402954\n",
      "Iteration 1900, Loss: 2.504983901977539\n",
      "Iteration 2000, Loss: 2.5021398067474365\n",
      "Iteration 2100, Loss: 2.4997050762176514\n",
      "Iteration 2200, Loss: 2.498044013977051\n",
      "Iteration 2300, Loss: 2.4961302280426025\n",
      "Iteration 2400, Loss: 2.494218111038208\n",
      "Iteration 2500, Loss: 2.4931349754333496\n",
      "Iteration 2600, Loss: 2.490839719772339\n",
      "Iteration 2700, Loss: 2.490679979324341\n",
      "Iteration 2800, Loss: 2.4886715412139893\n",
      "Iteration 2900, Loss: 2.4875218868255615\n",
      "Iteration 0, Loss: 2.8726630210876465\n",
      "Iteration 100, Loss: 2.732781171798706\n",
      "Iteration 200, Loss: 2.7211480140686035\n",
      "Iteration 300, Loss: 2.6868700981140137\n",
      "Iteration 400, Loss: 2.6645965576171875\n",
      "Iteration 500, Loss: 2.646054267883301\n",
      "Iteration 600, Loss: 2.630692958831787\n",
      "Iteration 700, Loss: 2.6184489727020264\n",
      "Iteration 800, Loss: 2.607288122177124\n",
      "Iteration 900, Loss: 2.5970420837402344\n",
      "Iteration 1000, Loss: 2.5884244441986084\n",
      "Iteration 1100, Loss: 2.580944776535034\n",
      "Iteration 1200, Loss: 2.5749130249023438\n",
      "Iteration 1300, Loss: 2.569476842880249\n",
      "Iteration 1400, Loss: 2.565001964569092\n",
      "Iteration 1500, Loss: 2.5604968070983887\n",
      "Iteration 1600, Loss: 2.557249069213867\n",
      "Iteration 1700, Loss: 2.553576707839966\n",
      "Iteration 1800, Loss: 2.550569772720337\n",
      "Iteration 1900, Loss: 2.5478920936584473\n",
      "Iteration 2000, Loss: 2.545811414718628\n",
      "Iteration 2100, Loss: 2.541715383529663\n",
      "Iteration 2200, Loss: 2.5401089191436768\n",
      "Iteration 2300, Loss: 2.537482976913452\n",
      "Iteration 2400, Loss: 2.5353500843048096\n",
      "Iteration 2500, Loss: 2.5337302684783936\n",
      "Iteration 2600, Loss: 2.5312230587005615\n",
      "Iteration 2700, Loss: 2.5296530723571777\n",
      "Iteration 2800, Loss: 2.5289785861968994\n",
      "Iteration 2900, Loss: 2.5275259017944336\n",
      "Iteration 0, Loss: 2.807292938232422\n",
      "Iteration 100, Loss: 2.648406744003296\n",
      "Iteration 200, Loss: 2.6110074520111084\n",
      "Iteration 300, Loss: 2.5859525203704834\n",
      "Iteration 400, Loss: 2.56608510017395\n",
      "Iteration 500, Loss: 2.552565336227417\n",
      "Iteration 600, Loss: 2.5451133251190186\n",
      "Iteration 700, Loss: 2.5327489376068115\n",
      "Iteration 800, Loss: 2.5247879028320312\n",
      "Iteration 900, Loss: 2.5189473628997803\n",
      "Iteration 1000, Loss: 2.516347646713257\n",
      "Iteration 1100, Loss: 2.509967803955078\n",
      "Iteration 1200, Loss: 2.511892080307007\n",
      "Iteration 1300, Loss: 2.502178907394409\n",
      "Iteration 1400, Loss: 2.5065858364105225\n",
      "Iteration 1500, Loss: 2.4956705570220947\n",
      "Iteration 1600, Loss: 2.495560884475708\n",
      "Iteration 1700, Loss: 2.4923837184906006\n",
      "Iteration 1800, Loss: 2.489546060562134\n",
      "Iteration 1900, Loss: 2.486637830734253\n",
      "Iteration 2000, Loss: 2.4836483001708984\n",
      "Iteration 2100, Loss: 2.491276502609253\n",
      "Iteration 2200, Loss: 2.479706048965454\n",
      "Iteration 2300, Loss: 2.4780120849609375\n",
      "Iteration 2400, Loss: 2.476980447769165\n",
      "Iteration 2500, Loss: 2.477259874343872\n",
      "Iteration 2600, Loss: 2.473126173019409\n",
      "Iteration 2700, Loss: 2.478895664215088\n",
      "Iteration 2800, Loss: 2.4703433513641357\n",
      "Iteration 2900, Loss: 2.4687538146972656\n",
      "Iteration 0, Loss: 3.1195783615112305\n",
      "Iteration 100, Loss: 3.0059573650360107\n",
      "Iteration 200, Loss: 2.9423422813415527\n",
      "Iteration 300, Loss: 2.928809642791748\n",
      "Iteration 400, Loss: 2.9075286388397217\n",
      "Iteration 500, Loss: 2.8948872089385986\n",
      "Iteration 600, Loss: 2.895176887512207\n",
      "Iteration 700, Loss: 2.874135971069336\n",
      "Iteration 800, Loss: 2.8670289516448975\n",
      "Iteration 900, Loss: 2.860065221786499\n",
      "Iteration 1000, Loss: 2.8561038970947266\n",
      "Iteration 1100, Loss: 2.8517167568206787\n",
      "Iteration 1200, Loss: 2.845770835876465\n",
      "Iteration 1300, Loss: 2.8393237590789795\n",
      "Iteration 1400, Loss: 2.8341476917266846\n",
      "Iteration 1500, Loss: 2.831469774246216\n",
      "Iteration 1600, Loss: 2.826857089996338\n",
      "Iteration 1700, Loss: 2.8230485916137695\n",
      "Iteration 1800, Loss: 2.8197567462921143\n",
      "Iteration 1900, Loss: 2.816941499710083\n",
      "Iteration 2000, Loss: 2.8145158290863037\n",
      "Iteration 2100, Loss: 2.8109984397888184\n",
      "Iteration 2200, Loss: 2.808974504470825\n",
      "Iteration 2300, Loss: 2.8062427043914795\n",
      "Iteration 2400, Loss: 2.8039889335632324\n",
      "Iteration 2500, Loss: 2.8025128841400146\n",
      "Iteration 2600, Loss: 2.8149452209472656\n",
      "Iteration 2700, Loss: 2.7979183197021484\n",
      "Iteration 2800, Loss: 2.7970523834228516\n",
      "Iteration 2900, Loss: 2.7955589294433594\n",
      "Iteration 0, Loss: 2.6428918838500977\n",
      "Iteration 100, Loss: 2.5073723793029785\n",
      "Iteration 200, Loss: 2.530116558074951\n",
      "Iteration 300, Loss: 2.4344482421875\n",
      "Iteration 400, Loss: 2.4104514122009277\n",
      "Iteration 500, Loss: 2.394944190979004\n",
      "Iteration 600, Loss: 2.3824398517608643\n",
      "Iteration 700, Loss: 2.3733808994293213\n",
      "Iteration 800, Loss: 2.3659825325012207\n",
      "Iteration 900, Loss: 2.3590850830078125\n",
      "Iteration 1000, Loss: 2.3550093173980713\n",
      "Iteration 1100, Loss: 2.347710132598877\n",
      "Iteration 1200, Loss: 2.3451430797576904\n",
      "Iteration 1300, Loss: 2.3386917114257812\n",
      "Iteration 1400, Loss: 2.336517333984375\n",
      "Iteration 1500, Loss: 2.3315088748931885\n",
      "Iteration 1600, Loss: 2.329878330230713\n",
      "Iteration 1700, Loss: 2.326307773590088\n",
      "Iteration 1800, Loss: 2.3224689960479736\n",
      "Iteration 1900, Loss: 2.3297131061553955\n",
      "Iteration 2000, Loss: 2.3183224201202393\n",
      "Iteration 2100, Loss: 2.31606388092041\n",
      "Iteration 2200, Loss: 2.31242299079895\n",
      "Iteration 2300, Loss: 2.312204599380493\n",
      "Iteration 2400, Loss: 2.3092041015625\n",
      "Iteration 2500, Loss: 2.3102705478668213\n",
      "Iteration 2600, Loss: 2.3054685592651367\n",
      "Iteration 2700, Loss: 2.312628984451294\n",
      "Iteration 2800, Loss: 2.3026585578918457\n",
      "Iteration 2900, Loss: 2.299684762954712\n",
      "Iteration 0, Loss: 2.741244077682495\n",
      "Iteration 100, Loss: 2.599275588989258\n",
      "Iteration 200, Loss: 2.584988594055176\n",
      "Iteration 300, Loss: 2.552565336227417\n",
      "Iteration 400, Loss: 2.533348321914673\n",
      "Iteration 500, Loss: 2.5194523334503174\n",
      "Iteration 600, Loss: 2.5065085887908936\n",
      "Iteration 700, Loss: 2.495979070663452\n",
      "Iteration 800, Loss: 2.4878647327423096\n",
      "Iteration 900, Loss: 2.478623151779175\n",
      "Iteration 1000, Loss: 2.472912311553955\n",
      "Iteration 1100, Loss: 2.4657065868377686\n",
      "Iteration 1200, Loss: 2.460543155670166\n",
      "Iteration 1300, Loss: 2.4558143615722656\n",
      "Iteration 1400, Loss: 2.4538087844848633\n",
      "Iteration 1500, Loss: 2.4559285640716553\n",
      "Iteration 1600, Loss: 2.443117141723633\n",
      "Iteration 1700, Loss: 2.460571050643921\n",
      "Iteration 1800, Loss: 2.4365973472595215\n",
      "Iteration 1900, Loss: 2.4429166316986084\n",
      "Iteration 2000, Loss: 2.4478085041046143\n",
      "Iteration 2100, Loss: 2.436959743499756\n",
      "Iteration 2200, Loss: 2.4273085594177246\n",
      "Iteration 2300, Loss: 2.4233222007751465\n",
      "Iteration 2400, Loss: 2.421236991882324\n",
      "Iteration 2500, Loss: 2.420226573944092\n",
      "Iteration 2600, Loss: 2.4266560077667236\n",
      "Iteration 2700, Loss: 2.4141972064971924\n",
      "Iteration 2800, Loss: 2.4121429920196533\n",
      "Iteration 2900, Loss: 2.4101996421813965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin.mat')['XA']\n",
    "\n",
    "C_on_perm=np.empty([Xall.shape[0],Xall.shape[0],50])\n",
    "loss_on_perm=np.zeros((50))\n",
    "angpermscore=np.zeros((50))\n",
    "for perm in range(50):\n",
    "    Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin.mat')['XA']\n",
    "    Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_fullwin.mat')['YA']\n",
    "\n",
    "    X=torch.from_numpy(np.float32(Xall))\n",
    "    n = X.size(0)\n",
    "\n",
    "    #apply rotation using random skew symmetric orthogonal transform\n",
    "    Aa=np.random.randn(n,n)\n",
    "    Yall=cayley_numpy(Aa-Aa.T)*Yall * scipy.linalg.inv(cayley_numpy(Aa-Aa.T))\n",
    "\n",
    "    Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "    # Initialize a skew-symmetric matrix A\n",
    "\n",
    "    A = torch.randn((n, n), requires_grad=True)\n",
    "    A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "    # Use ADAM optimizer\n",
    "    optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "        C = cayley_transform(A)\n",
    "        loss = loss_function(X, Y, C)\n",
    "\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update A using gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "    # Final optimized C\n",
    "    C_perm = cayley_transform(A)\n",
    "    C_perm=C_perm.detach().numpy()\n",
    "    C_on_perm[:,:,perm]=C_perm\n",
    "    losstmp = loss.detach().numpy()\n",
    "    loss_on_perm[perm]=losstmp\n",
    "\n",
    "    #compute angular\n",
    "    num = np.trace(X.detach().numpy().T @ C_perm @ Y.detach().numpy() @ np.linalg.inv(C_perm))\n",
    "\n",
    "\n",
    "    denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "    denom=denom.detach().numpy()\n",
    "    angpermscore[perm] = np.cos(np.arccos(num/denom))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin.mat')['XA']\n",
    "Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_fullwin.mat')['YA']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mdic = {'optimizedC':[C_optimized],'optoloss':[Optimized_loss],'angularoptimal': [angoptimalscore],'loss_on_perm_random': [loss_on_perm],'C_on_perm' : [C_on_perm],'angperscore': [angpermscore],'XA':[Xall],'YA':[Yall]}\n",
    "savemat(DataFold+'/C_optimized_full_dmd_full_win_ACC.mat',mdic)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perm with eigen maintained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now do DSA in PMD with A~ high components models with ncomps=197 (80% variance in PODs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 2.9436275959014893\n",
      "Iteration 100, Loss: 2.3967959880828857\n",
      "Iteration 200, Loss: 2.28698468208313\n",
      "Iteration 300, Loss: 2.1588640213012695\n",
      "Iteration 400, Loss: 2.0603926181793213\n",
      "Iteration 500, Loss: 1.9848281145095825\n",
      "Iteration 600, Loss: 1.9109870195388794\n",
      "Iteration 700, Loss: 1.8531900644302368\n",
      "Iteration 800, Loss: 1.799070954322815\n",
      "Iteration 900, Loss: 1.75983464717865\n",
      "Iteration 1000, Loss: 1.7113656997680664\n",
      "Iteration 1100, Loss: 1.6736339330673218\n",
      "Iteration 1200, Loss: 1.6380637884140015\n",
      "Iteration 1300, Loss: 1.617935061454773\n",
      "Iteration 1400, Loss: 1.5723769664764404\n",
      "Iteration 1500, Loss: 1.5464047193527222\n",
      "Iteration 1600, Loss: 1.528183937072754\n",
      "Iteration 1700, Loss: 1.4933598041534424\n",
      "Iteration 1800, Loss: 1.471987247467041\n",
      "Iteration 1900, Loss: 1.454038381576538\n",
      "Iteration 2000, Loss: 1.4329756498336792\n",
      "Iteration 2100, Loss: 1.410189151763916\n",
      "Iteration 2200, Loss: 1.3932673931121826\n",
      "Iteration 2300, Loss: 1.3697278499603271\n",
      "Iteration 2400, Loss: 1.3575644493103027\n",
      "Iteration 2500, Loss: 1.338990569114685\n",
      "Iteration 2600, Loss: 1.323287010192871\n",
      "Iteration 2700, Loss: 1.3109649419784546\n",
      "Iteration 2800, Loss: 1.298887014389038\n",
      "Iteration 2900, Loss: 1.2845664024353027\n"
     ]
    }
   ],
   "source": [
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin_pmd.mat')['XA']\n",
    "Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_fullwin_pmd.mat')['YA']\n",
    "\n",
    "\n",
    "X=torch.from_numpy(np.float32(Xall))\n",
    "Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "\n",
    "max_iterations=3000\n",
    "\n",
    "n = X.size(0)\n",
    "\n",
    "# Initialize a skew-symmetric matrix A\n",
    "\n",
    "A = torch.randn((n, n), requires_grad=True)\n",
    "A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "# Use ADAM optimizer\n",
    "optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "    C = cayley_transform(A)\n",
    "    loss = loss_function(X, Y, C)\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update A using gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration % 100 == 0:\n",
    "        print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "# Final optimized C\n",
    "C_optimized = cayley_transform(A)\n",
    "C_optimized=C_optimized.detach().numpy()\n",
    "Optimized_loss=loss.detach().numpy()\n",
    "\n",
    "#compute angular\n",
    "num = np.trace(X.detach().numpy().T @ C_optimized @ Y.detach().numpy() @ np.linalg.inv(C_optimized))\n",
    "\n",
    "\n",
    "denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "denom=denom.detach().numpy()\n",
    "angoptimalscore = np.cos(np.arccos(num/denom))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do perm DSA with PMD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 3.1339266300201416\n",
      "Iteration 100, Loss: 3.0806498527526855\n",
      "Iteration 200, Loss: 3.1003472805023193\n",
      "Iteration 300, Loss: 3.0249555110931396\n",
      "Iteration 400, Loss: 3.080049753189087\n",
      "Iteration 500, Loss: 3.0962111949920654\n",
      "Iteration 600, Loss: 3.0913684368133545\n",
      "Iteration 700, Loss: 2.977271556854248\n",
      "Iteration 800, Loss: 3.0038652420043945\n",
      "Iteration 900, Loss: 2.924264669418335\n",
      "Iteration 1000, Loss: 3.0446360111236572\n",
      "Iteration 1100, Loss: 2.935485363006592\n",
      "Iteration 1200, Loss: 2.899998188018799\n",
      "Iteration 1300, Loss: 3.087583065032959\n",
      "Iteration 1400, Loss: 3.0119309425354004\n",
      "Iteration 1500, Loss: 3.077054500579834\n",
      "Iteration 1600, Loss: 3.0077450275421143\n",
      "Iteration 1700, Loss: 3.069413900375366\n",
      "Iteration 1800, Loss: 3.00087571144104\n",
      "Iteration 1900, Loss: 3.0880911350250244\n",
      "Iteration 2000, Loss: 3.071841239929199\n",
      "Iteration 2100, Loss: 3.040009021759033\n",
      "Iteration 2200, Loss: 2.987030029296875\n",
      "Iteration 2300, Loss: 3.050919771194458\n",
      "Iteration 2400, Loss: 2.948763847351074\n",
      "Iteration 2500, Loss: 2.906719923019409\n",
      "Iteration 2600, Loss: 2.9985342025756836\n",
      "Iteration 2700, Loss: 2.8878061771392822\n",
      "Iteration 2800, Loss: 2.8701393604278564\n",
      "Iteration 2900, Loss: 2.856815814971924\n",
      "Iteration 0, Loss: 3.163538694381714\n",
      "Iteration 100, Loss: 3.0489115715026855\n",
      "Iteration 200, Loss: 2.9968411922454834\n",
      "Iteration 300, Loss: 3.0701630115509033\n",
      "Iteration 400, Loss: 2.981799602508545\n",
      "Iteration 500, Loss: 2.9566702842712402\n",
      "Iteration 600, Loss: 2.942647695541382\n",
      "Iteration 700, Loss: 2.9321303367614746\n",
      "Iteration 800, Loss: 2.923144817352295\n",
      "Iteration 900, Loss: 2.9150280952453613\n",
      "Iteration 1000, Loss: 2.9083151817321777\n",
      "Iteration 1100, Loss: 2.899984121322632\n",
      "Iteration 1200, Loss: 3.0316824913024902\n",
      "Iteration 1300, Loss: 2.909677028656006\n",
      "Iteration 1400, Loss: 2.8891875743865967\n",
      "Iteration 1500, Loss: 2.8795266151428223\n",
      "Iteration 1600, Loss: 2.8718390464782715\n",
      "Iteration 1700, Loss: 2.866893768310547\n",
      "Iteration 1800, Loss: 2.857997417449951\n",
      "Iteration 1900, Loss: 2.862966537475586\n",
      "Iteration 2000, Loss: 2.8773090839385986\n",
      "Iteration 2100, Loss: 2.846874475479126\n",
      "Iteration 2200, Loss: 2.969578266143799\n",
      "Iteration 2300, Loss: 2.848264694213867\n",
      "Iteration 2400, Loss: 2.835151195526123\n",
      "Iteration 2500, Loss: 2.8246805667877197\n",
      "Iteration 2600, Loss: 3.0103273391723633\n",
      "Iteration 2700, Loss: 2.83079195022583\n",
      "Iteration 2800, Loss: 2.8236284255981445\n",
      "Iteration 2900, Loss: 2.8147940635681152\n",
      "Iteration 0, Loss: 3.2201125621795654\n",
      "Iteration 100, Loss: 3.1801960468292236\n",
      "Iteration 200, Loss: 3.153785467147827\n",
      "Iteration 300, Loss: 3.1898818016052246\n",
      "Iteration 400, Loss: 3.1774230003356934\n",
      "Iteration 500, Loss: 3.1460773944854736\n",
      "Iteration 600, Loss: 3.1107616424560547\n",
      "Iteration 700, Loss: 3.0793678760528564\n",
      "Iteration 800, Loss: 3.1539993286132812\n",
      "Iteration 900, Loss: 3.0670759677886963\n",
      "Iteration 1000, Loss: 3.040288209915161\n",
      "Iteration 1100, Loss: 3.0218398571014404\n",
      "Iteration 1200, Loss: 3.0452053546905518\n",
      "Iteration 1300, Loss: 3.011531114578247\n",
      "Iteration 1400, Loss: 3.1332266330718994\n",
      "Iteration 1500, Loss: 2.993422508239746\n",
      "Iteration 1600, Loss: 3.1803855895996094\n",
      "Iteration 1700, Loss: 3.1698551177978516\n",
      "Iteration 1800, Loss: 3.1586410999298096\n",
      "Iteration 1900, Loss: 3.1451690196990967\n",
      "Iteration 2000, Loss: 3.1325137615203857\n",
      "Iteration 2100, Loss: 3.1229286193847656\n",
      "Iteration 2200, Loss: 3.115466833114624\n",
      "Iteration 2300, Loss: 3.1092333793640137\n",
      "Iteration 2400, Loss: 3.1037495136260986\n",
      "Iteration 2500, Loss: 3.098656415939331\n",
      "Iteration 2600, Loss: 3.093764066696167\n",
      "Iteration 2700, Loss: 3.0889952182769775\n",
      "Iteration 2800, Loss: 3.084320068359375\n",
      "Iteration 2900, Loss: 3.079725503921509\n",
      "Iteration 0, Loss: 3.364309310913086\n",
      "Iteration 100, Loss: 3.317065715789795\n",
      "Iteration 200, Loss: 3.2534942626953125\n",
      "Iteration 300, Loss: 3.197510242462158\n",
      "Iteration 400, Loss: 3.3401613235473633\n",
      "Iteration 500, Loss: 3.3379969596862793\n",
      "Iteration 600, Loss: 3.336042881011963\n",
      "Iteration 700, Loss: 3.3339343070983887\n",
      "Iteration 800, Loss: 3.3312811851501465\n",
      "Iteration 900, Loss: 3.327359437942505\n",
      "Iteration 1000, Loss: 3.32128643989563\n",
      "Iteration 1100, Loss: 3.3153018951416016\n",
      "Iteration 1200, Loss: 3.3106181621551514\n",
      "Iteration 1300, Loss: 3.3066961765289307\n",
      "Iteration 1400, Loss: 3.303093194961548\n",
      "Iteration 1500, Loss: 3.2996394634246826\n",
      "Iteration 1600, Loss: 3.296264886856079\n",
      "Iteration 1700, Loss: 3.292935371398926\n",
      "Iteration 1800, Loss: 3.289628267288208\n",
      "Iteration 1900, Loss: 3.2863147258758545\n",
      "Iteration 2000, Loss: 3.282972812652588\n",
      "Iteration 2100, Loss: 3.2795815467834473\n",
      "Iteration 2200, Loss: 3.2761199474334717\n",
      "Iteration 2300, Loss: 3.2725701332092285\n",
      "Iteration 2400, Loss: 3.268916130065918\n",
      "Iteration 2500, Loss: 3.265141487121582\n",
      "Iteration 2600, Loss: 3.2612340450286865\n",
      "Iteration 2700, Loss: 3.257185935974121\n",
      "Iteration 2800, Loss: 3.2529900074005127\n",
      "Iteration 2900, Loss: 3.2486422061920166\n",
      "Iteration 0, Loss: 3.3652429580688477\n",
      "Iteration 100, Loss: 3.2179620265960693\n",
      "Iteration 200, Loss: 3.3399364948272705\n",
      "Iteration 300, Loss: 3.331730365753174\n",
      "Iteration 400, Loss: 3.29372501373291\n",
      "Iteration 500, Loss: 3.2291910648345947\n",
      "Iteration 600, Loss: 3.33473539352417\n",
      "Iteration 700, Loss: 3.3303472995758057\n",
      "Iteration 800, Loss: 3.3252439498901367\n",
      "Iteration 900, Loss: 3.3179550170898438\n",
      "Iteration 1000, Loss: 3.307506561279297\n",
      "Iteration 1100, Loss: 3.291729211807251\n",
      "Iteration 1200, Loss: 3.2680530548095703\n",
      "Iteration 1300, Loss: 3.2360033988952637\n",
      "Iteration 1400, Loss: 3.299234390258789\n",
      "Iteration 1500, Loss: 3.256260395050049\n",
      "Iteration 1600, Loss: 3.2097835540771484\n",
      "Iteration 1700, Loss: 3.3165123462677\n",
      "Iteration 1800, Loss: 3.2654173374176025\n",
      "Iteration 1900, Loss: 3.2115139961242676\n",
      "Iteration 2000, Loss: 3.1749188899993896\n",
      "Iteration 2100, Loss: 3.215902805328369\n",
      "Iteration 2200, Loss: 3.135477304458618\n",
      "Iteration 2300, Loss: 3.3056695461273193\n",
      "Iteration 2400, Loss: 3.2760236263275146\n",
      "Iteration 2500, Loss: 3.1922831535339355\n",
      "Iteration 2600, Loss: 3.1390061378479004\n",
      "Iteration 2700, Loss: 3.116600751876831\n",
      "Iteration 2800, Loss: 3.19058895111084\n",
      "Iteration 2900, Loss: 3.1249635219573975\n",
      "Iteration 0, Loss: 3.3330585956573486\n",
      "Iteration 100, Loss: 3.2622992992401123\n",
      "Iteration 200, Loss: 3.283567428588867\n",
      "Iteration 300, Loss: 3.1373543739318848\n",
      "Iteration 400, Loss: 3.2394330501556396\n",
      "Iteration 500, Loss: 3.2942633628845215\n",
      "Iteration 600, Loss: 3.1396007537841797\n",
      "Iteration 700, Loss: 3.2744405269622803\n",
      "Iteration 800, Loss: 3.190131425857544\n",
      "Iteration 900, Loss: 3.1735031604766846\n",
      "Iteration 1000, Loss: 3.166440725326538\n",
      "Iteration 1100, Loss: 3.1610546112060547\n",
      "Iteration 1200, Loss: 3.15628981590271\n",
      "Iteration 1300, Loss: 3.151810646057129\n",
      "Iteration 1400, Loss: 3.1474926471710205\n",
      "Iteration 1500, Loss: 3.1432838439941406\n",
      "Iteration 1600, Loss: 3.1391806602478027\n",
      "Iteration 1700, Loss: 3.135207176208496\n",
      "Iteration 1800, Loss: 3.131401777267456\n",
      "Iteration 1900, Loss: 3.1278932094573975\n",
      "Iteration 2000, Loss: 3.124641180038452\n",
      "Iteration 2100, Loss: 3.121711015701294\n",
      "Iteration 2200, Loss: 3.1193037033081055\n",
      "Iteration 2300, Loss: 3.116943120956421\n",
      "Iteration 2400, Loss: 3.1147751808166504\n",
      "Iteration 2500, Loss: 3.11291766166687\n",
      "Iteration 2600, Loss: 3.1110458374023438\n",
      "Iteration 2700, Loss: 3.1096508502960205\n",
      "Iteration 2800, Loss: 3.1077589988708496\n",
      "Iteration 2900, Loss: 3.106161594390869\n",
      "Iteration 0, Loss: 3.2335703372955322\n",
      "Iteration 100, Loss: 3.1385304927825928\n",
      "Iteration 200, Loss: 3.2050840854644775\n",
      "Iteration 300, Loss: 3.1723976135253906\n",
      "Iteration 400, Loss: 3.179466485977173\n",
      "Iteration 500, Loss: 3.1972434520721436\n",
      "Iteration 600, Loss: 3.1431384086608887\n",
      "Iteration 700, Loss: 3.114413022994995\n",
      "Iteration 800, Loss: 3.0882833003997803\n",
      "Iteration 900, Loss: 3.063678503036499\n",
      "Iteration 1000, Loss: 3.20422101020813\n",
      "Iteration 1100, Loss: 3.199871778488159\n",
      "Iteration 1200, Loss: 3.1947202682495117\n",
      "Iteration 1300, Loss: 3.1860666275024414\n",
      "Iteration 1400, Loss: 3.1645376682281494\n",
      "Iteration 1500, Loss: 3.1212284564971924\n",
      "Iteration 1600, Loss: 3.1790544986724854\n",
      "Iteration 1700, Loss: 3.1550133228302\n",
      "Iteration 1800, Loss: 3.1222290992736816\n",
      "Iteration 1900, Loss: 3.1861064434051514\n",
      "Iteration 2000, Loss: 3.1503536701202393\n",
      "Iteration 2100, Loss: 3.0827221870422363\n",
      "Iteration 2200, Loss: 3.032160997390747\n",
      "Iteration 2300, Loss: 3.135563611984253\n",
      "Iteration 2400, Loss: 3.006791114807129\n",
      "Iteration 2500, Loss: 2.986356735229492\n",
      "Iteration 2600, Loss: 2.981405735015869\n",
      "Iteration 2700, Loss: 3.1686959266662598\n",
      "Iteration 2800, Loss: 3.1433656215667725\n",
      "Iteration 2900, Loss: 3.0808863639831543\n",
      "Iteration 0, Loss: 3.1778745651245117\n",
      "Iteration 100, Loss: 3.1334877014160156\n",
      "Iteration 200, Loss: 3.1278698444366455\n",
      "Iteration 300, Loss: 3.1442980766296387\n",
      "Iteration 400, Loss: 3.1259963512420654\n",
      "Iteration 500, Loss: 3.0779261589050293\n",
      "Iteration 600, Loss: 3.132883071899414\n",
      "Iteration 700, Loss: 3.441509246826172\n",
      "Iteration 800, Loss: 3.128051280975342\n",
      "Iteration 900, Loss: 3.092751979827881\n",
      "Iteration 1000, Loss: 3.1499648094177246\n",
      "Iteration 1100, Loss: 3.1372604370117188\n",
      "Iteration 1200, Loss: 3.1293249130249023\n",
      "Iteration 1300, Loss: 3.116837978363037\n",
      "Iteration 1400, Loss: 3.094247817993164\n",
      "Iteration 1500, Loss: 3.058882236480713\n",
      "Iteration 1600, Loss: 3.0468528270721436\n",
      "Iteration 1700, Loss: 3.0872809886932373\n",
      "Iteration 1800, Loss: 3.143779993057251\n",
      "Iteration 1900, Loss: 3.1405081748962402\n",
      "Iteration 2000, Loss: 3.137319564819336\n",
      "Iteration 2100, Loss: 3.133934259414673\n",
      "Iteration 2200, Loss: 3.129964828491211\n",
      "Iteration 2300, Loss: 3.124574661254883\n",
      "Iteration 2400, Loss: 3.1167399883270264\n",
      "Iteration 2500, Loss: 3.1056711673736572\n",
      "Iteration 2600, Loss: 3.090494155883789\n",
      "Iteration 2700, Loss: 3.0696170330047607\n",
      "Iteration 2800, Loss: 3.0431230068206787\n",
      "Iteration 2900, Loss: 3.11004638671875\n",
      "Iteration 0, Loss: 3.224280834197998\n",
      "Iteration 100, Loss: 3.1929402351379395\n",
      "Iteration 200, Loss: 3.1791470050811768\n",
      "Iteration 300, Loss: 3.1895456314086914\n",
      "Iteration 400, Loss: 3.178553819656372\n",
      "Iteration 500, Loss: 3.1586809158325195\n",
      "Iteration 600, Loss: 3.1879403591156006\n",
      "Iteration 700, Loss: 3.1803877353668213\n",
      "Iteration 800, Loss: 3.167670249938965\n",
      "Iteration 900, Loss: 3.129000425338745\n",
      "Iteration 1000, Loss: 3.194902181625366\n",
      "Iteration 1100, Loss: 3.1861863136291504\n",
      "Iteration 1200, Loss: 3.178018569946289\n",
      "Iteration 1300, Loss: 3.1668241024017334\n",
      "Iteration 1400, Loss: 3.144341468811035\n",
      "Iteration 1500, Loss: 3.0999560356140137\n",
      "Iteration 1600, Loss: 3.1597092151641846\n",
      "Iteration 1700, Loss: 3.0703601837158203\n",
      "Iteration 1800, Loss: 3.1644697189331055\n",
      "Iteration 1900, Loss: 3.0717148780822754\n",
      "Iteration 2000, Loss: 3.1771318912506104\n",
      "Iteration 2100, Loss: 3.15899920463562\n",
      "Iteration 2200, Loss: 3.133105516433716\n",
      "Iteration 2300, Loss: 3.1040942668914795\n",
      "Iteration 2400, Loss: 3.070035934448242\n",
      "Iteration 2500, Loss: 3.1289963722229004\n",
      "Iteration 2600, Loss: 3.1760740280151367\n",
      "Iteration 2700, Loss: 3.129272222518921\n",
      "Iteration 2800, Loss: 3.0639026165008545\n",
      "Iteration 2900, Loss: 3.0161972045898438\n",
      "Iteration 0, Loss: 3.253675937652588\n",
      "Iteration 100, Loss: 3.207719326019287\n",
      "Iteration 200, Loss: 3.2230522632598877\n",
      "Iteration 300, Loss: 3.2155447006225586\n",
      "Iteration 400, Loss: 3.1976711750030518\n",
      "Iteration 500, Loss: 3.1647064685821533\n",
      "Iteration 600, Loss: 3.130685806274414\n",
      "Iteration 700, Loss: 3.098161220550537\n",
      "Iteration 800, Loss: 3.071209669113159\n",
      "Iteration 900, Loss: 3.2154200077056885\n",
      "Iteration 1000, Loss: 3.1679084300994873\n",
      "Iteration 1100, Loss: 3.0731732845306396\n",
      "Iteration 1200, Loss: 3.0423660278320312\n",
      "Iteration 1300, Loss: 3.027376413345337\n",
      "Iteration 1400, Loss: 3.016566038131714\n",
      "Iteration 1500, Loss: 3.009194850921631\n",
      "Iteration 1600, Loss: 3.034405469894409\n",
      "Iteration 1700, Loss: 3.014878511428833\n",
      "Iteration 1800, Loss: 3.0035324096679688\n",
      "Iteration 1900, Loss: 2.9948620796203613\n",
      "Iteration 2000, Loss: 2.987316608428955\n",
      "Iteration 2100, Loss: 2.980532169342041\n",
      "Iteration 2200, Loss: 2.974236488342285\n",
      "Iteration 2300, Loss: 2.9683337211608887\n",
      "Iteration 2400, Loss: 2.962632179260254\n",
      "Iteration 2500, Loss: 2.95709228515625\n",
      "Iteration 2600, Loss: 2.9516489505767822\n",
      "Iteration 2700, Loss: 2.9462666511535645\n",
      "Iteration 2800, Loss: 2.9408762454986572\n",
      "Iteration 2900, Loss: 3.0331480503082275\n",
      "Iteration 0, Loss: 3.2040154933929443\n",
      "Iteration 100, Loss: 3.1654763221740723\n",
      "Iteration 200, Loss: 3.1777143478393555\n",
      "Iteration 300, Loss: 3.148934841156006\n",
      "Iteration 400, Loss: 3.0487711429595947\n",
      "Iteration 500, Loss: 5.028594017028809\n",
      "Iteration 600, Loss: 3.1585967540740967\n",
      "Iteration 700, Loss: 3.1314048767089844\n",
      "Iteration 800, Loss: 3.109060049057007\n",
      "Iteration 900, Loss: 3.0899226665496826\n",
      "Iteration 1000, Loss: 3.0722577571868896\n",
      "Iteration 1100, Loss: 3.0556154251098633\n",
      "Iteration 1200, Loss: 3.1676740646362305\n",
      "Iteration 1300, Loss: 3.103008985519409\n",
      "Iteration 1400, Loss: 3.0643937587738037\n",
      "Iteration 1500, Loss: 3.0388758182525635\n",
      "Iteration 1600, Loss: 3.020442008972168\n",
      "Iteration 1700, Loss: 3.0215635299682617\n",
      "Iteration 1800, Loss: 3.003891706466675\n",
      "Iteration 1900, Loss: 3.1705374717712402\n",
      "Iteration 2000, Loss: 3.1454873085021973\n",
      "Iteration 2100, Loss: 3.0826191902160645\n",
      "Iteration 2200, Loss: 3.0513217449188232\n",
      "Iteration 2300, Loss: 3.032503843307495\n",
      "Iteration 2400, Loss: 3.0184309482574463\n",
      "Iteration 2500, Loss: 3.0066146850585938\n",
      "Iteration 2600, Loss: 2.9973320960998535\n",
      "Iteration 2700, Loss: 2.989645481109619\n",
      "Iteration 2800, Loss: 2.984600305557251\n",
      "Iteration 2900, Loss: 3.0263595581054688\n",
      "Iteration 0, Loss: 3.159862518310547\n",
      "Iteration 100, Loss: 3.1246323585510254\n",
      "Iteration 200, Loss: 3.087296724319458\n",
      "Iteration 300, Loss: 3.0581343173980713\n",
      "Iteration 400, Loss: 3.126837730407715\n",
      "Iteration 500, Loss: 3.0613200664520264\n",
      "Iteration 600, Loss: 3.0323879718780518\n",
      "Iteration 700, Loss: 3.0074007511138916\n",
      "Iteration 800, Loss: 3.040158748626709\n",
      "Iteration 900, Loss: 2.99393367767334\n",
      "Iteration 1000, Loss: 2.969766616821289\n",
      "Iteration 1100, Loss: 3.09783673286438\n",
      "Iteration 1200, Loss: 2.980961561203003\n",
      "Iteration 1300, Loss: 2.948580265045166\n",
      "Iteration 1400, Loss: 2.981066942214966\n",
      "Iteration 1500, Loss: 2.9284656047821045\n",
      "Iteration 1600, Loss: 3.0305087566375732\n",
      "Iteration 1700, Loss: 2.9532182216644287\n",
      "Iteration 1800, Loss: 2.921088457107544\n",
      "Iteration 1900, Loss: 2.9062955379486084\n",
      "Iteration 2000, Loss: 2.896329402923584\n",
      "Iteration 2100, Loss: 2.8879733085632324\n",
      "Iteration 2200, Loss: 2.891162157058716\n",
      "Iteration 2300, Loss: 2.876701593399048\n",
      "Iteration 2400, Loss: 2.8729090690612793\n",
      "Iteration 2500, Loss: 2.996255397796631\n",
      "Iteration 2600, Loss: 2.929384469985962\n",
      "Iteration 2700, Loss: 2.907973289489746\n",
      "Iteration 2800, Loss: 2.8940114974975586\n",
      "Iteration 2900, Loss: 3.0558056831359863\n",
      "Iteration 0, Loss: 3.3613626956939697\n",
      "Iteration 100, Loss: 3.330369710922241\n",
      "Iteration 200, Loss: 3.3325586318969727\n",
      "Iteration 300, Loss: 3.334127902984619\n",
      "Iteration 400, Loss: 3.2496607303619385\n",
      "Iteration 500, Loss: 3.3206539154052734\n",
      "Iteration 600, Loss: 3.2857439517974854\n",
      "Iteration 700, Loss: 3.3314826488494873\n",
      "Iteration 800, Loss: 3.308929204940796\n",
      "Iteration 900, Loss: 3.27628231048584\n",
      "Iteration 1000, Loss: 3.338686227798462\n",
      "Iteration 1100, Loss: 3.3348474502563477\n",
      "Iteration 1200, Loss: 3.3287508487701416\n",
      "Iteration 1300, Loss: 3.32065749168396\n",
      "Iteration 1400, Loss: 3.3080148696899414\n",
      "Iteration 1500, Loss: 3.285386562347412\n",
      "Iteration 1600, Loss: 3.2454774379730225\n",
      "Iteration 1700, Loss: 3.3355770111083984\n",
      "Iteration 1800, Loss: 3.3296782970428467\n",
      "Iteration 1900, Loss: 3.323793888092041\n",
      "Iteration 2000, Loss: 3.3167123794555664\n",
      "Iteration 2100, Loss: 3.3044614791870117\n",
      "Iteration 2200, Loss: 3.280111312866211\n",
      "Iteration 2300, Loss: 3.315425157546997\n",
      "Iteration 2400, Loss: 3.306760311126709\n",
      "Iteration 2500, Loss: 3.294776439666748\n",
      "Iteration 2600, Loss: 3.272721529006958\n",
      "Iteration 2700, Loss: 3.232590675354004\n",
      "Iteration 2800, Loss: 3.304466724395752\n",
      "Iteration 2900, Loss: 3.270233392715454\n",
      "Iteration 0, Loss: 3.3686070442199707\n",
      "Iteration 100, Loss: 3.2951297760009766\n",
      "Iteration 200, Loss: 3.3314409255981445\n",
      "Iteration 300, Loss: 3.2968244552612305\n",
      "Iteration 400, Loss: 3.3266899585723877\n",
      "Iteration 500, Loss: 3.322605848312378\n",
      "Iteration 600, Loss: 3.320432424545288\n",
      "Iteration 700, Loss: 3.3187026977539062\n",
      "Iteration 800, Loss: 3.3170082569122314\n",
      "Iteration 900, Loss: 3.315159320831299\n",
      "Iteration 1000, Loss: 3.3129611015319824\n",
      "Iteration 1100, Loss: 3.310089349746704\n",
      "Iteration 1200, Loss: 3.305722713470459\n",
      "Iteration 1300, Loss: 3.296522855758667\n",
      "Iteration 1400, Loss: 3.279933452606201\n",
      "Iteration 1500, Loss: 3.2705774307250977\n",
      "Iteration 1600, Loss: 3.265138626098633\n",
      "Iteration 1700, Loss: 3.261019229888916\n",
      "Iteration 1800, Loss: 3.2574665546417236\n",
      "Iteration 1900, Loss: 3.254296064376831\n",
      "Iteration 2000, Loss: 3.2514231204986572\n",
      "Iteration 2100, Loss: 3.2487547397613525\n",
      "Iteration 2200, Loss: 3.2462158203125\n",
      "Iteration 2300, Loss: 3.243734836578369\n",
      "Iteration 2400, Loss: 3.2412548065185547\n",
      "Iteration 2500, Loss: 3.2387163639068604\n",
      "Iteration 2600, Loss: 3.236067295074463\n",
      "Iteration 2700, Loss: 3.233264446258545\n",
      "Iteration 2800, Loss: 3.23026704788208\n",
      "Iteration 2900, Loss: 3.227036714553833\n",
      "Iteration 0, Loss: 3.287712574005127\n",
      "Iteration 100, Loss: 3.2582497596740723\n",
      "Iteration 200, Loss: 3.2286629676818848\n",
      "Iteration 300, Loss: 3.25248122215271\n",
      "Iteration 400, Loss: 3.242396354675293\n",
      "Iteration 500, Loss: 3.2333521842956543\n",
      "Iteration 600, Loss: 3.220649003982544\n",
      "Iteration 700, Loss: 3.2010035514831543\n",
      "Iteration 800, Loss: 3.1717910766601562\n",
      "Iteration 900, Loss: 3.242825984954834\n",
      "Iteration 1000, Loss: 3.229766845703125\n",
      "Iteration 1100, Loss: 3.204012393951416\n",
      "Iteration 1200, Loss: 3.1624388694763184\n",
      "Iteration 1300, Loss: 3.120965003967285\n",
      "Iteration 1400, Loss: 3.237039804458618\n",
      "Iteration 1500, Loss: 3.2188637256622314\n",
      "Iteration 1600, Loss: 3.1627326011657715\n",
      "Iteration 1700, Loss: 3.107635736465454\n",
      "Iteration 1800, Loss: 3.199674367904663\n",
      "Iteration 1900, Loss: 3.078606605529785\n",
      "Iteration 2000, Loss: 3.1926651000976562\n",
      "Iteration 2100, Loss: 3.2444608211517334\n",
      "Iteration 2200, Loss: 3.2286221981048584\n",
      "Iteration 2300, Loss: 3.201761484146118\n",
      "Iteration 2400, Loss: 3.1511647701263428\n",
      "Iteration 2500, Loss: 3.1280922889709473\n",
      "Iteration 2600, Loss: 3.222508192062378\n",
      "Iteration 2700, Loss: 3.1232948303222656\n",
      "Iteration 2800, Loss: 3.225419521331787\n",
      "Iteration 2900, Loss: 3.1124744415283203\n",
      "Iteration 0, Loss: 3.259791135787964\n",
      "Iteration 100, Loss: 3.1219189167022705\n",
      "Iteration 200, Loss: 3.1523847579956055\n",
      "Iteration 300, Loss: 3.2222511768341064\n",
      "Iteration 400, Loss: 3.1347129344940186\n",
      "Iteration 500, Loss: 3.2284765243530273\n",
      "Iteration 600, Loss: 3.190556764602661\n",
      "Iteration 700, Loss: 3.114898204803467\n",
      "Iteration 800, Loss: 3.168449878692627\n",
      "Iteration 900, Loss: 3.2349936962127686\n",
      "Iteration 1000, Loss: 3.2302238941192627\n",
      "Iteration 1100, Loss: 3.209510564804077\n",
      "Iteration 1200, Loss: 3.1402132511138916\n",
      "Iteration 1300, Loss: 3.077033281326294\n",
      "Iteration 1400, Loss: 3.0504162311553955\n",
      "Iteration 1500, Loss: 3.112172842025757\n",
      "Iteration 1600, Loss: 3.0315005779266357\n",
      "Iteration 1700, Loss: 3.0186448097229004\n",
      "Iteration 1800, Loss: 3.169153928756714\n",
      "Iteration 1900, Loss: 3.009672164916992\n",
      "Iteration 2000, Loss: 2.996833324432373\n",
      "Iteration 2100, Loss: 3.0929839611053467\n",
      "Iteration 2200, Loss: 2.9887051582336426\n",
      "Iteration 2300, Loss: 2.9744668006896973\n",
      "Iteration 2400, Loss: 2.963005542755127\n",
      "Iteration 2500, Loss: 2.952439546585083\n",
      "Iteration 2600, Loss: 2.9434239864349365\n",
      "Iteration 2700, Loss: 2.938934087753296\n",
      "Iteration 2800, Loss: 2.9253005981445312\n",
      "Iteration 2900, Loss: 2.917422294616699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/_yg34tj15s306l4m7k_wf0qw0000gq/T/ipykernel_66893/3875915117.py:56: RuntimeWarning: invalid value encountered in arccos\n",
      "  angpermscore[perm] = np.cos(np.arccos(num/denom))\n",
      "/var/folders/tv/_yg34tj15s306l4m7k_wf0qw0000gq/T/ipykernel_66893/3875915117.py:56: RuntimeWarning: invalid value encountered in cos\n",
      "  angpermscore[perm] = np.cos(np.arccos(num/denom))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 3.2317795753479004\n",
      "Iteration 100, Loss: 3.209181070327759\n",
      "Iteration 200, Loss: 3.1807334423065186\n",
      "Iteration 300, Loss: 3.186981439590454\n",
      "Iteration 400, Loss: 3.1867892742156982\n",
      "Iteration 500, Loss: 3.1216559410095215\n",
      "Iteration 600, Loss: 3.2026233673095703\n",
      "Iteration 700, Loss: 3.19620943069458\n",
      "Iteration 800, Loss: 3.1901071071624756\n",
      "Iteration 900, Loss: 3.181532382965088\n",
      "Iteration 1000, Loss: 3.1624958515167236\n",
      "Iteration 1100, Loss: 3.1092963218688965\n",
      "Iteration 1200, Loss: 3.118081569671631\n",
      "Iteration 1300, Loss: 3.189025640487671\n",
      "Iteration 1400, Loss: 3.201256036758423\n",
      "Iteration 1500, Loss: 3.189573287963867\n",
      "Iteration 1600, Loss: 3.1615066528320312\n",
      "Iteration 1700, Loss: 3.185777187347412\n",
      "Iteration 1800, Loss: 3.170750617980957\n",
      "Iteration 1900, Loss: 3.1431548595428467\n",
      "Iteration 2000, Loss: 3.1628127098083496\n",
      "Iteration 2100, Loss: 3.1770386695861816\n",
      "Iteration 2200, Loss: 3.1658101081848145\n",
      "Iteration 2300, Loss: 3.1485402584075928\n",
      "Iteration 2400, Loss: 3.1053805351257324\n",
      "Iteration 2500, Loss: 3.165072441101074\n",
      "Iteration 2600, Loss: 3.149911880493164\n",
      "Iteration 2700, Loss: 3.1287901401519775\n",
      "Iteration 2800, Loss: 3.160923480987549\n",
      "Iteration 2900, Loss: 3.1179802417755127\n",
      "Iteration 0, Loss: 3.1985185146331787\n",
      "Iteration 100, Loss: 3.1383705139160156\n",
      "Iteration 200, Loss: 3.076782464981079\n",
      "Iteration 300, Loss: 3.1773805618286133\n",
      "Iteration 400, Loss: 3.170102119445801\n",
      "Iteration 500, Loss: 3.116278886795044\n",
      "Iteration 600, Loss: 3.0377142429351807\n",
      "Iteration 700, Loss: 3.106832504272461\n",
      "Iteration 800, Loss: 3.155804395675659\n",
      "Iteration 900, Loss: 3.062077045440674\n",
      "Iteration 1000, Loss: 3.179480791091919\n",
      "Iteration 1100, Loss: 3.178727388381958\n",
      "Iteration 1200, Loss: 3.177935838699341\n",
      "Iteration 1300, Loss: 3.177079916000366\n",
      "Iteration 1400, Loss: 3.1761457920074463\n",
      "Iteration 1500, Loss: 3.1751015186309814\n",
      "Iteration 1600, Loss: 3.1739182472229004\n",
      "Iteration 1700, Loss: 3.1725356578826904\n",
      "Iteration 1800, Loss: 3.1708669662475586\n",
      "Iteration 1900, Loss: 3.168768882751465\n",
      "Iteration 2000, Loss: 3.165994882583618\n",
      "Iteration 2100, Loss: 3.162135601043701\n",
      "Iteration 2200, Loss: 3.1565115451812744\n",
      "Iteration 2300, Loss: 3.1479411125183105\n",
      "Iteration 2400, Loss: 3.134402275085449\n",
      "Iteration 2500, Loss: 3.113663911819458\n",
      "Iteration 2600, Loss: 3.0868356227874756\n",
      "Iteration 2700, Loss: 3.144876003265381\n",
      "Iteration 2800, Loss: 3.119389533996582\n",
      "Iteration 2900, Loss: 3.0944361686706543\n",
      "Iteration 0, Loss: 3.174548625946045\n",
      "Iteration 100, Loss: 3.045153856277466\n",
      "Iteration 200, Loss: 2.9802587032318115\n",
      "Iteration 300, Loss: 2.9689457416534424\n",
      "Iteration 400, Loss: 3.1243085861206055\n",
      "Iteration 500, Loss: 2.9298930168151855\n",
      "Iteration 600, Loss: 2.9098782539367676\n",
      "Iteration 700, Loss: 2.968736171722412\n",
      "Iteration 800, Loss: 2.9227941036224365\n",
      "Iteration 900, Loss: 2.8924598693847656\n",
      "Iteration 1000, Loss: 3.014183521270752\n",
      "Iteration 1100, Loss: 2.8727893829345703\n",
      "Iteration 1200, Loss: 2.8556272983551025\n",
      "Iteration 1300, Loss: 2.8423354625701904\n",
      "Iteration 1400, Loss: 2.828333854675293\n",
      "Iteration 1500, Loss: 2.829796552658081\n",
      "Iteration 1600, Loss: 2.810521364212036\n",
      "Iteration 1700, Loss: 2.8011293411254883\n",
      "Iteration 1800, Loss: 2.7908384799957275\n",
      "Iteration 1900, Loss: 2.78403639793396\n",
      "Iteration 2000, Loss: 2.777431011199951\n",
      "Iteration 2100, Loss: 2.763340950012207\n",
      "Iteration 2200, Loss: 2.75653076171875\n",
      "Iteration 2300, Loss: 2.7555809020996094\n",
      "Iteration 2400, Loss: 2.7393264770507812\n",
      "Iteration 2500, Loss: 2.7343318462371826\n",
      "Iteration 2600, Loss: 2.731525182723999\n",
      "Iteration 2700, Loss: 2.7266297340393066\n",
      "Iteration 2800, Loss: 2.722449779510498\n",
      "Iteration 2900, Loss: 2.7155601978302\n",
      "Iteration 0, Loss: 3.270033121109009\n",
      "Iteration 100, Loss: 3.21305513381958\n",
      "Iteration 200, Loss: 3.2186338901519775\n",
      "Iteration 300, Loss: 3.2302184104919434\n",
      "Iteration 400, Loss: 3.215940475463867\n",
      "Iteration 500, Loss: 3.202089309692383\n",
      "Iteration 600, Loss: 3.1802620887756348\n",
      "Iteration 700, Loss: 3.211437463760376\n",
      "Iteration 800, Loss: 3.2141313552856445\n",
      "Iteration 900, Loss: 3.2057952880859375\n",
      "Iteration 1000, Loss: 3.19319486618042\n",
      "Iteration 1100, Loss: 3.1710383892059326\n",
      "Iteration 1200, Loss: 3.137950897216797\n",
      "Iteration 1300, Loss: 3.179647207260132\n",
      "Iteration 1400, Loss: 3.08422589302063\n",
      "Iteration 1500, Loss: 3.0938260555267334\n",
      "Iteration 1600, Loss: 3.1444151401519775\n",
      "Iteration 1700, Loss: 3.0392682552337646\n",
      "Iteration 1800, Loss: 3.195168972015381\n",
      "Iteration 1900, Loss: 3.0983080863952637\n",
      "Iteration 2000, Loss: 3.0587310791015625\n",
      "Iteration 2100, Loss: 3.1874499320983887\n",
      "Iteration 2200, Loss: 3.217289447784424\n",
      "Iteration 2300, Loss: 3.1901960372924805\n",
      "Iteration 2400, Loss: 3.145946741104126\n",
      "Iteration 2500, Loss: 3.0929794311523438\n",
      "Iteration 2600, Loss: 3.212641477584839\n",
      "Iteration 2700, Loss: 3.1683509349823\n",
      "Iteration 2800, Loss: 3.116248369216919\n",
      "Iteration 2900, Loss: 3.206498861312866\n",
      "Iteration 0, Loss: 3.1820788383483887\n",
      "Iteration 100, Loss: 3.137316942214966\n",
      "Iteration 200, Loss: 3.0978848934173584\n",
      "Iteration 300, Loss: 3.1468820571899414\n",
      "Iteration 400, Loss: 3.138367176055908\n",
      "Iteration 500, Loss: 3.118492603302002\n",
      "Iteration 600, Loss: 3.0759854316711426\n",
      "Iteration 700, Loss: 3.1149706840515137\n",
      "Iteration 800, Loss: 3.0690255165100098\n",
      "Iteration 900, Loss: 3.122718334197998\n",
      "Iteration 1000, Loss: 3.0873429775238037\n",
      "Iteration 1100, Loss: 3.0597429275512695\n",
      "Iteration 1200, Loss: 3.1288352012634277\n",
      "Iteration 1300, Loss: 3.103883981704712\n",
      "Iteration 1400, Loss: 3.074829339981079\n",
      "Iteration 1500, Loss: 3.123649835586548\n",
      "Iteration 1600, Loss: 3.06392765045166\n",
      "Iteration 1700, Loss: 3.0223777294158936\n",
      "Iteration 1800, Loss: 3.144597291946411\n",
      "Iteration 1900, Loss: 3.1221818923950195\n",
      "Iteration 2000, Loss: 3.0797603130340576\n",
      "Iteration 2100, Loss: 3.0737948417663574\n",
      "Iteration 2200, Loss: 3.0654380321502686\n",
      "Iteration 2300, Loss: 3.1450908184051514\n",
      "Iteration 2400, Loss: 3.1370813846588135\n",
      "Iteration 2500, Loss: 3.0621161460876465\n",
      "Iteration 2600, Loss: 2.995248794555664\n",
      "Iteration 2700, Loss: 3.144763946533203\n",
      "Iteration 2800, Loss: 3.0459506511688232\n",
      "Iteration 2900, Loss: 2.9696249961853027\n",
      "Iteration 0, Loss: 3.2485265731811523\n",
      "Iteration 100, Loss: 3.2185237407684326\n",
      "Iteration 200, Loss: 3.213498830795288\n",
      "Iteration 300, Loss: 3.1966519355773926\n",
      "Iteration 400, Loss: 3.1684460639953613\n",
      "Iteration 500, Loss: 3.125868082046509\n",
      "Iteration 600, Loss: 3.1755778789520264\n",
      "Iteration 700, Loss: 3.22161865234375\n",
      "Iteration 800, Loss: 3.1434733867645264\n",
      "Iteration 900, Loss: 3.083650827407837\n",
      "Iteration 1000, Loss: 3.0704362392425537\n",
      "Iteration 1100, Loss: 3.037572145462036\n",
      "Iteration 1200, Loss: 3.030524492263794\n",
      "Iteration 1300, Loss: 3.0081775188446045\n",
      "Iteration 1400, Loss: 2.9923746585845947\n",
      "Iteration 1500, Loss: 2.9801197052001953\n",
      "Iteration 1600, Loss: 2.9935874938964844\n",
      "Iteration 1700, Loss: 2.969132900238037\n",
      "Iteration 1800, Loss: 2.95790433883667\n",
      "Iteration 1900, Loss: 2.949141025543213\n",
      "Iteration 2000, Loss: 2.980884552001953\n",
      "Iteration 2100, Loss: 2.928828239440918\n",
      "Iteration 2200, Loss: 2.9237117767333984\n",
      "Iteration 2300, Loss: 2.912855863571167\n",
      "Iteration 2400, Loss: 2.9059059619903564\n",
      "Iteration 2500, Loss: 2.895630121231079\n",
      "Iteration 2600, Loss: 2.8935298919677734\n",
      "Iteration 2700, Loss: 2.8811886310577393\n",
      "Iteration 2800, Loss: 2.8725171089172363\n",
      "Iteration 2900, Loss: 2.8707921504974365\n",
      "Iteration 0, Loss: 3.3342416286468506\n",
      "Iteration 100, Loss: 3.291956901550293\n",
      "Iteration 200, Loss: 3.307830810546875\n",
      "Iteration 300, Loss: 3.2889158725738525\n",
      "Iteration 400, Loss: 3.1999001502990723\n",
      "Iteration 500, Loss: 3.257309675216675\n",
      "Iteration 600, Loss: 3.297559976577759\n",
      "Iteration 700, Loss: 3.276496171951294\n",
      "Iteration 800, Loss: 3.2357985973358154\n",
      "Iteration 900, Loss: 3.2996292114257812\n",
      "Iteration 1000, Loss: 3.2286112308502197\n",
      "Iteration 1100, Loss: 3.1585071086883545\n",
      "Iteration 1200, Loss: 3.2946276664733887\n",
      "Iteration 1300, Loss: 3.289559841156006\n",
      "Iteration 1400, Loss: 3.282301902770996\n",
      "Iteration 1500, Loss: 3.268742799758911\n",
      "Iteration 1600, Loss: 3.2461307048797607\n",
      "Iteration 1700, Loss: 3.2139744758605957\n",
      "Iteration 1800, Loss: 3.2800378799438477\n",
      "Iteration 1900, Loss: 3.2627875804901123\n",
      "Iteration 2000, Loss: 3.234649419784546\n",
      "Iteration 2100, Loss: 3.195941686630249\n",
      "Iteration 2200, Loss: 3.1675009727478027\n",
      "Iteration 2300, Loss: 3.142069101333618\n",
      "Iteration 2400, Loss: 3.125885248184204\n",
      "Iteration 2500, Loss: 3.1121082305908203\n",
      "Iteration 2600, Loss: 3.1003684997558594\n",
      "Iteration 2700, Loss: 3.090585231781006\n",
      "Iteration 2800, Loss: 3.0821475982666016\n",
      "Iteration 2900, Loss: 3.0747313499450684\n",
      "Iteration 0, Loss: 3.249955654144287\n",
      "Iteration 100, Loss: 3.1988718509674072\n",
      "Iteration 200, Loss: 3.13920259475708\n",
      "Iteration 300, Loss: 3.2132890224456787\n",
      "Iteration 400, Loss: 3.2311103343963623\n",
      "Iteration 500, Loss: 3.219820499420166\n",
      "Iteration 600, Loss: 3.190967321395874\n",
      "Iteration 700, Loss: 3.125786542892456\n",
      "Iteration 800, Loss: 3.2102973461151123\n",
      "Iteration 900, Loss: 3.1907739639282227\n",
      "Iteration 1000, Loss: 3.1483891010284424\n",
      "Iteration 1100, Loss: 3.091906785964966\n",
      "Iteration 1200, Loss: 3.192835569381714\n",
      "Iteration 1300, Loss: 3.061811685562134\n",
      "Iteration 1400, Loss: 3.0291786193847656\n",
      "Iteration 1500, Loss: 3.033801317214966\n",
      "Iteration 1600, Loss: 3.0306196212768555\n",
      "Iteration 1700, Loss: 3.0002939701080322\n",
      "Iteration 1800, Loss: 2.9839906692504883\n",
      "Iteration 1900, Loss: 2.990933418273926\n",
      "Iteration 2000, Loss: 2.9686999320983887\n",
      "Iteration 2100, Loss: 2.9608094692230225\n",
      "Iteration 2200, Loss: 2.965052843093872\n",
      "Iteration 2300, Loss: 2.946215867996216\n",
      "Iteration 2400, Loss: 2.938551187515259\n",
      "Iteration 2500, Loss: 2.96095871925354\n",
      "Iteration 2600, Loss: 2.9322314262390137\n",
      "Iteration 2700, Loss: 2.9170377254486084\n",
      "Iteration 2800, Loss: 2.931722640991211\n",
      "Iteration 2900, Loss: 2.904451608657837\n",
      "Iteration 0, Loss: 3.382887840270996\n",
      "Iteration 100, Loss: 3.255347490310669\n",
      "Iteration 200, Loss: 3.269672155380249\n",
      "Iteration 300, Loss: 3.1888067722320557\n",
      "Iteration 400, Loss: 3.1666386127471924\n",
      "Iteration 500, Loss: 3.1441915035247803\n",
      "Iteration 600, Loss: 3.2192790508270264\n",
      "Iteration 700, Loss: 3.169081449508667\n",
      "Iteration 800, Loss: 3.162432909011841\n",
      "Iteration 900, Loss: 3.160867691040039\n",
      "Iteration 1000, Loss: 3.1318984031677246\n",
      "Iteration 1100, Loss: 3.1152942180633545\n",
      "Iteration 1200, Loss: 3.099961996078491\n",
      "Iteration 1300, Loss: 3.0856387615203857\n",
      "Iteration 1400, Loss: 3.077113151550293\n",
      "Iteration 1500, Loss: 3.0628716945648193\n",
      "Iteration 1600, Loss: 3.0541462898254395\n",
      "Iteration 1700, Loss: 3.0517375469207764\n",
      "Iteration 1800, Loss: 3.0407443046569824\n",
      "Iteration 1900, Loss: 3.0230393409729004\n",
      "Iteration 2000, Loss: 3.01788330078125\n",
      "Iteration 2100, Loss: 3.009796142578125\n",
      "Iteration 2200, Loss: 2.9995059967041016\n",
      "Iteration 2300, Loss: 2.995087146759033\n",
      "Iteration 2400, Loss: 2.9854557514190674\n",
      "Iteration 2500, Loss: 2.9793739318847656\n",
      "Iteration 2600, Loss: 2.9783663749694824\n",
      "Iteration 2700, Loss: 2.968787670135498\n",
      "Iteration 2800, Loss: 2.9640376567840576\n",
      "Iteration 2900, Loss: 2.955622434616089\n",
      "Iteration 0, Loss: 3.2301852703094482\n",
      "Iteration 100, Loss: 3.099586248397827\n",
      "Iteration 200, Loss: 3.0991528034210205\n",
      "Iteration 300, Loss: 3.006962299346924\n",
      "Iteration 400, Loss: 2.965729236602783\n",
      "Iteration 500, Loss: 2.9356849193573\n",
      "Iteration 600, Loss: 2.917815685272217\n",
      "Iteration 700, Loss: 2.9024429321289062\n",
      "Iteration 800, Loss: 2.8813905715942383\n",
      "Iteration 900, Loss: 2.8698370456695557\n",
      "Iteration 1000, Loss: 2.860809326171875\n",
      "Iteration 1100, Loss: 2.842444658279419\n",
      "Iteration 1200, Loss: 2.8392128944396973\n",
      "Iteration 1300, Loss: 2.8235504627227783\n",
      "Iteration 1400, Loss: 2.8190481662750244\n",
      "Iteration 1500, Loss: 2.8086447715759277\n",
      "Iteration 1600, Loss: 2.8011767864227295\n",
      "Iteration 1700, Loss: 2.800670862197876\n",
      "Iteration 1800, Loss: 2.7887022495269775\n",
      "Iteration 1900, Loss: 2.785020589828491\n",
      "Iteration 2000, Loss: 2.7788643836975098\n",
      "Iteration 2100, Loss: 2.7728495597839355\n",
      "Iteration 2200, Loss: 2.766984701156616\n",
      "Iteration 2300, Loss: 2.7626590728759766\n",
      "Iteration 2400, Loss: 2.7554879188537598\n",
      "Iteration 2500, Loss: 2.758714437484741\n",
      "Iteration 2600, Loss: 2.7532339096069336\n",
      "Iteration 2700, Loss: 2.74776029586792\n",
      "Iteration 2800, Loss: 2.7383878231048584\n",
      "Iteration 2900, Loss: 2.734313726425171\n",
      "Iteration 0, Loss: 3.2575297355651855\n",
      "Iteration 100, Loss: 3.194348096847534\n",
      "Iteration 200, Loss: 3.2016067504882812\n",
      "Iteration 300, Loss: 3.1985952854156494\n",
      "Iteration 400, Loss: 3.1845180988311768\n",
      "Iteration 500, Loss: 3.149810314178467\n",
      "Iteration 600, Loss: 3.195582151412964\n",
      "Iteration 700, Loss: 3.1862711906433105\n",
      "Iteration 800, Loss: 3.174588203430176\n",
      "Iteration 900, Loss: 3.2271311283111572\n",
      "Iteration 1000, Loss: 3.208627700805664\n",
      "Iteration 1100, Loss: 3.1810877323150635\n",
      "Iteration 1200, Loss: 3.1879847049713135\n",
      "Iteration 1300, Loss: 3.1186952590942383\n",
      "Iteration 1400, Loss: 3.2330591678619385\n",
      "Iteration 1500, Loss: 3.2151002883911133\n",
      "Iteration 1600, Loss: 3.178452968597412\n",
      "Iteration 1700, Loss: 3.2273340225219727\n",
      "Iteration 1800, Loss: 3.2187154293060303\n",
      "Iteration 1900, Loss: 3.2000105381011963\n",
      "Iteration 2000, Loss: 3.156796932220459\n",
      "Iteration 2100, Loss: 3.1972765922546387\n",
      "Iteration 2200, Loss: 3.079962968826294\n",
      "Iteration 2300, Loss: 3.226497173309326\n",
      "Iteration 2400, Loss: 3.2226877212524414\n",
      "Iteration 2500, Loss: 3.2188544273376465\n",
      "Iteration 2600, Loss: 3.214421510696411\n",
      "Iteration 2700, Loss: 3.2084858417510986\n",
      "Iteration 2800, Loss: 3.198120355606079\n",
      "Iteration 2900, Loss: 3.175833225250244\n",
      "Iteration 0, Loss: 3.168480634689331\n",
      "Iteration 100, Loss: 3.0675370693206787\n",
      "Iteration 200, Loss: 3.104921340942383\n",
      "Iteration 300, Loss: 3.0314855575561523\n",
      "Iteration 400, Loss: 3.0790226459503174\n",
      "Iteration 500, Loss: 3.1257901191711426\n",
      "Iteration 600, Loss: 3.057492256164551\n",
      "Iteration 700, Loss: 3.0778491497039795\n",
      "Iteration 800, Loss: 3.1254706382751465\n",
      "Iteration 900, Loss: 3.1121840476989746\n",
      "Iteration 1000, Loss: 3.074091672897339\n",
      "Iteration 1100, Loss: 3.1380345821380615\n",
      "Iteration 1200, Loss: 3.135631561279297\n",
      "Iteration 1300, Loss: 3.134268283843994\n",
      "Iteration 1400, Loss: 3.1330106258392334\n",
      "Iteration 1500, Loss: 3.131737470626831\n",
      "Iteration 1600, Loss: 3.1303985118865967\n",
      "Iteration 1700, Loss: 3.128953456878662\n",
      "Iteration 1800, Loss: 3.1273751258850098\n",
      "Iteration 1900, Loss: 3.1256184577941895\n",
      "Iteration 2000, Loss: 3.1236274242401123\n",
      "Iteration 2100, Loss: 3.121326208114624\n",
      "Iteration 2200, Loss: 3.1186137199401855\n",
      "Iteration 2300, Loss: 3.1153366565704346\n",
      "Iteration 2400, Loss: 3.1112756729125977\n",
      "Iteration 2500, Loss: 3.106111526489258\n",
      "Iteration 2600, Loss: 3.0993924140930176\n",
      "Iteration 2700, Loss: 3.0905275344848633\n",
      "Iteration 2800, Loss: 3.0788328647613525\n",
      "Iteration 2900, Loss: 3.063781976699829\n",
      "Iteration 0, Loss: 3.2436718940734863\n",
      "Iteration 100, Loss: 3.192762613296509\n",
      "Iteration 200, Loss: 3.0522544384002686\n",
      "Iteration 300, Loss: 3.1710026264190674\n",
      "Iteration 400, Loss: 3.2179977893829346\n",
      "Iteration 500, Loss: 3.181489944458008\n",
      "Iteration 600, Loss: 3.2154557704925537\n",
      "Iteration 700, Loss: 3.2037196159362793\n",
      "Iteration 800, Loss: 3.171682596206665\n",
      "Iteration 900, Loss: 3.219001054763794\n",
      "Iteration 1000, Loss: 3.211360216140747\n",
      "Iteration 1100, Loss: 3.202758550643921\n",
      "Iteration 1200, Loss: 3.1857192516326904\n",
      "Iteration 1300, Loss: 3.1534788608551025\n",
      "Iteration 1400, Loss: 3.112063407897949\n",
      "Iteration 1500, Loss: 3.07960844039917\n",
      "Iteration 1600, Loss: 3.0579166412353516\n",
      "Iteration 1700, Loss: 3.219797134399414\n",
      "Iteration 1800, Loss: 3.2168633937835693\n",
      "Iteration 1900, Loss: 3.214056968688965\n",
      "Iteration 2000, Loss: 3.2109251022338867\n",
      "Iteration 2100, Loss: 3.207172393798828\n",
      "Iteration 2200, Loss: 3.2023515701293945\n",
      "Iteration 2300, Loss: 3.1955647468566895\n",
      "Iteration 2400, Loss: 3.185138463973999\n",
      "Iteration 2500, Loss: 3.1687934398651123\n",
      "Iteration 2600, Loss: 3.1450634002685547\n",
      "Iteration 2700, Loss: 3.115482807159424\n",
      "Iteration 2800, Loss: 3.084561586380005\n",
      "Iteration 2900, Loss: 3.06412410736084\n",
      "Iteration 0, Loss: 3.3658623695373535\n",
      "Iteration 100, Loss: 3.300179958343506\n",
      "Iteration 200, Loss: 3.2433419227600098\n",
      "Iteration 300, Loss: 3.199298143386841\n",
      "Iteration 400, Loss: 3.1703360080718994\n",
      "Iteration 500, Loss: 3.1469595432281494\n",
      "Iteration 600, Loss: 3.276857376098633\n",
      "Iteration 700, Loss: 3.126891613006592\n",
      "Iteration 800, Loss: 3.215193271636963\n",
      "Iteration 900, Loss: 3.2765820026397705\n",
      "Iteration 1000, Loss: 3.2132859230041504\n",
      "Iteration 1100, Loss: 3.214672327041626\n",
      "Iteration 1200, Loss: 3.13702654838562\n",
      "Iteration 1300, Loss: 3.1329517364501953\n",
      "Iteration 1400, Loss: 3.109097957611084\n",
      "Iteration 1500, Loss: 3.1063568592071533\n",
      "Iteration 1600, Loss: 3.073216676712036\n",
      "Iteration 1700, Loss: 3.073521375656128\n",
      "Iteration 1800, Loss: 3.056642770767212\n",
      "Iteration 1900, Loss: 3.065357208251953\n",
      "Iteration 2000, Loss: 3.042311668395996\n",
      "Iteration 2100, Loss: 3.0541062355041504\n",
      "Iteration 2200, Loss: 3.019221782684326\n",
      "Iteration 2300, Loss: 3.0200095176696777\n",
      "Iteration 2400, Loss: 3.0135414600372314\n",
      "Iteration 2500, Loss: 2.996778964996338\n",
      "Iteration 2600, Loss: 2.9938032627105713\n",
      "Iteration 2700, Loss: 2.97805118560791\n",
      "Iteration 2800, Loss: 2.977062225341797\n",
      "Iteration 2900, Loss: 2.969078302383423\n",
      "Iteration 0, Loss: 3.2480669021606445\n",
      "Iteration 100, Loss: 3.224872350692749\n",
      "Iteration 200, Loss: 3.2135658264160156\n",
      "Iteration 300, Loss: 3.146711587905884\n",
      "Iteration 400, Loss: 3.224691390991211\n",
      "Iteration 500, Loss: 3.2225089073181152\n",
      "Iteration 600, Loss: 3.221186876296997\n",
      "Iteration 700, Loss: 3.220121383666992\n",
      "Iteration 800, Loss: 3.2192111015319824\n",
      "Iteration 900, Loss: 3.218362331390381\n",
      "Iteration 1000, Loss: 3.2175099849700928\n",
      "Iteration 1100, Loss: 3.216628074645996\n",
      "Iteration 1200, Loss: 3.215702533721924\n",
      "Iteration 1300, Loss: 3.214724540710449\n",
      "Iteration 1400, Loss: 3.2136783599853516\n",
      "Iteration 1500, Loss: 3.2125537395477295\n",
      "Iteration 1600, Loss: 3.2113332748413086\n",
      "Iteration 1700, Loss: 3.2099969387054443\n",
      "Iteration 1800, Loss: 3.2085227966308594\n",
      "Iteration 1900, Loss: 3.2068777084350586\n",
      "Iteration 2000, Loss: 3.2050302028656006\n",
      "Iteration 2100, Loss: 3.202925682067871\n",
      "Iteration 2200, Loss: 3.200500249862671\n",
      "Iteration 2300, Loss: 3.197669267654419\n",
      "Iteration 2400, Loss: 3.1943137645721436\n",
      "Iteration 2500, Loss: 3.1902787685394287\n",
      "Iteration 2600, Loss: 3.1853625774383545\n",
      "Iteration 2700, Loss: 3.179333448410034\n",
      "Iteration 2800, Loss: 3.171964168548584\n",
      "Iteration 2900, Loss: 3.1631181240081787\n",
      "Iteration 0, Loss: 3.150980234146118\n",
      "Iteration 100, Loss: 3.1160593032836914\n",
      "Iteration 200, Loss: 3.131239414215088\n",
      "Iteration 300, Loss: 3.127070665359497\n",
      "Iteration 400, Loss: 3.1198606491088867\n",
      "Iteration 500, Loss: 3.107171058654785\n",
      "Iteration 600, Loss: 3.0841660499572754\n",
      "Iteration 700, Loss: 3.116118907928467\n",
      "Iteration 800, Loss: 3.102731227874756\n",
      "Iteration 900, Loss: 3.0828230381011963\n",
      "Iteration 1000, Loss: 3.0492873191833496\n",
      "Iteration 1100, Loss: 3.054988384246826\n",
      "Iteration 1200, Loss: 3.0206055641174316\n",
      "Iteration 1300, Loss: 3.106485605239868\n",
      "Iteration 1400, Loss: 3.0276451110839844\n",
      "Iteration 1500, Loss: 3.099456548690796\n",
      "Iteration 1600, Loss: 2.9772934913635254\n",
      "Iteration 1700, Loss: 2.929985761642456\n",
      "Iteration 1800, Loss: 3.123399019241333\n",
      "Iteration 1900, Loss: 3.12083101272583\n",
      "Iteration 2000, Loss: 3.116685152053833\n",
      "Iteration 2100, Loss: 3.1098389625549316\n",
      "Iteration 2200, Loss: 3.102668285369873\n",
      "Iteration 2300, Loss: 3.0953891277313232\n",
      "Iteration 2400, Loss: 3.088114023208618\n",
      "Iteration 2500, Loss: 3.0809311866760254\n",
      "Iteration 2600, Loss: 3.0738608837127686\n",
      "Iteration 2700, Loss: 3.0668582916259766\n",
      "Iteration 2800, Loss: 3.0598700046539307\n",
      "Iteration 2900, Loss: 3.052870035171509\n",
      "Iteration 0, Loss: 3.168530225753784\n",
      "Iteration 100, Loss: 3.1050870418548584\n",
      "Iteration 200, Loss: 3.1605887413024902\n",
      "Iteration 300, Loss: 3.159761905670166\n",
      "Iteration 400, Loss: 3.1589815616607666\n",
      "Iteration 500, Loss: 3.1582562923431396\n",
      "Iteration 600, Loss: 3.157604932785034\n",
      "Iteration 700, Loss: 3.157022476196289\n",
      "Iteration 800, Loss: 3.156503915786743\n",
      "Iteration 900, Loss: 3.1560440063476562\n",
      "Iteration 1000, Loss: 3.155632972717285\n",
      "Iteration 1100, Loss: 3.1552677154541016\n",
      "Iteration 1200, Loss: 3.154938220977783\n",
      "Iteration 1300, Loss: 3.154641628265381\n",
      "Iteration 1400, Loss: 3.1543731689453125\n",
      "Iteration 1500, Loss: 3.1541271209716797\n",
      "Iteration 1600, Loss: 3.153903007507324\n",
      "Iteration 1700, Loss: 3.153698205947876\n",
      "Iteration 1800, Loss: 3.15350604057312\n",
      "Iteration 1900, Loss: 3.1533288955688477\n",
      "Iteration 2000, Loss: 3.153162956237793\n",
      "Iteration 2100, Loss: 3.1530065536499023\n",
      "Iteration 2200, Loss: 3.152857780456543\n",
      "Iteration 2300, Loss: 3.1527185440063477\n",
      "Iteration 2400, Loss: 3.152583599090576\n",
      "Iteration 2500, Loss: 3.1524558067321777\n",
      "Iteration 2600, Loss: 3.152332305908203\n",
      "Iteration 2700, Loss: 3.1522130966186523\n",
      "Iteration 2800, Loss: 3.152095079421997\n",
      "Iteration 2900, Loss: 3.1519813537597656\n",
      "Iteration 0, Loss: 3.081707000732422\n",
      "Iteration 100, Loss: 3.0505664348602295\n",
      "Iteration 200, Loss: 3.0572853088378906\n",
      "Iteration 300, Loss: 3.0442206859588623\n",
      "Iteration 400, Loss: 3.0255982875823975\n",
      "Iteration 500, Loss: 2.982286214828491\n",
      "Iteration 600, Loss: 3.046790599822998\n",
      "Iteration 700, Loss: 3.0426955223083496\n",
      "Iteration 800, Loss: 3.0383098125457764\n",
      "Iteration 900, Loss: 3.0329043865203857\n",
      "Iteration 1000, Loss: 3.025548219680786\n",
      "Iteration 1100, Loss: 3.014200210571289\n",
      "Iteration 1200, Loss: 2.9949262142181396\n",
      "Iteration 1300, Loss: 2.96372389793396\n",
      "Iteration 1400, Loss: 3.022155284881592\n",
      "Iteration 1500, Loss: 2.9981870651245117\n",
      "Iteration 1600, Loss: 2.9646708965301514\n",
      "Iteration 1700, Loss: 2.9211230278015137\n",
      "Iteration 1800, Loss: 2.888303518295288\n",
      "Iteration 1900, Loss: 2.8909494876861572\n",
      "Iteration 2000, Loss: 2.8952033519744873\n",
      "Iteration 2100, Loss: 2.8441014289855957\n",
      "Iteration 2200, Loss: 2.8268606662750244\n",
      "Iteration 2300, Loss: 2.9272427558898926\n",
      "Iteration 2400, Loss: 2.887701988220215\n",
      "Iteration 2500, Loss: 3.036281108856201\n",
      "Iteration 2600, Loss: 3.0275087356567383\n",
      "Iteration 2700, Loss: 3.018425703048706\n",
      "Iteration 2800, Loss: 3.004426956176758\n",
      "Iteration 2900, Loss: 2.976438283920288\n",
      "Iteration 0, Loss: 3.295438051223755\n",
      "Iteration 100, Loss: 3.260248899459839\n",
      "Iteration 200, Loss: 3.2088239192962646\n",
      "Iteration 300, Loss: 3.164308547973633\n",
      "Iteration 400, Loss: 3.1048529148101807\n",
      "Iteration 500, Loss: 3.1007139682769775\n",
      "Iteration 600, Loss: 3.0699806213378906\n",
      "Iteration 700, Loss: 3.054255247116089\n",
      "Iteration 800, Loss: 3.175034284591675\n",
      "Iteration 900, Loss: 3.0779154300689697\n",
      "Iteration 1000, Loss: 3.0466091632843018\n",
      "Iteration 1100, Loss: 3.0300984382629395\n",
      "Iteration 1200, Loss: 3.017240524291992\n",
      "Iteration 1300, Loss: 3.0059473514556885\n",
      "Iteration 1400, Loss: 2.99607515335083\n",
      "Iteration 1500, Loss: 2.9857311248779297\n",
      "Iteration 1600, Loss: 2.991374969482422\n",
      "Iteration 1700, Loss: 2.973245143890381\n",
      "Iteration 1800, Loss: 2.962080717086792\n",
      "Iteration 1900, Loss: 2.9545679092407227\n",
      "Iteration 2000, Loss: 2.945587635040283\n",
      "Iteration 2100, Loss: 2.943413019180298\n",
      "Iteration 2200, Loss: 2.9302096366882324\n",
      "Iteration 2300, Loss: 2.924992799758911\n",
      "Iteration 2400, Loss: 3.084832191467285\n",
      "Iteration 2500, Loss: 2.9303138256073\n",
      "Iteration 2600, Loss: 2.919029474258423\n",
      "Iteration 2700, Loss: 2.909148931503296\n",
      "Iteration 2800, Loss: 2.9091360569000244\n",
      "Iteration 2900, Loss: 2.8974814414978027\n",
      "Iteration 0, Loss: 3.252997398376465\n",
      "Iteration 100, Loss: 3.3069589138031006\n",
      "Iteration 200, Loss: 3.2276463508605957\n",
      "Iteration 300, Loss: 3.208789110183716\n",
      "Iteration 400, Loss: 3.178298234939575\n",
      "Iteration 500, Loss: 3.151000738143921\n",
      "Iteration 600, Loss: 3.193326234817505\n",
      "Iteration 700, Loss: 3.220365047454834\n",
      "Iteration 800, Loss: 3.1978163719177246\n",
      "Iteration 900, Loss: 3.1514735221862793\n",
      "Iteration 1000, Loss: 3.134650230407715\n",
      "Iteration 1100, Loss: 3.076570510864258\n",
      "Iteration 1200, Loss: 3.051154613494873\n",
      "Iteration 1300, Loss: 3.1435439586639404\n",
      "Iteration 1400, Loss: 3.2022621631622314\n",
      "Iteration 1500, Loss: 3.128157138824463\n",
      "Iteration 1600, Loss: 3.0708484649658203\n",
      "Iteration 1700, Loss: 3.0448451042175293\n",
      "Iteration 1800, Loss: 3.029898166656494\n",
      "Iteration 1900, Loss: 3.01898193359375\n",
      "Iteration 2000, Loss: 3.0106170177459717\n",
      "Iteration 2100, Loss: 3.003253936767578\n",
      "Iteration 2200, Loss: 3.0109410285949707\n",
      "Iteration 2300, Loss: 2.9987893104553223\n",
      "Iteration 2400, Loss: 2.9886438846588135\n",
      "Iteration 2500, Loss: 2.9810030460357666\n",
      "Iteration 2600, Loss: 2.9765329360961914\n",
      "Iteration 2700, Loss: 2.982701539993286\n",
      "Iteration 2800, Loss: 2.968252658843994\n",
      "Iteration 2900, Loss: 2.959291934967041\n",
      "Iteration 0, Loss: 3.2932820320129395\n",
      "Iteration 100, Loss: 3.170320510864258\n",
      "Iteration 200, Loss: 3.231802463531494\n",
      "Iteration 300, Loss: 3.2720890045166016\n",
      "Iteration 400, Loss: 3.2612502574920654\n",
      "Iteration 500, Loss: 3.230010986328125\n",
      "Iteration 600, Loss: 3.188323497772217\n",
      "Iteration 700, Loss: 3.1612677574157715\n",
      "Iteration 800, Loss: 3.1995656490325928\n",
      "Iteration 900, Loss: 3.128178119659424\n",
      "Iteration 1000, Loss: 3.2632765769958496\n",
      "Iteration 1100, Loss: 3.257464647293091\n",
      "Iteration 1200, Loss: 3.2483279705047607\n",
      "Iteration 1300, Loss: 3.228212833404541\n",
      "Iteration 1400, Loss: 3.1864359378814697\n",
      "Iteration 1500, Loss: 3.2509915828704834\n",
      "Iteration 1600, Loss: 3.24320125579834\n",
      "Iteration 1700, Loss: 3.2371017932891846\n",
      "Iteration 1800, Loss: 3.230242967605591\n",
      "Iteration 1900, Loss: 3.221195697784424\n",
      "Iteration 2000, Loss: 3.208503007888794\n",
      "Iteration 2100, Loss: 3.190171718597412\n",
      "Iteration 2200, Loss: 3.164297342300415\n",
      "Iteration 2300, Loss: 3.212284803390503\n",
      "Iteration 2400, Loss: 3.1568093299865723\n",
      "Iteration 2500, Loss: 3.119407892227173\n",
      "Iteration 2600, Loss: 3.227447509765625\n",
      "Iteration 2700, Loss: 3.1175923347473145\n",
      "Iteration 2800, Loss: 3.0753860473632812\n",
      "Iteration 2900, Loss: 3.0765960216522217\n",
      "Iteration 0, Loss: 3.2420616149902344\n",
      "Iteration 100, Loss: 3.1347908973693848\n",
      "Iteration 200, Loss: 3.2070391178131104\n",
      "Iteration 300, Loss: 3.129389762878418\n",
      "Iteration 400, Loss: 3.1944100856781006\n",
      "Iteration 500, Loss: 3.1079494953155518\n",
      "Iteration 600, Loss: 3.145063877105713\n",
      "Iteration 700, Loss: 3.0658228397369385\n",
      "Iteration 800, Loss: 3.07098650932312\n",
      "Iteration 900, Loss: 3.0085573196411133\n",
      "Iteration 1000, Loss: 2.987668991088867\n",
      "Iteration 1100, Loss: 2.972290515899658\n",
      "Iteration 1200, Loss: 2.9591641426086426\n",
      "Iteration 1300, Loss: 3.1667580604553223\n",
      "Iteration 1400, Loss: 3.0664618015289307\n",
      "Iteration 1500, Loss: 2.9894514083862305\n",
      "Iteration 1600, Loss: 2.964115858078003\n",
      "Iteration 1700, Loss: 2.9463634490966797\n",
      "Iteration 1800, Loss: 2.9295215606689453\n",
      "Iteration 1900, Loss: 2.9264914989471436\n",
      "Iteration 2000, Loss: 2.9205703735351562\n",
      "Iteration 2100, Loss: 2.9139018058776855\n",
      "Iteration 2200, Loss: 2.891477108001709\n",
      "Iteration 2300, Loss: 2.882780075073242\n",
      "Iteration 2400, Loss: 2.874424695968628\n",
      "Iteration 2500, Loss: 2.8641271591186523\n",
      "Iteration 2600, Loss: 2.8574860095977783\n",
      "Iteration 2700, Loss: 2.848763942718506\n",
      "Iteration 2800, Loss: 2.8436782360076904\n",
      "Iteration 2900, Loss: 2.83345103263855\n",
      "Iteration 0, Loss: 3.2185466289520264\n",
      "Iteration 100, Loss: 3.1818835735321045\n",
      "Iteration 200, Loss: 3.1839094161987305\n",
      "Iteration 300, Loss: 3.16312313079834\n",
      "Iteration 400, Loss: 3.03845477104187\n",
      "Iteration 500, Loss: 3.1645736694335938\n",
      "Iteration 600, Loss: 3.040088653564453\n",
      "Iteration 700, Loss: 2.998983144760132\n",
      "Iteration 800, Loss: 2.980170726776123\n",
      "Iteration 900, Loss: 2.9664034843444824\n",
      "Iteration 1000, Loss: 2.968623638153076\n",
      "Iteration 1100, Loss: 2.9430370330810547\n",
      "Iteration 1200, Loss: 2.9454126358032227\n",
      "Iteration 1300, Loss: 2.9197378158569336\n",
      "Iteration 1400, Loss: 2.910099744796753\n",
      "Iteration 1500, Loss: 2.897475242614746\n",
      "Iteration 1600, Loss: 2.8886101245880127\n",
      "Iteration 1700, Loss: 2.9073948860168457\n",
      "Iteration 1800, Loss: 2.8696072101593018\n",
      "Iteration 1900, Loss: 2.8598101139068604\n",
      "Iteration 2000, Loss: 2.8510820865631104\n",
      "Iteration 2100, Loss: 2.8413949012756348\n",
      "Iteration 2200, Loss: 2.8519198894500732\n",
      "Iteration 2300, Loss: 2.825512409210205\n",
      "Iteration 2400, Loss: 2.8279266357421875\n",
      "Iteration 2500, Loss: 2.8088324069976807\n",
      "Iteration 2600, Loss: 2.804924726486206\n",
      "Iteration 2700, Loss: 2.806384563446045\n",
      "Iteration 2800, Loss: 2.7931177616119385\n",
      "Iteration 2900, Loss: 2.7864139080047607\n",
      "Iteration 0, Loss: 3.25565767288208\n",
      "Iteration 100, Loss: 3.1757588386535645\n",
      "Iteration 200, Loss: 3.1430373191833496\n",
      "Iteration 300, Loss: 3.1321041584014893\n",
      "Iteration 400, Loss: 3.690659523010254\n",
      "Iteration 500, Loss: 3.1494853496551514\n",
      "Iteration 600, Loss: 3.095482110977173\n",
      "Iteration 700, Loss: 3.197591543197632\n",
      "Iteration 800, Loss: 3.0852086544036865\n",
      "Iteration 900, Loss: 3.0519819259643555\n",
      "Iteration 1000, Loss: 3.1494176387786865\n",
      "Iteration 1100, Loss: 3.0457990169525146\n",
      "Iteration 1200, Loss: 3.0296475887298584\n",
      "Iteration 1300, Loss: 3.0185060501098633\n",
      "Iteration 1400, Loss: 3.009173631668091\n",
      "Iteration 1500, Loss: 3.001530170440674\n",
      "Iteration 1600, Loss: 2.9925482273101807\n",
      "Iteration 1700, Loss: 2.982860803604126\n",
      "Iteration 1800, Loss: 2.9816622734069824\n",
      "Iteration 1900, Loss: 2.96980357170105\n",
      "Iteration 2000, Loss: 2.9592323303222656\n",
      "Iteration 2100, Loss: 2.948885440826416\n",
      "Iteration 2200, Loss: 2.9452481269836426\n",
      "Iteration 2300, Loss: 2.9307851791381836\n",
      "Iteration 2400, Loss: 2.9277567863464355\n",
      "Iteration 2500, Loss: 2.920644998550415\n",
      "Iteration 2600, Loss: 3.0187759399414062\n",
      "Iteration 2700, Loss: 3.047252655029297\n",
      "Iteration 2800, Loss: 2.957590341567993\n",
      "Iteration 2900, Loss: 2.9415178298950195\n",
      "Iteration 0, Loss: 3.435493230819702\n",
      "Iteration 100, Loss: 3.395575523376465\n",
      "Iteration 200, Loss: 3.3716909885406494\n",
      "Iteration 300, Loss: 3.353632926940918\n",
      "Iteration 400, Loss: 3.3337626457214355\n",
      "Iteration 500, Loss: 3.312039375305176\n",
      "Iteration 600, Loss: 3.29044508934021\n",
      "Iteration 700, Loss: 3.2720463275909424\n",
      "Iteration 800, Loss: 3.306722640991211\n",
      "Iteration 900, Loss: 3.255427122116089\n",
      "Iteration 1000, Loss: 3.3040828704833984\n",
      "Iteration 1100, Loss: 3.345240354537964\n",
      "Iteration 1200, Loss: 3.2949917316436768\n",
      "Iteration 1300, Loss: 3.345665693283081\n",
      "Iteration 1400, Loss: 3.2880072593688965\n",
      "Iteration 1500, Loss: 3.4035487174987793\n",
      "Iteration 1600, Loss: 3.3959617614746094\n",
      "Iteration 1700, Loss: 3.376028537750244\n",
      "Iteration 1800, Loss: 3.318082094192505\n",
      "Iteration 1900, Loss: 3.2672786712646484\n",
      "Iteration 2000, Loss: 3.2427549362182617\n",
      "Iteration 2100, Loss: 3.2292919158935547\n",
      "Iteration 2200, Loss: 3.220078945159912\n",
      "Iteration 2300, Loss: 3.2139766216278076\n",
      "Iteration 2400, Loss: 3.3082330226898193\n",
      "Iteration 2500, Loss: 3.250667095184326\n",
      "Iteration 2600, Loss: 3.2222886085510254\n",
      "Iteration 2700, Loss: 3.217576026916504\n",
      "Iteration 2800, Loss: 3.204906702041626\n",
      "Iteration 2900, Loss: 3.1975433826446533\n",
      "Iteration 0, Loss: 3.2751095294952393\n",
      "Iteration 100, Loss: 3.195838689804077\n",
      "Iteration 200, Loss: 3.2273504734039307\n",
      "Iteration 300, Loss: 3.235379219055176\n",
      "Iteration 400, Loss: 3.230203151702881\n",
      "Iteration 500, Loss: 3.188549041748047\n",
      "Iteration 600, Loss: 3.2130837440490723\n",
      "Iteration 700, Loss: 3.16005277633667\n",
      "Iteration 800, Loss: 3.230811357498169\n",
      "Iteration 900, Loss: 3.2255616188049316\n",
      "Iteration 1000, Loss: 3.2208707332611084\n",
      "Iteration 1100, Loss: 3.21525239944458\n",
      "Iteration 1200, Loss: 3.207240104675293\n",
      "Iteration 1300, Loss: 3.1939942836761475\n",
      "Iteration 1400, Loss: 3.1706039905548096\n",
      "Iteration 1500, Loss: 3.134697675704956\n",
      "Iteration 1600, Loss: 3.0949909687042236\n",
      "Iteration 1700, Loss: 3.227417230606079\n",
      "Iteration 1800, Loss: 3.218494176864624\n",
      "Iteration 1900, Loss: 3.2099413871765137\n",
      "Iteration 2000, Loss: 3.1937477588653564\n",
      "Iteration 2100, Loss: 3.155923366546631\n",
      "Iteration 2200, Loss: 3.104740619659424\n",
      "Iteration 2300, Loss: 3.066505193710327\n",
      "Iteration 2400, Loss: 3.1588916778564453\n",
      "Iteration 2500, Loss: 3.172368288040161\n",
      "Iteration 2600, Loss: 3.0690999031066895\n",
      "Iteration 2700, Loss: 3.0394177436828613\n",
      "Iteration 2800, Loss: 3.0227034091949463\n",
      "Iteration 2900, Loss: 3.0091755390167236\n",
      "Iteration 0, Loss: 3.1659693717956543\n",
      "Iteration 100, Loss: 3.1210460662841797\n",
      "Iteration 200, Loss: 3.1018638610839844\n",
      "Iteration 300, Loss: 3.140483856201172\n",
      "Iteration 400, Loss: 3.1378371715545654\n",
      "Iteration 500, Loss: 3.1345510482788086\n",
      "Iteration 600, Loss: 3.1287708282470703\n",
      "Iteration 700, Loss: 3.1169633865356445\n",
      "Iteration 800, Loss: 3.0920755863189697\n",
      "Iteration 900, Loss: 3.055448293685913\n",
      "Iteration 1000, Loss: 3.0222554206848145\n",
      "Iteration 1100, Loss: 2.9948325157165527\n",
      "Iteration 1200, Loss: 2.971933603286743\n",
      "Iteration 1300, Loss: 2.9532089233398438\n",
      "Iteration 1400, Loss: 2.938364028930664\n",
      "Iteration 1500, Loss: 2.9267401695251465\n",
      "Iteration 1600, Loss: 2.917560338973999\n",
      "Iteration 1700, Loss: 2.9101595878601074\n",
      "Iteration 1800, Loss: 2.9040331840515137\n",
      "Iteration 1900, Loss: 2.8988161087036133\n",
      "Iteration 2000, Loss: 2.894249439239502\n",
      "Iteration 2100, Loss: 2.890136480331421\n",
      "Iteration 2200, Loss: 2.8863308429718018\n",
      "Iteration 2300, Loss: 2.8827192783355713\n",
      "Iteration 2400, Loss: 2.8792171478271484\n",
      "Iteration 2500, Loss: 2.875751495361328\n",
      "Iteration 2600, Loss: 2.872260570526123\n",
      "Iteration 2700, Loss: 2.8687150478363037\n",
      "Iteration 2800, Loss: 2.8650827407836914\n",
      "Iteration 2900, Loss: 2.861337900161743\n",
      "Iteration 0, Loss: 3.357421636581421\n",
      "Iteration 100, Loss: 3.337958574295044\n",
      "Iteration 200, Loss: 3.3275201320648193\n",
      "Iteration 300, Loss: 3.2979228496551514\n",
      "Iteration 400, Loss: 3.3044137954711914\n",
      "Iteration 500, Loss: 3.3291118144989014\n",
      "Iteration 600, Loss: 3.3136396408081055\n",
      "Iteration 700, Loss: 3.287696599960327\n",
      "Iteration 800, Loss: 3.2359724044799805\n",
      "Iteration 900, Loss: 3.3003671169281006\n",
      "Iteration 1000, Loss: 3.259998083114624\n",
      "Iteration 1100, Loss: 3.3223378658294678\n",
      "Iteration 1200, Loss: 3.3131160736083984\n",
      "Iteration 1300, Loss: 3.3007311820983887\n",
      "Iteration 1400, Loss: 3.2781195640563965\n",
      "Iteration 1500, Loss: 3.2437069416046143\n",
      "Iteration 1600, Loss: 3.2100422382354736\n",
      "Iteration 1700, Loss: 3.1834616661071777\n",
      "Iteration 1800, Loss: 3.2843692302703857\n",
      "Iteration 1900, Loss: 3.2247390747070312\n",
      "Iteration 2000, Loss: 3.1755125522613525\n",
      "Iteration 2100, Loss: 3.152144193649292\n",
      "Iteration 2200, Loss: 3.1364378929138184\n",
      "Iteration 2300, Loss: 3.127120018005371\n",
      "Iteration 2400, Loss: 3.30094313621521\n",
      "Iteration 2500, Loss: 3.25266170501709\n",
      "Iteration 2600, Loss: 3.166152000427246\n",
      "Iteration 2700, Loss: 3.1259191036224365\n",
      "Iteration 2800, Loss: 3.109708547592163\n",
      "Iteration 2900, Loss: 3.098644256591797\n",
      "Iteration 0, Loss: 3.168617010116577\n",
      "Iteration 100, Loss: 3.0949649810791016\n",
      "Iteration 200, Loss: 3.0515427589416504\n",
      "Iteration 300, Loss: 3.015212059020996\n",
      "Iteration 400, Loss: 2.941983222961426\n",
      "Iteration 500, Loss: 2.9966654777526855\n",
      "Iteration 600, Loss: 2.9176509380340576\n",
      "Iteration 700, Loss: 3.048154354095459\n",
      "Iteration 800, Loss: 3.0299060344696045\n",
      "Iteration 900, Loss: 3.1103482246398926\n",
      "Iteration 1000, Loss: 3.067781448364258\n",
      "Iteration 1100, Loss: 3.088139533996582\n",
      "Iteration 1200, Loss: 3.022667646408081\n",
      "Iteration 1300, Loss: 3.1128642559051514\n",
      "Iteration 1400, Loss: 3.098480701446533\n",
      "Iteration 1500, Loss: 3.076601028442383\n",
      "Iteration 1600, Loss: 3.106804847717285\n",
      "Iteration 1700, Loss: 3.0689377784729004\n",
      "Iteration 1800, Loss: 3.1155614852905273\n",
      "Iteration 1900, Loss: 3.0906527042388916\n",
      "Iteration 2000, Loss: 3.0682945251464844\n",
      "Iteration 2100, Loss: 3.037959337234497\n",
      "Iteration 2200, Loss: 3.0890772342681885\n",
      "Iteration 2300, Loss: 3.0247204303741455\n",
      "Iteration 2400, Loss: 2.971302032470703\n",
      "Iteration 2500, Loss: 2.9971370697021484\n",
      "Iteration 2600, Loss: 2.9503536224365234\n",
      "Iteration 2700, Loss: 2.9371328353881836\n",
      "Iteration 2800, Loss: 2.919553518295288\n",
      "Iteration 2900, Loss: 2.9161977767944336\n",
      "Iteration 0, Loss: 3.1107447147369385\n",
      "Iteration 100, Loss: 3.086644411087036\n",
      "Iteration 200, Loss: 3.0839884281158447\n",
      "Iteration 300, Loss: 3.0811409950256348\n",
      "Iteration 400, Loss: 3.076197862625122\n",
      "Iteration 500, Loss: 3.0682997703552246\n",
      "Iteration 600, Loss: 3.057955503463745\n",
      "Iteration 700, Loss: 3.0459940433502197\n",
      "Iteration 800, Loss: 3.033393383026123\n",
      "Iteration 900, Loss: 3.0209574699401855\n",
      "Iteration 1000, Loss: 3.008701801300049\n",
      "Iteration 1100, Loss: 2.996440887451172\n",
      "Iteration 1200, Loss: 2.9841156005859375\n",
      "Iteration 1300, Loss: 2.9718127250671387\n",
      "Iteration 1400, Loss: 2.959702968597412\n",
      "Iteration 1500, Loss: 2.947962522506714\n",
      "Iteration 1600, Loss: 2.9367220401763916\n",
      "Iteration 1700, Loss: 2.9260683059692383\n",
      "Iteration 1800, Loss: 2.916064977645874\n",
      "Iteration 1900, Loss: 2.9068262577056885\n",
      "Iteration 2000, Loss: 2.8985610008239746\n",
      "Iteration 2100, Loss: 3.0655288696289062\n",
      "Iteration 2200, Loss: 3.013730525970459\n",
      "Iteration 2300, Loss: 2.9283320903778076\n",
      "Iteration 2400, Loss: 2.9009130001068115\n",
      "Iteration 2500, Loss: 2.888474464416504\n",
      "Iteration 2600, Loss: 2.8798794746398926\n",
      "Iteration 2700, Loss: 2.8727867603302\n",
      "Iteration 2800, Loss: 2.86653995513916\n",
      "Iteration 2900, Loss: 2.8609061241149902\n",
      "Iteration 0, Loss: 3.239617347717285\n",
      "Iteration 100, Loss: 3.215101957321167\n",
      "Iteration 200, Loss: 3.2139639854431152\n",
      "Iteration 300, Loss: 3.2108633518218994\n",
      "Iteration 400, Loss: 3.2059881687164307\n",
      "Iteration 500, Loss: 3.196575403213501\n",
      "Iteration 600, Loss: 3.1814968585968018\n",
      "Iteration 700, Loss: 3.163599729537964\n",
      "Iteration 800, Loss: 3.142700672149658\n",
      "Iteration 900, Loss: 3.11942195892334\n",
      "Iteration 1000, Loss: 3.095824718475342\n",
      "Iteration 1100, Loss: 3.0747194290161133\n",
      "Iteration 1200, Loss: 3.1378514766693115\n",
      "Iteration 1300, Loss: 3.085222005844116\n",
      "Iteration 1400, Loss: 3.059939384460449\n",
      "Iteration 1500, Loss: 3.0431740283966064\n",
      "Iteration 1600, Loss: 3.0312256813049316\n",
      "Iteration 1700, Loss: 3.021634578704834\n",
      "Iteration 1800, Loss: 3.013395309448242\n",
      "Iteration 1900, Loss: 3.0073370933532715\n",
      "Iteration 2000, Loss: 2.9997599124908447\n",
      "Iteration 2100, Loss: 3.196887254714966\n",
      "Iteration 2200, Loss: 3.1860392093658447\n",
      "Iteration 2300, Loss: 3.1662721633911133\n",
      "Iteration 2400, Loss: 3.123511552810669\n",
      "Iteration 2500, Loss: 3.06626558303833\n",
      "Iteration 2600, Loss: 3.027498483657837\n",
      "Iteration 2700, Loss: 3.0061540603637695\n",
      "Iteration 2800, Loss: 2.9932522773742676\n",
      "Iteration 2900, Loss: 2.9841763973236084\n",
      "Iteration 0, Loss: 3.3187191486358643\n",
      "Iteration 100, Loss: 3.2536747455596924\n",
      "Iteration 200, Loss: 3.2576546669006348\n",
      "Iteration 300, Loss: 3.267415761947632\n",
      "Iteration 400, Loss: 3.171368360519409\n",
      "Iteration 500, Loss: 3.262305736541748\n",
      "Iteration 600, Loss: 3.231257200241089\n",
      "Iteration 700, Loss: 3.20137095451355\n",
      "Iteration 800, Loss: 3.1801598072052\n",
      "Iteration 900, Loss: 3.162585973739624\n",
      "Iteration 1000, Loss: 3.146904945373535\n",
      "Iteration 1100, Loss: 3.132845163345337\n",
      "Iteration 1200, Loss: 3.120328187942505\n",
      "Iteration 1300, Loss: 3.1092045307159424\n",
      "Iteration 1400, Loss: 3.099393129348755\n",
      "Iteration 1500, Loss: 3.0912954807281494\n",
      "Iteration 1600, Loss: 3.083570957183838\n",
      "Iteration 1700, Loss: 3.076587200164795\n",
      "Iteration 1800, Loss: 3.0700809955596924\n",
      "Iteration 1900, Loss: 3.063945770263672\n",
      "Iteration 2000, Loss: 3.0580966472625732\n",
      "Iteration 2100, Loss: 3.0524864196777344\n",
      "Iteration 2200, Loss: 3.0470712184906006\n",
      "Iteration 2300, Loss: 3.04178524017334\n",
      "Iteration 2400, Loss: 3.036667585372925\n",
      "Iteration 2500, Loss: 3.117543935775757\n",
      "Iteration 2600, Loss: 3.2086901664733887\n",
      "Iteration 2700, Loss: 3.2170944213867188\n",
      "Iteration 2800, Loss: 3.2437140941619873\n",
      "Iteration 2900, Loss: 3.2312350273132324\n",
      "Iteration 0, Loss: 3.2423102855682373\n",
      "Iteration 100, Loss: 3.1879875659942627\n",
      "Iteration 200, Loss: 3.170346260070801\n",
      "Iteration 300, Loss: 3.2032554149627686\n",
      "Iteration 400, Loss: 3.1480796337127686\n",
      "Iteration 500, Loss: 3.181203603744507\n",
      "Iteration 600, Loss: 3.2074966430664062\n",
      "Iteration 700, Loss: 3.195298433303833\n",
      "Iteration 800, Loss: 3.109102964401245\n",
      "Iteration 900, Loss: 3.205585479736328\n",
      "Iteration 1000, Loss: 3.1940836906433105\n",
      "Iteration 1100, Loss: 3.178640842437744\n",
      "Iteration 1200, Loss: 3.152920961380005\n",
      "Iteration 1300, Loss: 3.1900134086608887\n",
      "Iteration 1400, Loss: 3.139040946960449\n",
      "Iteration 1500, Loss: 3.089158058166504\n",
      "Iteration 1600, Loss: 3.1290862560272217\n",
      "Iteration 1700, Loss: 3.067282199859619\n",
      "Iteration 1800, Loss: 3.1857151985168457\n",
      "Iteration 1900, Loss: 3.03583025932312\n",
      "Iteration 2000, Loss: 3.0053961277008057\n",
      "Iteration 2100, Loss: 3.189241647720337\n",
      "Iteration 2200, Loss: 3.1819417476654053\n",
      "Iteration 2300, Loss: 3.1732122898101807\n",
      "Iteration 2400, Loss: 3.1615748405456543\n",
      "Iteration 2500, Loss: 3.1453306674957275\n",
      "Iteration 2600, Loss: 3.1234965324401855\n",
      "Iteration 2700, Loss: 3.0983660221099854\n",
      "Iteration 2800, Loss: 3.160597801208496\n",
      "Iteration 2900, Loss: 3.1389644145965576\n",
      "Iteration 0, Loss: 3.259336233139038\n",
      "Iteration 100, Loss: 3.225985527038574\n",
      "Iteration 200, Loss: 3.2153384685516357\n",
      "Iteration 300, Loss: 3.173797130584717\n",
      "Iteration 400, Loss: 3.2123095989227295\n",
      "Iteration 500, Loss: 3.2278640270233154\n",
      "Iteration 600, Loss: 3.181419610977173\n",
      "Iteration 700, Loss: 3.1788647174835205\n",
      "Iteration 800, Loss: 3.190546989440918\n",
      "Iteration 900, Loss: 3.224813938140869\n",
      "Iteration 1000, Loss: 3.173288345336914\n",
      "Iteration 1100, Loss: 3.2244510650634766\n",
      "Iteration 1200, Loss: 3.205385446548462\n",
      "Iteration 1300, Loss: 3.155153512954712\n",
      "Iteration 1400, Loss: 3.2102816104888916\n",
      "Iteration 1500, Loss: 3.1662063598632812\n",
      "Iteration 1600, Loss: 3.186218500137329\n",
      "Iteration 1700, Loss: 3.193117618560791\n",
      "Iteration 1800, Loss: 3.18497896194458\n",
      "Iteration 1900, Loss: 3.226585865020752\n",
      "Iteration 2000, Loss: 3.2136712074279785\n",
      "Iteration 2100, Loss: 3.168947219848633\n",
      "Iteration 2200, Loss: 3.220555543899536\n",
      "Iteration 2300, Loss: 3.203495740890503\n",
      "Iteration 2400, Loss: 3.170844554901123\n",
      "Iteration 2500, Loss: 3.1975290775299072\n",
      "Iteration 2600, Loss: 3.151093006134033\n",
      "Iteration 2700, Loss: 3.198888063430786\n",
      "Iteration 2800, Loss: 3.160726308822632\n",
      "Iteration 2900, Loss: 3.2177734375\n"
     ]
    }
   ],
   "source": [
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin_pmd.mat')['XA']\n",
    "\n",
    "C_on_perm=np.empty([Xall.shape[0],Xall.shape[0],50])\n",
    "loss_on_perm=np.zeros((50))\n",
    "angpermscore=np.zeros((50))\n",
    "for perm in range(50):\n",
    "    Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin_pmd.mat')['XA']\n",
    "    Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_fullwin_pmd.mat')['YA']\n",
    "\n",
    "    X=torch.from_numpy(np.float32(Xall))\n",
    "    n = X.size(0)\n",
    "\n",
    "    #apply rotation using random skew symmetric orthogonal transform\n",
    "    Aa=np.random.randn(n,n)\n",
    "    Yall=cayley_numpy(Aa-Aa.T)*Yall * scipy.linalg.inv(cayley_numpy(Aa-Aa.T))\n",
    "\n",
    "    Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "    # Initialize a skew-symmetric matrix A\n",
    "\n",
    "    A = torch.randn((n, n), requires_grad=True)\n",
    "    A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "    # Use ADAM optimizer\n",
    "    optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "        C = cayley_transform(A)\n",
    "        loss = loss_function(X, Y, C)\n",
    "\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update A using gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "    # Final optimized C\n",
    "    C_perm = cayley_transform(A)\n",
    "    C_perm=C_perm.detach().numpy()\n",
    "    C_on_perm[:,:,perm]=C_perm\n",
    "    losstmp = loss.detach().numpy()\n",
    "    loss_on_perm[perm]=losstmp\n",
    "\n",
    "    #compute angular\n",
    "    num = np.trace(X.detach().numpy().T @ C_perm @ Y.detach().numpy() @ np.linalg.inv(C_perm))\n",
    "\n",
    "\n",
    "    denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "    denom=denom.detach().numpy()\n",
    "    angpermscore[perm] = np.cos(np.arccos(num/denom))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_fullwin_pmd.mat')['XA']\n",
    "Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_fullwin_pmd.mat')['YA']\n",
    "\n",
    "\n",
    "\n",
    "mdic = {'optimizedC':[C_optimized],'optoloss':[Optimized_loss],'angularoptimal': [angoptimalscore],'loss_on_perm_random': [loss_on_perm],'C_on_perm' : [C_on_perm],'angperscore': [angpermscore],'Xall':[Xall],'Yall':[Yall]}\n",
    "savemat(DataFold+'/C_optimized_full_dmd_PMD.mat',mdic)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "xlim=(-.6, .6)\n",
    "ylim=(-.6, .6)\n",
    "nxpts=9\n",
    "nypts=9\n",
    "alpha=0.8\n",
    "ax=None\n",
    "figsize=(3, 3)\n",
    "\n",
    "\n",
    "x = np.linspace(*xlim, nxpts)\n",
    "y = np.linspace(*ylim, nypts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "xy = np.column_stack((X.ravel(), Y.ravel()))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "dxydt = xy.dot(Xall[0:2,0:2])-xy\n",
    "\n",
    "ax.quiver(xy[:, 0], xy[:, 1], dxydt[:, 0], dxydt[:, 1],color=colors[0])\n",
    "\n",
    "\n",
    "dxydt = xy.dot(Yall[0:2,0:2])-xy\n",
    "\n",
    "ax.quiver(xy[:, 0], xy[:, 1], dxydt[:, 0], dxydt[:, 1],  color=colors[1])\n",
    "\n",
    "\n",
    "# split plot\n",
    "\n",
    "Yprime=C_optimized@Yall@np.linalg.inv(C_optimized)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "dxydt = xy.dot(Xall[0:2,0:2])-xy\n",
    "\n",
    "ax.quiver(xy[:, 0], xy[:, 1], dxydt[:, 0], dxydt[:, 1],color=colors[0])\n",
    "\n",
    "\n",
    "dxydt = xy.dot(Yprime[0:2,0:2])-xy\n",
    "\n",
    "ax.quiver(xy[:, 0], xy[:, 1], dxydt[:, 0], dxydt[:, 1],  color=colors[1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
