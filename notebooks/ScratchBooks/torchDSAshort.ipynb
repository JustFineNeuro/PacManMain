{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def frobenius_norm(tensor):\n",
    "    return torch.norm(tensor, 'fro')\n",
    "\n",
    "\n",
    "def loss_function(X, Y, C):\n",
    "    return frobenius_norm(X - C @ Y @ C.inverse())\n",
    "\n",
    "\n",
    "def cayley_transform(A):\n",
    "    I = torch.eye(A.size(0), dtype=A.dtype, device=A.device)\n",
    "    return torch.linalg.solve(I + A, I - A)\n",
    "\n",
    "def cayley_numpy(A):\n",
    "    I =np.eye((Aa-Aa.T).shape[0])\n",
    "    return np.linalg.solve(I+A,I-A)\n",
    "\n",
    "learning_rate = 0.01\n",
    "max_iterations = 1500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now do DSA with A~ high components models with ncomps=116 (80% variance in PODs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps.mat')['XA']\n",
    "Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps.mat')['YA']\n",
    "\n",
    "\n",
    "X=torch.from_numpy(np.float32(Xall))\n",
    "Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "\n",
    "max_iterations=3000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run DSA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/envs/main/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 3.543290376663208\n",
      "Iteration 100, Loss: 2.5587775707244873\n",
      "Iteration 200, Loss: 2.1216747760772705\n",
      "Iteration 300, Loss: 1.893959403038025\n",
      "Iteration 400, Loss: 1.7469725608825684\n",
      "Iteration 500, Loss: 1.638789415359497\n",
      "Iteration 600, Loss: 1.5567067861557007\n",
      "Iteration 700, Loss: 1.4933186769485474\n",
      "Iteration 800, Loss: 1.4388370513916016\n",
      "Iteration 900, Loss: 1.392980694770813\n",
      "Iteration 1000, Loss: 1.3530372381210327\n",
      "Iteration 1100, Loss: 1.3185499906539917\n",
      "Iteration 1200, Loss: 1.2924251556396484\n",
      "Iteration 1300, Loss: 1.265633225440979\n",
      "Iteration 1400, Loss: 1.240638256072998\n",
      "Iteration 1500, Loss: 1.2199738025665283\n",
      "Iteration 1600, Loss: 1.198548436164856\n",
      "Iteration 1700, Loss: 1.177392601966858\n",
      "Iteration 1800, Loss: 1.1614265441894531\n",
      "Iteration 1900, Loss: 1.1435043811798096\n",
      "Iteration 2000, Loss: 1.128136157989502\n",
      "Iteration 2100, Loss: 1.1101489067077637\n",
      "Iteration 2200, Loss: 1.0958455801010132\n",
      "Iteration 2300, Loss: 1.0833172798156738\n",
      "Iteration 2400, Loss: 1.0711603164672852\n",
      "Iteration 2500, Loss: 1.0556974411010742\n",
      "Iteration 2600, Loss: 1.0447838306427002\n",
      "Iteration 2700, Loss: 1.0367470979690552\n",
      "Iteration 2800, Loss: 1.0242608785629272\n",
      "Iteration 2900, Loss: 1.01363205909729\n"
     ]
    }
   ],
   "source": [
    "n = X.size(0)\n",
    "\n",
    "# Initialize a skew-symmetric matrix A\n",
    "\n",
    "A = torch.randn((n, n), requires_grad=True)\n",
    "A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "# Use ADAM optimizer\n",
    "optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "    C = cayley_transform(A)\n",
    "    loss = loss_function(X, Y, C)\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update A using gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration % 100 == 0:\n",
    "        print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "# Final optimized C\n",
    "C_optimized = cayley_transform(A)\n",
    "C_optimized=C_optimized.detach().numpy()\n",
    "Optimized_loss=loss.detach().numpy()\n",
    "\n",
    "#compute angular\n",
    "num = np.trace(X.detach().numpy().T @ C_optimized @ Y.detach().numpy() @ np.linalg.inv(C_optimized))\n",
    "\n",
    "\n",
    "denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "denom=denom.detach().numpy()\n",
    "angoptimalscore = np.cos(np.arccos(num/denom))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "50:50 split comparison within system now"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perm with random x 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 3.156742811203003\n",
      "Iteration 100, Loss: 2.9119744300842285\n",
      "Iteration 200, Loss: 2.8325586318969727\n",
      "Iteration 300, Loss: 2.7709357738494873\n",
      "Iteration 400, Loss: 2.7277019023895264\n",
      "Iteration 500, Loss: 2.700035572052002\n",
      "Iteration 600, Loss: 2.6897881031036377\n",
      "Iteration 700, Loss: 2.6406564712524414\n",
      "Iteration 800, Loss: 2.62481427192688\n",
      "Iteration 900, Loss: 2.6052916049957275\n",
      "Iteration 1000, Loss: 2.594083786010742\n",
      "Iteration 1100, Loss: 2.574978828430176\n",
      "Iteration 1200, Loss: 2.5598013401031494\n",
      "Iteration 1300, Loss: 2.553746223449707\n",
      "Iteration 1400, Loss: 2.540450096130371\n",
      "Iteration 1500, Loss: 2.530935764312744\n",
      "Iteration 1600, Loss: 2.521026611328125\n",
      "Iteration 1700, Loss: 2.510446310043335\n",
      "Iteration 1800, Loss: 2.5034849643707275\n",
      "Iteration 1900, Loss: 2.4963228702545166\n",
      "Iteration 2000, Loss: 2.4852254390716553\n",
      "Iteration 2100, Loss: 2.476865291595459\n",
      "Iteration 2200, Loss: 2.473109722137451\n",
      "Iteration 2300, Loss: 2.4665677547454834\n",
      "Iteration 2400, Loss: 2.457742214202881\n",
      "Iteration 2500, Loss: 2.44992733001709\n",
      "Iteration 2600, Loss: 2.4435956478118896\n",
      "Iteration 2700, Loss: 2.4405882358551025\n",
      "Iteration 2800, Loss: 2.4351232051849365\n",
      "Iteration 2900, Loss: 2.427443265914917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/_yg34tj15s306l4m7k_wf0qw0000gq/T/ipykernel_44290/3063630798.py:55: RuntimeWarning: invalid value encountered in arccos\n",
      "  angpermscore[perm] = np.cos(np.arccos(num/denom))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 3.1366727352142334\n",
      "Iteration 100, Loss: 2.9348220825195312\n",
      "Iteration 200, Loss: 2.8553154468536377\n",
      "Iteration 300, Loss: 2.8125646114349365\n",
      "Iteration 400, Loss: 2.7720718383789062\n",
      "Iteration 500, Loss: 2.7519423961639404\n",
      "Iteration 600, Loss: 2.7258260250091553\n",
      "Iteration 700, Loss: 2.6893670558929443\n",
      "Iteration 800, Loss: 2.677729606628418\n",
      "Iteration 900, Loss: 2.645343065261841\n",
      "Iteration 1000, Loss: 2.6419050693511963\n",
      "Iteration 1100, Loss: 2.6219730377197266\n",
      "Iteration 1200, Loss: 2.607372760772705\n",
      "Iteration 1300, Loss: 2.587630033493042\n",
      "Iteration 1400, Loss: 2.628061294555664\n",
      "Iteration 1500, Loss: 2.571596384048462\n",
      "Iteration 1600, Loss: 2.5628223419189453\n",
      "Iteration 1700, Loss: 2.5498476028442383\n",
      "Iteration 1800, Loss: 2.5393435955047607\n",
      "Iteration 1900, Loss: 2.5388803482055664\n",
      "Iteration 2000, Loss: 2.521383762359619\n",
      "Iteration 2100, Loss: 2.539430618286133\n",
      "Iteration 2200, Loss: 2.5137085914611816\n",
      "Iteration 2300, Loss: 2.5104329586029053\n",
      "Iteration 2400, Loss: 2.519509792327881\n",
      "Iteration 2500, Loss: 2.491983413696289\n",
      "Iteration 2600, Loss: 2.48882794380188\n",
      "Iteration 2700, Loss: 2.4848859310150146\n",
      "Iteration 2800, Loss: 2.4729206562042236\n",
      "Iteration 2900, Loss: 2.481527090072632\n",
      "Iteration 0, Loss: 3.3211305141448975\n",
      "Iteration 100, Loss: 3.086596727371216\n",
      "Iteration 200, Loss: 3.0330569744110107\n",
      "Iteration 300, Loss: 2.9705963134765625\n",
      "Iteration 400, Loss: 2.922851324081421\n",
      "Iteration 500, Loss: 2.90700626373291\n",
      "Iteration 600, Loss: 2.897845506668091\n",
      "Iteration 700, Loss: 2.853017568588257\n",
      "Iteration 800, Loss: 2.8391599655151367\n",
      "Iteration 900, Loss: 2.825078248977661\n",
      "Iteration 1000, Loss: 2.8057796955108643\n",
      "Iteration 1100, Loss: 2.805201530456543\n",
      "Iteration 1200, Loss: 2.7819554805755615\n",
      "Iteration 1300, Loss: 2.784874677658081\n",
      "Iteration 1400, Loss: 2.765592336654663\n",
      "Iteration 1500, Loss: 2.75492000579834\n",
      "Iteration 1600, Loss: 2.7485406398773193\n",
      "Iteration 1700, Loss: 2.7375264167785645\n",
      "Iteration 1800, Loss: 2.7422585487365723\n",
      "Iteration 1900, Loss: 2.7289628982543945\n",
      "Iteration 2000, Loss: 2.7196381092071533\n",
      "Iteration 2100, Loss: 2.711073398590088\n",
      "Iteration 2200, Loss: 2.7107648849487305\n",
      "Iteration 2300, Loss: 2.701587438583374\n",
      "Iteration 2400, Loss: 2.6959099769592285\n",
      "Iteration 2500, Loss: 2.692007303237915\n",
      "Iteration 2600, Loss: 2.6833457946777344\n",
      "Iteration 2700, Loss: 2.6752874851226807\n",
      "Iteration 2800, Loss: 2.6705942153930664\n",
      "Iteration 2900, Loss: 2.6675662994384766\n",
      "Iteration 0, Loss: 3.163609743118286\n",
      "Iteration 100, Loss: 2.9545938968658447\n",
      "Iteration 200, Loss: 2.890941858291626\n",
      "Iteration 300, Loss: 2.843038558959961\n",
      "Iteration 400, Loss: 2.817166805267334\n",
      "Iteration 500, Loss: 2.7784247398376465\n",
      "Iteration 600, Loss: 2.7497048377990723\n",
      "Iteration 700, Loss: 2.7309141159057617\n",
      "Iteration 800, Loss: 2.704674005508423\n",
      "Iteration 900, Loss: 2.6950740814208984\n",
      "Iteration 1000, Loss: 2.6785264015197754\n",
      "Iteration 1100, Loss: 2.6640818119049072\n",
      "Iteration 1200, Loss: 2.6534745693206787\n",
      "Iteration 1300, Loss: 2.6417975425720215\n",
      "Iteration 1400, Loss: 2.6344897747039795\n",
      "Iteration 1500, Loss: 2.6172266006469727\n",
      "Iteration 1600, Loss: 2.5923104286193848\n",
      "Iteration 1700, Loss: 2.586611747741699\n",
      "Iteration 1800, Loss: 2.5779223442077637\n",
      "Iteration 1900, Loss: 2.5882036685943604\n",
      "Iteration 2000, Loss: 2.561190605163574\n",
      "Iteration 2100, Loss: 2.5491554737091064\n",
      "Iteration 2200, Loss: 2.584813356399536\n",
      "Iteration 2300, Loss: 2.5385019779205322\n",
      "Iteration 2400, Loss: 2.5352158546447754\n",
      "Iteration 2500, Loss: 2.521707057952881\n",
      "Iteration 2600, Loss: 2.520050287246704\n",
      "Iteration 2700, Loss: 2.5142149925231934\n",
      "Iteration 2800, Loss: 2.5090279579162598\n",
      "Iteration 2900, Loss: 2.5022337436676025\n",
      "Iteration 0, Loss: 3.1796274185180664\n",
      "Iteration 100, Loss: 2.9258623123168945\n",
      "Iteration 200, Loss: 2.9188833236694336\n",
      "Iteration 300, Loss: 2.8103981018066406\n",
      "Iteration 400, Loss: 2.7646656036376953\n",
      "Iteration 500, Loss: 2.7301080226898193\n",
      "Iteration 600, Loss: 2.6972925662994385\n",
      "Iteration 700, Loss: 2.6802380084991455\n",
      "Iteration 800, Loss: 2.6623592376708984\n",
      "Iteration 900, Loss: 2.6305458545684814\n",
      "Iteration 1000, Loss: 2.621450901031494\n",
      "Iteration 1100, Loss: 2.604729175567627\n",
      "Iteration 1200, Loss: 2.58562970161438\n",
      "Iteration 1300, Loss: 2.5796544551849365\n",
      "Iteration 1400, Loss: 2.56793212890625\n",
      "Iteration 1500, Loss: 2.556952953338623\n",
      "Iteration 1600, Loss: 2.545830488204956\n",
      "Iteration 1700, Loss: 2.540409803390503\n",
      "Iteration 1800, Loss: 2.5345335006713867\n",
      "Iteration 1900, Loss: 2.5234148502349854\n",
      "Iteration 2000, Loss: 2.519509792327881\n",
      "Iteration 2100, Loss: 2.5111567974090576\n",
      "Iteration 2200, Loss: 2.503941059112549\n",
      "Iteration 2300, Loss: 2.5005788803100586\n",
      "Iteration 2400, Loss: 2.495490789413452\n",
      "Iteration 2500, Loss: 2.4904115200042725\n",
      "Iteration 2600, Loss: 2.4854509830474854\n",
      "Iteration 2700, Loss: 2.478029489517212\n",
      "Iteration 2800, Loss: 2.4742250442504883\n",
      "Iteration 2900, Loss: 2.4686646461486816\n",
      "Iteration 0, Loss: 3.202810049057007\n",
      "Iteration 100, Loss: 2.993112564086914\n",
      "Iteration 200, Loss: 2.9193646907806396\n",
      "Iteration 300, Loss: 2.891671895980835\n",
      "Iteration 400, Loss: 2.843240976333618\n",
      "Iteration 500, Loss: 2.832226514816284\n",
      "Iteration 600, Loss: 2.7976467609405518\n",
      "Iteration 700, Loss: 2.7783291339874268\n",
      "Iteration 800, Loss: 2.761824369430542\n",
      "Iteration 900, Loss: 2.739802122116089\n",
      "Iteration 1000, Loss: 2.720667839050293\n",
      "Iteration 1100, Loss: 2.72161602973938\n",
      "Iteration 1200, Loss: 2.698450803756714\n",
      "Iteration 1300, Loss: 2.6825790405273438\n",
      "Iteration 1400, Loss: 2.677168130874634\n",
      "Iteration 1500, Loss: 2.658848285675049\n",
      "Iteration 1600, Loss: 2.6571500301361084\n",
      "Iteration 1700, Loss: 2.64483642578125\n",
      "Iteration 1800, Loss: 2.635291576385498\n",
      "Iteration 1900, Loss: 2.6276373863220215\n",
      "Iteration 2000, Loss: 2.621469259262085\n",
      "Iteration 2100, Loss: 2.6109557151794434\n",
      "Iteration 2200, Loss: 2.6049396991729736\n",
      "Iteration 2300, Loss: 2.601760149002075\n",
      "Iteration 2400, Loss: 2.5901987552642822\n",
      "Iteration 2500, Loss: 2.5865328311920166\n",
      "Iteration 2600, Loss: 2.578972339630127\n",
      "Iteration 2700, Loss: 2.5765950679779053\n",
      "Iteration 2800, Loss: 2.5671114921569824\n",
      "Iteration 2900, Loss: 2.5602986812591553\n",
      "Iteration 0, Loss: 3.3588175773620605\n",
      "Iteration 100, Loss: 3.119492769241333\n",
      "Iteration 200, Loss: 3.0502068996429443\n",
      "Iteration 300, Loss: 2.9921443462371826\n",
      "Iteration 400, Loss: 2.9541175365448\n",
      "Iteration 500, Loss: 2.9292845726013184\n",
      "Iteration 600, Loss: 2.8946518898010254\n",
      "Iteration 700, Loss: 2.8714160919189453\n",
      "Iteration 800, Loss: 2.8514583110809326\n",
      "Iteration 900, Loss: 2.835787296295166\n",
      "Iteration 1000, Loss: 2.8204140663146973\n",
      "Iteration 1100, Loss: 2.804494857788086\n",
      "Iteration 1200, Loss: 2.7929275035858154\n",
      "Iteration 1300, Loss: 2.782289981842041\n",
      "Iteration 1400, Loss: 2.770742416381836\n",
      "Iteration 1500, Loss: 2.762432813644409\n",
      "Iteration 1600, Loss: 2.7491326332092285\n",
      "Iteration 1700, Loss: 2.754117965698242\n",
      "Iteration 1800, Loss: 2.7332940101623535\n",
      "Iteration 1900, Loss: 2.729184627532959\n",
      "Iteration 2000, Loss: 2.720187187194824\n",
      "Iteration 2100, Loss: 2.7142181396484375\n",
      "Iteration 2200, Loss: 2.707287549972534\n",
      "Iteration 2300, Loss: 2.702507734298706\n",
      "Iteration 2400, Loss: 2.696364164352417\n",
      "Iteration 2500, Loss: 2.6910860538482666\n",
      "Iteration 2600, Loss: 2.6855874061584473\n",
      "Iteration 2700, Loss: 2.685192823410034\n",
      "Iteration 2800, Loss: 2.6750872135162354\n",
      "Iteration 2900, Loss: 2.6723623275756836\n",
      "Iteration 0, Loss: 3.2026593685150146\n",
      "Iteration 100, Loss: 2.9879276752471924\n",
      "Iteration 200, Loss: 2.8912644386291504\n",
      "Iteration 300, Loss: 2.838515043258667\n",
      "Iteration 400, Loss: 2.7973854541778564\n",
      "Iteration 500, Loss: 2.7683229446411133\n",
      "Iteration 600, Loss: 2.74875545501709\n",
      "Iteration 700, Loss: 2.7137930393218994\n",
      "Iteration 800, Loss: 2.6978461742401123\n",
      "Iteration 900, Loss: 2.682157039642334\n",
      "Iteration 1000, Loss: 2.6634721755981445\n",
      "Iteration 1100, Loss: 2.6448400020599365\n",
      "Iteration 1200, Loss: 2.6378211975097656\n",
      "Iteration 1300, Loss: 2.6221282482147217\n",
      "Iteration 1400, Loss: 2.6083266735076904\n",
      "Iteration 1500, Loss: 2.598475456237793\n",
      "Iteration 1600, Loss: 2.5895168781280518\n",
      "Iteration 1700, Loss: 2.5804240703582764\n",
      "Iteration 1800, Loss: 2.573852777481079\n",
      "Iteration 1900, Loss: 2.564828634262085\n",
      "Iteration 2000, Loss: 2.5515079498291016\n",
      "Iteration 2100, Loss: 2.548114776611328\n",
      "Iteration 2200, Loss: 2.539367914199829\n",
      "Iteration 2300, Loss: 2.5302963256835938\n",
      "Iteration 2400, Loss: 2.5249035358428955\n",
      "Iteration 2500, Loss: 2.51785945892334\n",
      "Iteration 2600, Loss: 2.5099937915802\n",
      "Iteration 2700, Loss: 2.505341053009033\n",
      "Iteration 2800, Loss: 2.4972639083862305\n",
      "Iteration 2900, Loss: 2.4938838481903076\n",
      "Iteration 0, Loss: 3.212632894515991\n",
      "Iteration 100, Loss: 2.933354139328003\n",
      "Iteration 200, Loss: 2.8571290969848633\n",
      "Iteration 300, Loss: 2.803135633468628\n",
      "Iteration 400, Loss: 2.766859769821167\n",
      "Iteration 500, Loss: 2.73234486579895\n",
      "Iteration 600, Loss: 2.708540201187134\n",
      "Iteration 700, Loss: 2.6856110095977783\n",
      "Iteration 800, Loss: 2.6664228439331055\n",
      "Iteration 900, Loss: 2.652444362640381\n",
      "Iteration 1000, Loss: 2.6323647499084473\n",
      "Iteration 1100, Loss: 2.6197869777679443\n",
      "Iteration 1200, Loss: 2.609017848968506\n",
      "Iteration 1300, Loss: 2.5962390899658203\n",
      "Iteration 1400, Loss: 2.5837180614471436\n",
      "Iteration 1500, Loss: 2.570533037185669\n",
      "Iteration 1600, Loss: 2.567051887512207\n",
      "Iteration 1700, Loss: 2.557076930999756\n",
      "Iteration 1800, Loss: 2.548438310623169\n",
      "Iteration 1900, Loss: 2.5431430339813232\n",
      "Iteration 2000, Loss: 2.532379627227783\n",
      "Iteration 2100, Loss: 2.5255165100097656\n",
      "Iteration 2200, Loss: 2.518052339553833\n",
      "Iteration 2300, Loss: 2.5101795196533203\n",
      "Iteration 2400, Loss: 2.505380868911743\n",
      "Iteration 2500, Loss: 2.4979865550994873\n",
      "Iteration 2600, Loss: 2.503767967224121\n",
      "Iteration 2700, Loss: 2.50179386138916\n",
      "Iteration 2800, Loss: 2.4865527153015137\n",
      "Iteration 2900, Loss: 2.4811363220214844\n",
      "Iteration 0, Loss: 3.2065927982330322\n",
      "Iteration 100, Loss: 3.026388168334961\n",
      "Iteration 200, Loss: 2.906306266784668\n",
      "Iteration 300, Loss: 2.8731698989868164\n",
      "Iteration 400, Loss: 2.8139028549194336\n",
      "Iteration 500, Loss: 2.7863335609436035\n",
      "Iteration 600, Loss: 2.7526774406433105\n",
      "Iteration 700, Loss: 2.7265701293945312\n",
      "Iteration 800, Loss: 2.7098424434661865\n",
      "Iteration 900, Loss: 2.6905078887939453\n",
      "Iteration 1000, Loss: 2.669254779815674\n",
      "Iteration 1100, Loss: 2.6556355953216553\n",
      "Iteration 1200, Loss: 2.642747163772583\n",
      "Iteration 1300, Loss: 2.6311230659484863\n",
      "Iteration 1400, Loss: 2.6191787719726562\n",
      "Iteration 1500, Loss: 2.605602741241455\n",
      "Iteration 1600, Loss: 2.6044185161590576\n",
      "Iteration 1700, Loss: 2.5933845043182373\n",
      "Iteration 1800, Loss: 2.585040330886841\n",
      "Iteration 1900, Loss: 2.5739381313323975\n",
      "Iteration 2000, Loss: 2.568462371826172\n",
      "Iteration 2100, Loss: 2.5627553462982178\n",
      "Iteration 2200, Loss: 2.550083637237549\n",
      "Iteration 2300, Loss: 2.545596122741699\n",
      "Iteration 2400, Loss: 2.542175054550171\n",
      "Iteration 2500, Loss: 2.5355889797210693\n",
      "Iteration 2600, Loss: 2.5374209880828857\n",
      "Iteration 2700, Loss: 2.526702642440796\n",
      "Iteration 2800, Loss: 2.5221853256225586\n",
      "Iteration 2900, Loss: 2.5186350345611572\n",
      "Iteration 0, Loss: 3.2622220516204834\n",
      "Iteration 100, Loss: 3.010953664779663\n",
      "Iteration 200, Loss: 2.9840011596679688\n",
      "Iteration 300, Loss: 2.9178781509399414\n",
      "Iteration 400, Loss: 2.867701292037964\n",
      "Iteration 500, Loss: 2.8380987644195557\n",
      "Iteration 600, Loss: 2.799457311630249\n",
      "Iteration 700, Loss: 2.7803730964660645\n",
      "Iteration 800, Loss: 2.7550737857818604\n",
      "Iteration 900, Loss: 2.7391810417175293\n",
      "Iteration 1000, Loss: 2.718832492828369\n",
      "Iteration 1100, Loss: 2.7017714977264404\n",
      "Iteration 1200, Loss: 2.690610885620117\n",
      "Iteration 1300, Loss: 2.678314208984375\n",
      "Iteration 1400, Loss: 2.663419008255005\n",
      "Iteration 1500, Loss: 2.6514649391174316\n",
      "Iteration 1600, Loss: 2.642298460006714\n",
      "Iteration 1700, Loss: 2.634099006652832\n",
      "Iteration 1800, Loss: 2.6241252422332764\n",
      "Iteration 1900, Loss: 2.6186575889587402\n",
      "Iteration 2000, Loss: 2.6093719005584717\n",
      "Iteration 2100, Loss: 2.5990164279937744\n",
      "Iteration 2200, Loss: 2.5942916870117188\n",
      "Iteration 2300, Loss: 2.5856423377990723\n",
      "Iteration 2400, Loss: 2.579575777053833\n",
      "Iteration 2500, Loss: 2.574105739593506\n",
      "Iteration 2600, Loss: 2.566066265106201\n",
      "Iteration 2700, Loss: 2.563021421432495\n",
      "Iteration 2800, Loss: 2.556154727935791\n",
      "Iteration 2900, Loss: 2.550891876220703\n",
      "Iteration 0, Loss: 3.308539390563965\n",
      "Iteration 100, Loss: 3.0662927627563477\n",
      "Iteration 200, Loss: 2.971985340118408\n",
      "Iteration 300, Loss: 2.9247965812683105\n",
      "Iteration 400, Loss: 2.8813605308532715\n",
      "Iteration 500, Loss: 2.8472847938537598\n",
      "Iteration 600, Loss: 2.820251703262329\n",
      "Iteration 700, Loss: 2.8037025928497314\n",
      "Iteration 800, Loss: 2.7825937271118164\n",
      "Iteration 900, Loss: 2.7712767124176025\n",
      "Iteration 1000, Loss: 2.757153034210205\n",
      "Iteration 1100, Loss: 2.7469441890716553\n",
      "Iteration 1200, Loss: 2.731924533843994\n",
      "Iteration 1300, Loss: 2.7172510623931885\n",
      "Iteration 1400, Loss: 2.7130532264709473\n",
      "Iteration 1500, Loss: 2.6995465755462646\n",
      "Iteration 1600, Loss: 2.689826011657715\n",
      "Iteration 1700, Loss: 2.679727554321289\n",
      "Iteration 1800, Loss: 2.6740777492523193\n",
      "Iteration 1900, Loss: 2.668962001800537\n",
      "Iteration 2000, Loss: 2.65268611907959\n",
      "Iteration 2100, Loss: 2.645453691482544\n",
      "Iteration 2200, Loss: 2.638242721557617\n",
      "Iteration 2300, Loss: 2.6348392963409424\n",
      "Iteration 2400, Loss: 2.634552240371704\n",
      "Iteration 2500, Loss: 2.622650623321533\n",
      "Iteration 2600, Loss: 2.6182258129119873\n",
      "Iteration 2700, Loss: 2.6118476390838623\n",
      "Iteration 2800, Loss: 2.60455060005188\n",
      "Iteration 2900, Loss: 2.599686622619629\n",
      "Iteration 0, Loss: 3.321666955947876\n",
      "Iteration 100, Loss: 3.0896189212799072\n",
      "Iteration 200, Loss: 3.024381637573242\n",
      "Iteration 300, Loss: 2.9761457443237305\n",
      "Iteration 400, Loss: 2.9517323970794678\n",
      "Iteration 500, Loss: 2.9159481525421143\n",
      "Iteration 600, Loss: 2.8937480449676514\n",
      "Iteration 700, Loss: 2.895512342453003\n",
      "Iteration 800, Loss: 2.859225273132324\n",
      "Iteration 900, Loss: 2.8394484519958496\n",
      "Iteration 1000, Loss: 2.830657720565796\n",
      "Iteration 1100, Loss: 2.8374252319335938\n",
      "Iteration 1200, Loss: 2.7891154289245605\n",
      "Iteration 1300, Loss: 2.7803592681884766\n",
      "Iteration 1400, Loss: 2.766967535018921\n",
      "Iteration 1500, Loss: 2.7570865154266357\n",
      "Iteration 1600, Loss: 2.7461180686950684\n",
      "Iteration 1700, Loss: 2.733760356903076\n",
      "Iteration 1800, Loss: 2.7318849563598633\n",
      "Iteration 1900, Loss: 2.7202179431915283\n",
      "Iteration 2000, Loss: 2.7079479694366455\n",
      "Iteration 2100, Loss: 2.7057507038116455\n",
      "Iteration 2200, Loss: 2.693899154663086\n",
      "Iteration 2300, Loss: 2.690934658050537\n",
      "Iteration 2400, Loss: 2.681525230407715\n",
      "Iteration 2500, Loss: 2.676337718963623\n",
      "Iteration 2600, Loss: 2.67079758644104\n",
      "Iteration 2700, Loss: 2.6676692962646484\n",
      "Iteration 2800, Loss: 2.660672426223755\n",
      "Iteration 2900, Loss: 2.651731014251709\n",
      "Iteration 0, Loss: 3.297098398208618\n",
      "Iteration 100, Loss: 3.0286760330200195\n",
      "Iteration 200, Loss: 2.939014196395874\n",
      "Iteration 300, Loss: 2.8852710723876953\n",
      "Iteration 400, Loss: 2.840721368789673\n",
      "Iteration 500, Loss: 2.8069639205932617\n",
      "Iteration 600, Loss: 2.779959201812744\n",
      "Iteration 700, Loss: 2.7567384243011475\n",
      "Iteration 800, Loss: 2.7342562675476074\n",
      "Iteration 900, Loss: 2.716212749481201\n",
      "Iteration 1000, Loss: 2.7021994590759277\n",
      "Iteration 1100, Loss: 2.691664457321167\n",
      "Iteration 1200, Loss: 2.6716158390045166\n",
      "Iteration 1300, Loss: 2.6635243892669678\n",
      "Iteration 1400, Loss: 2.653172492980957\n",
      "Iteration 1500, Loss: 2.6402299404144287\n",
      "Iteration 1600, Loss: 2.6358745098114014\n",
      "Iteration 1700, Loss: 2.6265900135040283\n",
      "Iteration 1800, Loss: 2.616203784942627\n",
      "Iteration 1900, Loss: 2.608983278274536\n",
      "Iteration 2000, Loss: 2.6039910316467285\n",
      "Iteration 2100, Loss: 2.597717761993408\n",
      "Iteration 2200, Loss: 2.5916929244995117\n",
      "Iteration 2300, Loss: 2.5843167304992676\n",
      "Iteration 2400, Loss: 2.5803580284118652\n",
      "Iteration 2500, Loss: 2.5757293701171875\n",
      "Iteration 2600, Loss: 2.5633952617645264\n",
      "Iteration 2700, Loss: 2.5686771869659424\n",
      "Iteration 2800, Loss: 2.557201623916626\n",
      "Iteration 2900, Loss: 2.551710844039917\n",
      "Iteration 0, Loss: 3.1669585704803467\n",
      "Iteration 100, Loss: 2.9381113052368164\n",
      "Iteration 200, Loss: 2.881457567214966\n",
      "Iteration 300, Loss: 2.8044347763061523\n",
      "Iteration 400, Loss: 2.7577741146087646\n",
      "Iteration 500, Loss: 2.723318099975586\n",
      "Iteration 600, Loss: 2.697120189666748\n",
      "Iteration 700, Loss: 2.6719019412994385\n",
      "Iteration 800, Loss: 2.6476457118988037\n",
      "Iteration 900, Loss: 2.662654161453247\n",
      "Iteration 1000, Loss: 2.6123697757720947\n",
      "Iteration 1100, Loss: 2.597717761993408\n",
      "Iteration 1200, Loss: 2.593416452407837\n",
      "Iteration 1300, Loss: 2.5753424167633057\n",
      "Iteration 1400, Loss: 2.5631072521209717\n",
      "Iteration 1500, Loss: 2.545954704284668\n",
      "Iteration 1600, Loss: 2.558412551879883\n",
      "Iteration 1700, Loss: 2.5291073322296143\n",
      "Iteration 1800, Loss: 2.5235579013824463\n",
      "Iteration 1900, Loss: 2.5142738819122314\n",
      "Iteration 2000, Loss: 2.506565570831299\n",
      "Iteration 2100, Loss: 2.500882148742676\n",
      "Iteration 2200, Loss: 2.4899673461914062\n",
      "Iteration 2300, Loss: 2.4864962100982666\n",
      "Iteration 2400, Loss: 2.4790995121002197\n",
      "Iteration 2500, Loss: 2.472421407699585\n",
      "Iteration 2600, Loss: 2.4693198204040527\n",
      "Iteration 2700, Loss: 2.466550588607788\n",
      "Iteration 2800, Loss: 2.4569129943847656\n",
      "Iteration 2900, Loss: 2.4571125507354736\n",
      "Iteration 0, Loss: 3.1614792346954346\n",
      "Iteration 100, Loss: 2.9405252933502197\n",
      "Iteration 200, Loss: 2.8492038249969482\n",
      "Iteration 300, Loss: 2.7859742641448975\n",
      "Iteration 400, Loss: 2.7437362670898438\n",
      "Iteration 500, Loss: 2.723262310028076\n",
      "Iteration 600, Loss: 2.692791700363159\n",
      "Iteration 700, Loss: 2.657290458679199\n",
      "Iteration 800, Loss: 2.6344048976898193\n",
      "Iteration 900, Loss: 2.6185617446899414\n",
      "Iteration 1000, Loss: 2.6168859004974365\n",
      "Iteration 1100, Loss: 2.585148811340332\n",
      "Iteration 1200, Loss: 2.565988540649414\n",
      "Iteration 1300, Loss: 2.559540033340454\n",
      "Iteration 1400, Loss: 2.550539255142212\n",
      "Iteration 1500, Loss: 2.532897710800171\n",
      "Iteration 1600, Loss: 2.523226022720337\n",
      "Iteration 1700, Loss: 2.521787405014038\n",
      "Iteration 1800, Loss: 2.505613327026367\n",
      "Iteration 1900, Loss: 2.5056281089782715\n",
      "Iteration 2000, Loss: 2.4933714866638184\n",
      "Iteration 2100, Loss: 2.489230155944824\n",
      "Iteration 2200, Loss: 2.4750354290008545\n",
      "Iteration 2300, Loss: 2.471247911453247\n",
      "Iteration 2400, Loss: 2.4664154052734375\n",
      "Iteration 2500, Loss: 2.459892988204956\n",
      "Iteration 2600, Loss: 2.4598844051361084\n",
      "Iteration 2700, Loss: 2.4519360065460205\n",
      "Iteration 2800, Loss: 2.446326971054077\n",
      "Iteration 2900, Loss: 2.440310001373291\n",
      "Iteration 0, Loss: 3.2148098945617676\n",
      "Iteration 100, Loss: 2.994166851043701\n",
      "Iteration 200, Loss: 2.882265567779541\n",
      "Iteration 300, Loss: 2.8343544006347656\n",
      "Iteration 400, Loss: 2.816434621810913\n",
      "Iteration 500, Loss: 2.7706947326660156\n",
      "Iteration 600, Loss: 2.7428700923919678\n",
      "Iteration 700, Loss: 2.727076530456543\n",
      "Iteration 800, Loss: 2.7069547176361084\n",
      "Iteration 900, Loss: 2.6898016929626465\n",
      "Iteration 1000, Loss: 2.6730122566223145\n",
      "Iteration 1100, Loss: 2.655463218688965\n",
      "Iteration 1200, Loss: 2.6509695053100586\n",
      "Iteration 1300, Loss: 2.6401431560516357\n",
      "Iteration 1400, Loss: 2.6214680671691895\n",
      "Iteration 1500, Loss: 2.6136152744293213\n",
      "Iteration 1600, Loss: 2.606374740600586\n",
      "Iteration 1700, Loss: 2.59647274017334\n",
      "Iteration 1800, Loss: 2.590822458267212\n",
      "Iteration 1900, Loss: 2.5815176963806152\n",
      "Iteration 2000, Loss: 2.572082281112671\n",
      "Iteration 2100, Loss: 2.5674540996551514\n",
      "Iteration 2200, Loss: 2.559291124343872\n",
      "Iteration 2300, Loss: 2.554966926574707\n",
      "Iteration 2400, Loss: 2.544501543045044\n",
      "Iteration 2500, Loss: 2.539691209793091\n",
      "Iteration 2600, Loss: 2.535860776901245\n",
      "Iteration 2700, Loss: 2.5279059410095215\n",
      "Iteration 2800, Loss: 2.5252583026885986\n",
      "Iteration 2900, Loss: 2.517428159713745\n",
      "Iteration 0, Loss: 3.125546932220459\n",
      "Iteration 100, Loss: 2.884798288345337\n",
      "Iteration 200, Loss: 2.8061068058013916\n",
      "Iteration 300, Loss: 2.75132417678833\n",
      "Iteration 400, Loss: 2.703800916671753\n",
      "Iteration 500, Loss: 2.663017511367798\n",
      "Iteration 600, Loss: 2.6312341690063477\n",
      "Iteration 700, Loss: 2.612107276916504\n",
      "Iteration 800, Loss: 2.5852060317993164\n",
      "Iteration 900, Loss: 2.566007137298584\n",
      "Iteration 1000, Loss: 2.5441534519195557\n",
      "Iteration 1100, Loss: 2.526078224182129\n",
      "Iteration 1200, Loss: 2.512181282043457\n",
      "Iteration 1300, Loss: 2.5037362575531006\n",
      "Iteration 1400, Loss: 2.508702278137207\n",
      "Iteration 1500, Loss: 2.4801113605499268\n",
      "Iteration 1600, Loss: 2.4673538208007812\n",
      "Iteration 1700, Loss: 2.4567108154296875\n",
      "Iteration 1800, Loss: 2.455166816711426\n",
      "Iteration 1900, Loss: 2.4369595050811768\n",
      "Iteration 2000, Loss: 2.4333131313323975\n",
      "Iteration 2100, Loss: 2.431117057800293\n",
      "Iteration 2200, Loss: 2.4196503162384033\n",
      "Iteration 2300, Loss: 2.4145476818084717\n",
      "Iteration 2400, Loss: 2.407113790512085\n",
      "Iteration 2500, Loss: 2.4031689167022705\n",
      "Iteration 2600, Loss: 2.394033908843994\n",
      "Iteration 2700, Loss: 2.391840696334839\n",
      "Iteration 2800, Loss: 2.383152961730957\n",
      "Iteration 2900, Loss: 2.374398708343506\n",
      "Iteration 0, Loss: 3.1934423446655273\n",
      "Iteration 100, Loss: 2.935681104660034\n",
      "Iteration 200, Loss: 2.8362233638763428\n",
      "Iteration 300, Loss: 2.7746453285217285\n",
      "Iteration 400, Loss: 2.7343649864196777\n",
      "Iteration 500, Loss: 2.69884991645813\n",
      "Iteration 600, Loss: 2.6769816875457764\n",
      "Iteration 700, Loss: 2.6526925563812256\n",
      "Iteration 800, Loss: 2.619704008102417\n",
      "Iteration 900, Loss: 2.6059985160827637\n",
      "Iteration 1000, Loss: 2.5899693965911865\n",
      "Iteration 1100, Loss: 2.5715882778167725\n",
      "Iteration 1200, Loss: 2.563633680343628\n",
      "Iteration 1300, Loss: 2.5482776165008545\n",
      "Iteration 1400, Loss: 2.5397133827209473\n",
      "Iteration 1500, Loss: 2.526937246322632\n",
      "Iteration 1600, Loss: 2.5193190574645996\n",
      "Iteration 1700, Loss: 2.507578134536743\n",
      "Iteration 1800, Loss: 2.5013461112976074\n",
      "Iteration 1900, Loss: 2.4931960105895996\n",
      "Iteration 2000, Loss: 2.4926021099090576\n",
      "Iteration 2100, Loss: 2.4804019927978516\n",
      "Iteration 2200, Loss: 2.4735591411590576\n",
      "Iteration 2300, Loss: 2.469777822494507\n",
      "Iteration 2400, Loss: 2.463840961456299\n",
      "Iteration 2500, Loss: 2.4556002616882324\n",
      "Iteration 2600, Loss: 2.4486653804779053\n",
      "Iteration 2700, Loss: 2.4462814331054688\n",
      "Iteration 2800, Loss: 2.4386162757873535\n",
      "Iteration 2900, Loss: 2.4393224716186523\n",
      "Iteration 0, Loss: 3.3108749389648438\n",
      "Iteration 100, Loss: 3.0769107341766357\n",
      "Iteration 200, Loss: 2.987546682357788\n",
      "Iteration 300, Loss: 2.9361422061920166\n",
      "Iteration 400, Loss: 2.9020659923553467\n",
      "Iteration 500, Loss: 2.8670132160186768\n",
      "Iteration 600, Loss: 2.844059944152832\n",
      "Iteration 700, Loss: 2.826676845550537\n",
      "Iteration 800, Loss: 2.8251430988311768\n",
      "Iteration 900, Loss: 2.790191173553467\n",
      "Iteration 1000, Loss: 2.7792410850524902\n",
      "Iteration 1100, Loss: 2.752408504486084\n",
      "Iteration 1200, Loss: 2.7419230937957764\n",
      "Iteration 1300, Loss: 2.735018014907837\n",
      "Iteration 1400, Loss: 2.720587730407715\n",
      "Iteration 1500, Loss: 2.7099485397338867\n",
      "Iteration 1600, Loss: 2.7020065784454346\n",
      "Iteration 1700, Loss: 2.6923091411590576\n",
      "Iteration 1800, Loss: 2.6837170124053955\n",
      "Iteration 1900, Loss: 2.6730730533599854\n",
      "Iteration 2000, Loss: 2.6699318885803223\n",
      "Iteration 2100, Loss: 2.6703975200653076\n",
      "Iteration 2200, Loss: 2.6571691036224365\n",
      "Iteration 2300, Loss: 2.6482043266296387\n",
      "Iteration 2400, Loss: 2.6489853858947754\n",
      "Iteration 2500, Loss: 2.6406919956207275\n",
      "Iteration 2600, Loss: 2.63234281539917\n",
      "Iteration 2700, Loss: 2.6295478343963623\n",
      "Iteration 2800, Loss: 2.6263973712921143\n",
      "Iteration 2900, Loss: 2.6173717975616455\n",
      "Iteration 0, Loss: 3.2663919925689697\n",
      "Iteration 100, Loss: 3.045740842819214\n",
      "Iteration 200, Loss: 2.974083423614502\n",
      "Iteration 300, Loss: 2.966186761856079\n",
      "Iteration 400, Loss: 2.901045799255371\n",
      "Iteration 500, Loss: 2.8656508922576904\n",
      "Iteration 600, Loss: 2.8552939891815186\n",
      "Iteration 700, Loss: 2.821272850036621\n",
      "Iteration 800, Loss: 2.7995030879974365\n",
      "Iteration 900, Loss: 2.786653518676758\n",
      "Iteration 1000, Loss: 2.768494129180908\n",
      "Iteration 1100, Loss: 2.747972011566162\n",
      "Iteration 1200, Loss: 2.734163522720337\n",
      "Iteration 1300, Loss: 2.73612117767334\n",
      "Iteration 1400, Loss: 2.7144129276275635\n",
      "Iteration 1500, Loss: 2.710789680480957\n",
      "Iteration 1600, Loss: 2.6958091259002686\n",
      "Iteration 1700, Loss: 2.684692621231079\n",
      "Iteration 1800, Loss: 2.678461790084839\n",
      "Iteration 1900, Loss: 2.668450355529785\n",
      "Iteration 2000, Loss: 2.6724507808685303\n",
      "Iteration 2100, Loss: 2.6493968963623047\n",
      "Iteration 2200, Loss: 2.6480164527893066\n",
      "Iteration 2300, Loss: 2.636674642562866\n",
      "Iteration 2400, Loss: 2.634460210800171\n",
      "Iteration 2500, Loss: 2.637774705886841\n",
      "Iteration 2600, Loss: 2.6187636852264404\n",
      "Iteration 2700, Loss: 2.616595506668091\n",
      "Iteration 2800, Loss: 2.6113407611846924\n",
      "Iteration 2900, Loss: 2.6069939136505127\n",
      "Iteration 0, Loss: 3.1688969135284424\n",
      "Iteration 100, Loss: 2.918043613433838\n",
      "Iteration 200, Loss: 2.8190455436706543\n",
      "Iteration 300, Loss: 2.7666232585906982\n",
      "Iteration 400, Loss: 2.7246572971343994\n",
      "Iteration 500, Loss: 2.6947739124298096\n",
      "Iteration 600, Loss: 2.6719810962677\n",
      "Iteration 700, Loss: 2.646574020385742\n",
      "Iteration 800, Loss: 2.6341307163238525\n",
      "Iteration 900, Loss: 2.6074209213256836\n",
      "Iteration 1000, Loss: 2.6023030281066895\n",
      "Iteration 1100, Loss: 2.576725721359253\n",
      "Iteration 1200, Loss: 2.5608396530151367\n",
      "Iteration 1300, Loss: 2.5742857456207275\n",
      "Iteration 1400, Loss: 2.5362234115600586\n",
      "Iteration 1500, Loss: 2.5380091667175293\n",
      "Iteration 1600, Loss: 2.5232880115509033\n",
      "Iteration 1700, Loss: 2.5062785148620605\n",
      "Iteration 1800, Loss: 2.5101943016052246\n",
      "Iteration 1900, Loss: 2.4940712451934814\n",
      "Iteration 2000, Loss: 2.4884696006774902\n",
      "Iteration 2100, Loss: 2.4800655841827393\n",
      "Iteration 2200, Loss: 2.4720356464385986\n",
      "Iteration 2300, Loss: 2.4658939838409424\n",
      "Iteration 2400, Loss: 2.4632937908172607\n",
      "Iteration 2500, Loss: 2.457228422164917\n",
      "Iteration 2600, Loss: 2.4521520137786865\n",
      "Iteration 2700, Loss: 2.444164752960205\n",
      "Iteration 2800, Loss: 2.439398765563965\n",
      "Iteration 2900, Loss: 2.434974431991577\n",
      "Iteration 0, Loss: 3.3504059314727783\n",
      "Iteration 100, Loss: 3.0859227180480957\n",
      "Iteration 200, Loss: 3.0106074810028076\n",
      "Iteration 300, Loss: 2.957869291305542\n",
      "Iteration 400, Loss: 2.9188454151153564\n",
      "Iteration 500, Loss: 2.8849854469299316\n",
      "Iteration 600, Loss: 2.8643229007720947\n",
      "Iteration 700, Loss: 2.8421437740325928\n",
      "Iteration 800, Loss: 2.815383195877075\n",
      "Iteration 900, Loss: 2.7996230125427246\n",
      "Iteration 1000, Loss: 2.7877354621887207\n",
      "Iteration 1100, Loss: 2.775623083114624\n",
      "Iteration 1200, Loss: 2.758344888687134\n",
      "Iteration 1300, Loss: 2.752807140350342\n",
      "Iteration 1400, Loss: 2.744074821472168\n",
      "Iteration 1500, Loss: 2.7358176708221436\n",
      "Iteration 1600, Loss: 2.7248048782348633\n",
      "Iteration 1700, Loss: 2.7198846340179443\n",
      "Iteration 1800, Loss: 2.7081871032714844\n",
      "Iteration 1900, Loss: 2.701359748840332\n",
      "Iteration 2000, Loss: 2.69287109375\n",
      "Iteration 2100, Loss: 2.690101385116577\n",
      "Iteration 2200, Loss: 2.681933879852295\n",
      "Iteration 2300, Loss: 2.6800031661987305\n",
      "Iteration 2400, Loss: 2.670342445373535\n",
      "Iteration 2500, Loss: 2.668231964111328\n",
      "Iteration 2600, Loss: 2.6630172729492188\n",
      "Iteration 2700, Loss: 2.658595561981201\n",
      "Iteration 2800, Loss: 2.655141830444336\n",
      "Iteration 2900, Loss: 2.649474620819092\n",
      "Iteration 0, Loss: 3.1650991439819336\n",
      "Iteration 100, Loss: 2.9057137966156006\n",
      "Iteration 200, Loss: 2.81299090385437\n",
      "Iteration 300, Loss: 2.771054267883301\n",
      "Iteration 400, Loss: 2.7293200492858887\n",
      "Iteration 500, Loss: 2.6924867630004883\n",
      "Iteration 600, Loss: 2.666642665863037\n",
      "Iteration 700, Loss: 2.644364595413208\n",
      "Iteration 800, Loss: 2.625520706176758\n",
      "Iteration 900, Loss: 2.6113250255584717\n",
      "Iteration 1000, Loss: 2.593632459640503\n",
      "Iteration 1100, Loss: 2.5766284465789795\n",
      "Iteration 1200, Loss: 2.5632667541503906\n",
      "Iteration 1300, Loss: 2.5629172325134277\n",
      "Iteration 1400, Loss: 2.543665647506714\n",
      "Iteration 1500, Loss: 2.5331881046295166\n",
      "Iteration 1600, Loss: 2.5274178981781006\n",
      "Iteration 1700, Loss: 2.5218944549560547\n",
      "Iteration 1800, Loss: 2.5087714195251465\n",
      "Iteration 1900, Loss: 2.5081064701080322\n",
      "Iteration 2000, Loss: 2.491827964782715\n",
      "Iteration 2100, Loss: 2.486332893371582\n",
      "Iteration 2200, Loss: 2.4813272953033447\n",
      "Iteration 2300, Loss: 2.477689504623413\n",
      "Iteration 2400, Loss: 2.46970796585083\n",
      "Iteration 2500, Loss: 2.459451198577881\n",
      "Iteration 2600, Loss: 2.4614033699035645\n",
      "Iteration 2700, Loss: 2.45171856880188\n",
      "Iteration 2800, Loss: 2.4477221965789795\n",
      "Iteration 2900, Loss: 2.4407222270965576\n",
      "Iteration 0, Loss: 3.183302164077759\n",
      "Iteration 100, Loss: 2.952921152114868\n",
      "Iteration 200, Loss: 2.875821113586426\n",
      "Iteration 300, Loss: 2.821397542953491\n",
      "Iteration 400, Loss: 2.7772815227508545\n",
      "Iteration 500, Loss: 2.7410006523132324\n",
      "Iteration 600, Loss: 2.713390350341797\n",
      "Iteration 700, Loss: 2.6881937980651855\n",
      "Iteration 800, Loss: 2.673017740249634\n",
      "Iteration 900, Loss: 2.6556477546691895\n",
      "Iteration 1000, Loss: 2.637941360473633\n",
      "Iteration 1100, Loss: 2.622101306915283\n",
      "Iteration 1200, Loss: 2.6079888343811035\n",
      "Iteration 1300, Loss: 2.6028780937194824\n",
      "Iteration 1400, Loss: 2.587761163711548\n",
      "Iteration 1500, Loss: 2.5759458541870117\n",
      "Iteration 1600, Loss: 2.570039749145508\n",
      "Iteration 1700, Loss: 2.5575664043426514\n",
      "Iteration 1800, Loss: 2.5540642738342285\n",
      "Iteration 1900, Loss: 2.5392959117889404\n",
      "Iteration 2000, Loss: 2.539287567138672\n",
      "Iteration 2100, Loss: 2.5292129516601562\n",
      "Iteration 2200, Loss: 2.523301124572754\n",
      "Iteration 2300, Loss: 2.5125513076782227\n",
      "Iteration 2400, Loss: 2.507878303527832\n",
      "Iteration 2500, Loss: 2.5083930492401123\n",
      "Iteration 2600, Loss: 2.492954730987549\n",
      "Iteration 2700, Loss: 2.489734172821045\n",
      "Iteration 2800, Loss: 2.490875005722046\n",
      "Iteration 2900, Loss: 2.4817566871643066\n",
      "Iteration 0, Loss: 3.4347898960113525\n",
      "Iteration 100, Loss: 3.1966240406036377\n",
      "Iteration 200, Loss: 3.1359236240386963\n",
      "Iteration 300, Loss: 3.0853612422943115\n",
      "Iteration 400, Loss: 3.049257755279541\n",
      "Iteration 500, Loss: 3.018801689147949\n",
      "Iteration 600, Loss: 2.9987943172454834\n",
      "Iteration 700, Loss: 2.9726128578186035\n",
      "Iteration 800, Loss: 2.961059808731079\n",
      "Iteration 900, Loss: 2.9431166648864746\n",
      "Iteration 1000, Loss: 2.9266695976257324\n",
      "Iteration 1100, Loss: 2.9132368564605713\n",
      "Iteration 1200, Loss: 2.899732828140259\n",
      "Iteration 1300, Loss: 2.8915295600891113\n",
      "Iteration 1400, Loss: 2.880290985107422\n",
      "Iteration 1500, Loss: 2.8715662956237793\n",
      "Iteration 1600, Loss: 2.8649487495422363\n",
      "Iteration 1700, Loss: 2.8506932258605957\n",
      "Iteration 1800, Loss: 2.8418431282043457\n",
      "Iteration 1900, Loss: 2.8335764408111572\n",
      "Iteration 2000, Loss: 2.8250129222869873\n",
      "Iteration 2100, Loss: 2.819326400756836\n",
      "Iteration 2200, Loss: 2.816368579864502\n",
      "Iteration 2300, Loss: 2.807481050491333\n",
      "Iteration 2400, Loss: 2.8041441440582275\n",
      "Iteration 2500, Loss: 2.800934076309204\n",
      "Iteration 2600, Loss: 2.7955260276794434\n",
      "Iteration 2700, Loss: 2.7899298667907715\n",
      "Iteration 2800, Loss: 2.7819406986236572\n",
      "Iteration 2900, Loss: 2.778813600540161\n",
      "Iteration 0, Loss: 3.139528512954712\n",
      "Iteration 100, Loss: 2.9043571949005127\n",
      "Iteration 200, Loss: 2.8205997943878174\n",
      "Iteration 300, Loss: 2.7551450729370117\n",
      "Iteration 400, Loss: 2.7198939323425293\n",
      "Iteration 500, Loss: 2.705608367919922\n",
      "Iteration 600, Loss: 2.6438088417053223\n",
      "Iteration 700, Loss: 2.6189959049224854\n",
      "Iteration 800, Loss: 2.6063501834869385\n",
      "Iteration 900, Loss: 2.5846879482269287\n",
      "Iteration 1000, Loss: 2.5571556091308594\n",
      "Iteration 1100, Loss: 2.5426390171051025\n",
      "Iteration 1200, Loss: 2.5337040424346924\n",
      "Iteration 1300, Loss: 2.5180978775024414\n",
      "Iteration 1400, Loss: 2.5100274085998535\n",
      "Iteration 1500, Loss: 2.492877244949341\n",
      "Iteration 1600, Loss: 2.488157033920288\n",
      "Iteration 1700, Loss: 2.4743025302886963\n",
      "Iteration 1800, Loss: 2.4723098278045654\n",
      "Iteration 1900, Loss: 2.462728500366211\n",
      "Iteration 2000, Loss: 2.4584267139434814\n",
      "Iteration 2100, Loss: 2.4469361305236816\n",
      "Iteration 2200, Loss: 2.4464213848114014\n",
      "Iteration 2300, Loss: 2.4325907230377197\n",
      "Iteration 2400, Loss: 2.4331653118133545\n",
      "Iteration 2500, Loss: 2.4265456199645996\n",
      "Iteration 2600, Loss: 2.4210681915283203\n",
      "Iteration 2700, Loss: 2.4138786792755127\n",
      "Iteration 2800, Loss: 2.4100394248962402\n",
      "Iteration 2900, Loss: 2.406785488128662\n",
      "Iteration 0, Loss: 3.236185073852539\n",
      "Iteration 100, Loss: 3.017045497894287\n",
      "Iteration 200, Loss: 2.9413959980010986\n",
      "Iteration 300, Loss: 2.9176623821258545\n",
      "Iteration 400, Loss: 2.86016845703125\n",
      "Iteration 500, Loss: 2.829558849334717\n",
      "Iteration 600, Loss: 2.8021903038024902\n",
      "Iteration 700, Loss: 2.796696901321411\n",
      "Iteration 800, Loss: 2.768019676208496\n",
      "Iteration 900, Loss: 2.748103618621826\n",
      "Iteration 1000, Loss: 2.7326242923736572\n",
      "Iteration 1100, Loss: 2.712364435195923\n",
      "Iteration 1200, Loss: 2.710057020187378\n",
      "Iteration 1300, Loss: 2.6947288513183594\n",
      "Iteration 1400, Loss: 2.684734344482422\n",
      "Iteration 1500, Loss: 2.673337459564209\n",
      "Iteration 1600, Loss: 2.6632845401763916\n",
      "Iteration 1700, Loss: 2.6623497009277344\n",
      "Iteration 1800, Loss: 2.646183967590332\n",
      "Iteration 1900, Loss: 2.633822202682495\n",
      "Iteration 2000, Loss: 2.6257176399230957\n",
      "Iteration 2100, Loss: 2.627124071121216\n",
      "Iteration 2200, Loss: 2.611346483230591\n",
      "Iteration 2300, Loss: 2.607463836669922\n",
      "Iteration 2400, Loss: 2.596353769302368\n",
      "Iteration 2500, Loss: 2.594170331954956\n",
      "Iteration 2600, Loss: 2.5878241062164307\n",
      "Iteration 2700, Loss: 2.5802743434906006\n",
      "Iteration 2800, Loss: 2.5772194862365723\n",
      "Iteration 2900, Loss: 2.568849563598633\n",
      "Iteration 0, Loss: 3.2687129974365234\n",
      "Iteration 100, Loss: 3.058605909347534\n",
      "Iteration 200, Loss: 2.967322826385498\n",
      "Iteration 300, Loss: 2.9115777015686035\n",
      "Iteration 400, Loss: 2.874051570892334\n",
      "Iteration 500, Loss: 2.841130256652832\n",
      "Iteration 600, Loss: 2.8171350955963135\n",
      "Iteration 700, Loss: 2.7869200706481934\n",
      "Iteration 800, Loss: 2.769289970397949\n",
      "Iteration 900, Loss: 2.754873037338257\n",
      "Iteration 1000, Loss: 2.735227346420288\n",
      "Iteration 1100, Loss: 2.7208871841430664\n",
      "Iteration 1200, Loss: 2.7094385623931885\n",
      "Iteration 1300, Loss: 2.697829008102417\n",
      "Iteration 1400, Loss: 2.6890382766723633\n",
      "Iteration 1500, Loss: 2.680145740509033\n",
      "Iteration 1600, Loss: 2.6695635318756104\n",
      "Iteration 1700, Loss: 2.657485246658325\n",
      "Iteration 1800, Loss: 2.650162935256958\n",
      "Iteration 1900, Loss: 2.642240047454834\n",
      "Iteration 2000, Loss: 2.640336036682129\n",
      "Iteration 2100, Loss: 2.629488706588745\n",
      "Iteration 2200, Loss: 2.6218209266662598\n",
      "Iteration 2300, Loss: 2.6177289485931396\n",
      "Iteration 2400, Loss: 2.611283302307129\n",
      "Iteration 2500, Loss: 2.604567527770996\n",
      "Iteration 2600, Loss: 2.5994577407836914\n",
      "Iteration 2700, Loss: 2.594080686569214\n",
      "Iteration 2800, Loss: 2.590719699859619\n",
      "Iteration 2900, Loss: 2.585634231567383\n",
      "Iteration 0, Loss: 3.2535035610198975\n",
      "Iteration 100, Loss: 3.0170938968658447\n",
      "Iteration 200, Loss: 2.9278101921081543\n",
      "Iteration 300, Loss: 2.8782296180725098\n",
      "Iteration 400, Loss: 2.8374369144439697\n",
      "Iteration 500, Loss: 2.8050718307495117\n",
      "Iteration 600, Loss: 2.7757925987243652\n",
      "Iteration 700, Loss: 2.750013589859009\n",
      "Iteration 800, Loss: 2.730729818344116\n",
      "Iteration 900, Loss: 2.702916145324707\n",
      "Iteration 1000, Loss: 2.684922218322754\n",
      "Iteration 1100, Loss: 2.6755645275115967\n",
      "Iteration 1200, Loss: 2.657919406890869\n",
      "Iteration 1300, Loss: 2.647615909576416\n",
      "Iteration 1400, Loss: 2.6330513954162598\n",
      "Iteration 1500, Loss: 2.6229026317596436\n",
      "Iteration 1600, Loss: 2.6180412769317627\n",
      "Iteration 1700, Loss: 2.604365825653076\n",
      "Iteration 1800, Loss: 2.6026554107666016\n",
      "Iteration 1900, Loss: 2.5914950370788574\n",
      "Iteration 2000, Loss: 2.5879061222076416\n",
      "Iteration 2100, Loss: 2.576295852661133\n",
      "Iteration 2200, Loss: 2.568650960922241\n",
      "Iteration 2300, Loss: 2.5625317096710205\n",
      "Iteration 2400, Loss: 2.55759859085083\n",
      "Iteration 2500, Loss: 2.5508265495300293\n",
      "Iteration 2600, Loss: 2.5447123050689697\n",
      "Iteration 2700, Loss: 2.539401054382324\n",
      "Iteration 2800, Loss: 2.5360002517700195\n",
      "Iteration 2900, Loss: 2.5278303623199463\n",
      "Iteration 0, Loss: 3.263608932495117\n",
      "Iteration 100, Loss: 3.032212257385254\n",
      "Iteration 200, Loss: 2.9532368183135986\n",
      "Iteration 300, Loss: 2.9132559299468994\n",
      "Iteration 400, Loss: 2.881478786468506\n",
      "Iteration 500, Loss: 2.850850820541382\n",
      "Iteration 600, Loss: 2.8262856006622314\n",
      "Iteration 700, Loss: 2.809903144836426\n",
      "Iteration 800, Loss: 2.793844223022461\n",
      "Iteration 900, Loss: 2.7737371921539307\n",
      "Iteration 1000, Loss: 2.761348247528076\n",
      "Iteration 1100, Loss: 2.755509376525879\n",
      "Iteration 1200, Loss: 2.731796979904175\n",
      "Iteration 1300, Loss: 2.7223076820373535\n",
      "Iteration 1400, Loss: 2.710338830947876\n",
      "Iteration 1500, Loss: 2.7036924362182617\n",
      "Iteration 1600, Loss: 2.687676191329956\n",
      "Iteration 1700, Loss: 2.6796910762786865\n",
      "Iteration 1800, Loss: 2.6676363945007324\n",
      "Iteration 1900, Loss: 2.6678152084350586\n",
      "Iteration 2000, Loss: 2.6502726078033447\n",
      "Iteration 2100, Loss: 2.6432945728302\n",
      "Iteration 2200, Loss: 2.6374001502990723\n",
      "Iteration 2300, Loss: 2.6288607120513916\n",
      "Iteration 2400, Loss: 2.6203629970550537\n",
      "Iteration 2500, Loss: 2.61474347114563\n",
      "Iteration 2600, Loss: 2.609952926635742\n",
      "Iteration 2700, Loss: 2.605128526687622\n",
      "Iteration 2800, Loss: 2.60137677192688\n",
      "Iteration 2900, Loss: 2.5917036533355713\n",
      "Iteration 0, Loss: 3.2444562911987305\n",
      "Iteration 100, Loss: 2.9927244186401367\n",
      "Iteration 200, Loss: 2.918985366821289\n",
      "Iteration 300, Loss: 2.8628365993499756\n",
      "Iteration 400, Loss: 2.823225975036621\n",
      "Iteration 500, Loss: 2.7937114238739014\n",
      "Iteration 600, Loss: 2.7639243602752686\n",
      "Iteration 700, Loss: 2.7433385848999023\n",
      "Iteration 800, Loss: 2.7240214347839355\n",
      "Iteration 900, Loss: 2.706758737564087\n",
      "Iteration 1000, Loss: 2.694031000137329\n",
      "Iteration 1100, Loss: 2.6752734184265137\n",
      "Iteration 1200, Loss: 2.666111707687378\n",
      "Iteration 1300, Loss: 2.650286912918091\n",
      "Iteration 1400, Loss: 2.64247989654541\n",
      "Iteration 1500, Loss: 2.632986068725586\n",
      "Iteration 1600, Loss: 2.619400978088379\n",
      "Iteration 1700, Loss: 2.6130034923553467\n",
      "Iteration 1800, Loss: 2.6096043586730957\n",
      "Iteration 1900, Loss: 2.6025352478027344\n",
      "Iteration 2000, Loss: 2.5879251956939697\n",
      "Iteration 2100, Loss: 2.5904626846313477\n",
      "Iteration 2200, Loss: 2.5801069736480713\n",
      "Iteration 2300, Loss: 2.5732572078704834\n",
      "Iteration 2400, Loss: 2.567192554473877\n",
      "Iteration 2500, Loss: 2.562518835067749\n",
      "Iteration 2600, Loss: 2.553309440612793\n",
      "Iteration 2700, Loss: 2.54559063911438\n",
      "Iteration 2800, Loss: 2.5420432090759277\n",
      "Iteration 2900, Loss: 2.54355788230896\n",
      "Iteration 0, Loss: 3.250817060470581\n",
      "Iteration 100, Loss: 2.97747802734375\n",
      "Iteration 200, Loss: 2.898037910461426\n",
      "Iteration 300, Loss: 2.8487343788146973\n",
      "Iteration 400, Loss: 2.809800863265991\n",
      "Iteration 500, Loss: 2.7894527912139893\n",
      "Iteration 600, Loss: 2.7607429027557373\n",
      "Iteration 700, Loss: 2.7337646484375\n",
      "Iteration 800, Loss: 2.714256525039673\n",
      "Iteration 900, Loss: 2.698284864425659\n",
      "Iteration 1000, Loss: 2.687871217727661\n",
      "Iteration 1100, Loss: 2.6703855991363525\n",
      "Iteration 1200, Loss: 2.6550991535186768\n",
      "Iteration 1300, Loss: 2.6439132690429688\n",
      "Iteration 1400, Loss: 2.6295511722564697\n",
      "Iteration 1500, Loss: 2.61946177482605\n",
      "Iteration 1600, Loss: 2.614189624786377\n",
      "Iteration 1700, Loss: 2.600642204284668\n",
      "Iteration 1800, Loss: 2.5946285724639893\n",
      "Iteration 1900, Loss: 2.586655616760254\n",
      "Iteration 2000, Loss: 2.5802855491638184\n",
      "Iteration 2100, Loss: 2.573124647140503\n",
      "Iteration 2200, Loss: 2.562936544418335\n",
      "Iteration 2300, Loss: 2.564622640609741\n",
      "Iteration 2400, Loss: 2.55598783493042\n",
      "Iteration 2500, Loss: 2.551514148712158\n",
      "Iteration 2600, Loss: 2.543206214904785\n",
      "Iteration 2700, Loss: 2.537224292755127\n",
      "Iteration 2800, Loss: 2.533280849456787\n",
      "Iteration 2900, Loss: 2.5288796424865723\n",
      "Iteration 0, Loss: 3.1614527702331543\n",
      "Iteration 100, Loss: 2.9447638988494873\n",
      "Iteration 200, Loss: 2.8927338123321533\n",
      "Iteration 300, Loss: 2.8225107192993164\n",
      "Iteration 400, Loss: 2.779658079147339\n",
      "Iteration 500, Loss: 2.748523235321045\n",
      "Iteration 600, Loss: 2.7193965911865234\n",
      "Iteration 700, Loss: 2.7008743286132812\n",
      "Iteration 800, Loss: 2.686493158340454\n",
      "Iteration 900, Loss: 2.667379379272461\n",
      "Iteration 1000, Loss: 2.6476681232452393\n",
      "Iteration 1100, Loss: 2.6264684200286865\n",
      "Iteration 1200, Loss: 2.618563413619995\n",
      "Iteration 1300, Loss: 2.6040537357330322\n",
      "Iteration 1400, Loss: 2.5962178707122803\n",
      "Iteration 1500, Loss: 2.581782579421997\n",
      "Iteration 1600, Loss: 2.5757458209991455\n",
      "Iteration 1700, Loss: 2.5640578269958496\n",
      "Iteration 1800, Loss: 2.5508110523223877\n",
      "Iteration 1900, Loss: 2.54290509223938\n",
      "Iteration 2000, Loss: 2.5391995906829834\n",
      "Iteration 2100, Loss: 2.53605318069458\n",
      "Iteration 2200, Loss: 2.5260751247406006\n",
      "Iteration 2300, Loss: 2.5150535106658936\n",
      "Iteration 2400, Loss: 2.511199951171875\n",
      "Iteration 2500, Loss: 2.505070686340332\n",
      "Iteration 2600, Loss: 2.4973535537719727\n",
      "Iteration 2700, Loss: 2.4946582317352295\n",
      "Iteration 2800, Loss: 2.485489845275879\n",
      "Iteration 2900, Loss: 2.4762017726898193\n",
      "Iteration 0, Loss: 3.1590566635131836\n",
      "Iteration 100, Loss: 2.93294095993042\n",
      "Iteration 200, Loss: 2.8821592330932617\n",
      "Iteration 300, Loss: 2.8191375732421875\n",
      "Iteration 400, Loss: 2.785240888595581\n",
      "Iteration 500, Loss: 2.7485201358795166\n",
      "Iteration 600, Loss: 2.726262092590332\n",
      "Iteration 700, Loss: 2.7030277252197266\n",
      "Iteration 800, Loss: 2.6926655769348145\n",
      "Iteration 900, Loss: 2.6668527126312256\n",
      "Iteration 1000, Loss: 2.6591200828552246\n",
      "Iteration 1100, Loss: 2.6441566944122314\n",
      "Iteration 1200, Loss: 2.626645565032959\n",
      "Iteration 1300, Loss: 2.6248886585235596\n",
      "Iteration 1400, Loss: 2.6049845218658447\n",
      "Iteration 1500, Loss: 2.605538845062256\n",
      "Iteration 1600, Loss: 2.5982515811920166\n",
      "Iteration 1700, Loss: 2.5790634155273438\n",
      "Iteration 1800, Loss: 2.5744314193725586\n",
      "Iteration 1900, Loss: 2.562871217727661\n",
      "Iteration 2000, Loss: 2.5556066036224365\n",
      "Iteration 2100, Loss: 2.54794979095459\n",
      "Iteration 2200, Loss: 2.5429129600524902\n",
      "Iteration 2300, Loss: 2.536592483520508\n",
      "Iteration 2400, Loss: 2.527322292327881\n",
      "Iteration 2500, Loss: 2.526937246322632\n",
      "Iteration 2600, Loss: 2.513868570327759\n",
      "Iteration 2700, Loss: 2.5107555389404297\n",
      "Iteration 2800, Loss: 2.5090723037719727\n",
      "Iteration 2900, Loss: 2.4970667362213135\n",
      "Iteration 0, Loss: 3.198251724243164\n",
      "Iteration 100, Loss: 2.97383189201355\n",
      "Iteration 200, Loss: 2.895189046859741\n",
      "Iteration 300, Loss: 2.8421685695648193\n",
      "Iteration 400, Loss: 2.806910276412964\n",
      "Iteration 500, Loss: 2.7909486293792725\n",
      "Iteration 600, Loss: 2.757789134979248\n",
      "Iteration 700, Loss: 2.7472074031829834\n",
      "Iteration 800, Loss: 2.7261619567871094\n",
      "Iteration 900, Loss: 2.699542760848999\n",
      "Iteration 1000, Loss: 2.6967194080352783\n",
      "Iteration 1100, Loss: 2.6712515354156494\n",
      "Iteration 1200, Loss: 2.658823013305664\n",
      "Iteration 1300, Loss: 2.6462435722351074\n",
      "Iteration 1400, Loss: 2.6343815326690674\n",
      "Iteration 1500, Loss: 2.6231119632720947\n",
      "Iteration 1600, Loss: 2.6117584705352783\n",
      "Iteration 1700, Loss: 2.605640172958374\n",
      "Iteration 1800, Loss: 2.5937561988830566\n",
      "Iteration 1900, Loss: 2.5884335041046143\n",
      "Iteration 2000, Loss: 2.576319694519043\n",
      "Iteration 2100, Loss: 2.5766067504882812\n",
      "Iteration 2200, Loss: 2.5620439052581787\n",
      "Iteration 2300, Loss: 2.559061288833618\n",
      "Iteration 2400, Loss: 2.5530292987823486\n",
      "Iteration 2500, Loss: 2.548100709915161\n",
      "Iteration 2600, Loss: 2.543968915939331\n",
      "Iteration 2700, Loss: 2.532966136932373\n",
      "Iteration 2800, Loss: 2.530071496963501\n",
      "Iteration 2900, Loss: 2.5245845317840576\n",
      "Iteration 0, Loss: 3.2225987911224365\n",
      "Iteration 100, Loss: 2.9972169399261475\n",
      "Iteration 200, Loss: 2.896713972091675\n",
      "Iteration 300, Loss: 2.8425676822662354\n",
      "Iteration 400, Loss: 2.801708936691284\n",
      "Iteration 500, Loss: 2.7702431678771973\n",
      "Iteration 600, Loss: 2.7399649620056152\n",
      "Iteration 700, Loss: 2.715491533279419\n",
      "Iteration 800, Loss: 2.702927589416504\n",
      "Iteration 900, Loss: 2.6796374320983887\n",
      "Iteration 1000, Loss: 2.6618494987487793\n",
      "Iteration 1100, Loss: 2.6542856693267822\n",
      "Iteration 1200, Loss: 2.637342691421509\n",
      "Iteration 1300, Loss: 2.634333372116089\n",
      "Iteration 1400, Loss: 2.6176211833953857\n",
      "Iteration 1500, Loss: 2.6094419956207275\n",
      "Iteration 1600, Loss: 2.595250368118286\n",
      "Iteration 1700, Loss: 2.592334747314453\n",
      "Iteration 1800, Loss: 2.609745740890503\n",
      "Iteration 1900, Loss: 2.579810380935669\n",
      "Iteration 2000, Loss: 2.5717785358428955\n",
      "Iteration 2100, Loss: 2.5643301010131836\n",
      "Iteration 2200, Loss: 2.5704851150512695\n",
      "Iteration 2300, Loss: 2.552121639251709\n",
      "Iteration 2400, Loss: 2.5467703342437744\n",
      "Iteration 2500, Loss: 2.54044508934021\n",
      "Iteration 2600, Loss: 2.536929130554199\n",
      "Iteration 2700, Loss: 2.5331666469573975\n",
      "Iteration 2800, Loss: 2.5247509479522705\n",
      "Iteration 2900, Loss: 2.525459051132202\n",
      "Iteration 0, Loss: 3.2483575344085693\n",
      "Iteration 100, Loss: 3.0252342224121094\n",
      "Iteration 200, Loss: 2.930990695953369\n",
      "Iteration 300, Loss: 2.8761026859283447\n",
      "Iteration 400, Loss: 2.839962959289551\n",
      "Iteration 500, Loss: 2.812249183654785\n",
      "Iteration 600, Loss: 2.789527416229248\n",
      "Iteration 700, Loss: 2.768519163131714\n",
      "Iteration 800, Loss: 2.767674446105957\n",
      "Iteration 900, Loss: 2.7321054935455322\n",
      "Iteration 1000, Loss: 2.7240967750549316\n",
      "Iteration 1100, Loss: 2.7083003520965576\n",
      "Iteration 1200, Loss: 2.690337896347046\n",
      "Iteration 1300, Loss: 2.678732395172119\n",
      "Iteration 1400, Loss: 2.67109751701355\n",
      "Iteration 1500, Loss: 2.662838935852051\n",
      "Iteration 1600, Loss: 2.648710250854492\n",
      "Iteration 1700, Loss: 2.6405928134918213\n",
      "Iteration 1800, Loss: 2.6309750080108643\n",
      "Iteration 1900, Loss: 2.6235721111297607\n",
      "Iteration 2000, Loss: 2.618744134902954\n",
      "Iteration 2100, Loss: 2.613027334213257\n",
      "Iteration 2200, Loss: 2.600703716278076\n",
      "Iteration 2300, Loss: 2.598977565765381\n",
      "Iteration 2400, Loss: 2.5922656059265137\n",
      "Iteration 2500, Loss: 2.5832974910736084\n",
      "Iteration 2600, Loss: 2.581359624862671\n",
      "Iteration 2700, Loss: 2.580237865447998\n",
      "Iteration 2800, Loss: 2.569934129714966\n",
      "Iteration 2900, Loss: 2.563411235809326\n",
      "Iteration 0, Loss: 3.2273099422454834\n",
      "Iteration 100, Loss: 3.003380060195923\n",
      "Iteration 200, Loss: 2.914956569671631\n",
      "Iteration 300, Loss: 2.8631317615509033\n",
      "Iteration 400, Loss: 2.8235878944396973\n",
      "Iteration 500, Loss: 2.7874755859375\n",
      "Iteration 600, Loss: 2.765359401702881\n",
      "Iteration 700, Loss: 2.737593173980713\n",
      "Iteration 800, Loss: 2.718111276626587\n",
      "Iteration 900, Loss: 2.6979427337646484\n",
      "Iteration 1000, Loss: 2.684859275817871\n",
      "Iteration 1100, Loss: 2.6704304218292236\n",
      "Iteration 1200, Loss: 2.6528067588806152\n",
      "Iteration 1300, Loss: 2.639618158340454\n",
      "Iteration 1400, Loss: 2.63281512260437\n",
      "Iteration 1500, Loss: 2.623964786529541\n",
      "Iteration 1600, Loss: 2.6099555492401123\n",
      "Iteration 1700, Loss: 2.6030147075653076\n",
      "Iteration 1800, Loss: 2.5900750160217285\n",
      "Iteration 1900, Loss: 2.583322763442993\n",
      "Iteration 2000, Loss: 2.580591917037964\n",
      "Iteration 2100, Loss: 2.5753490924835205\n",
      "Iteration 2200, Loss: 2.562326669692993\n",
      "Iteration 2300, Loss: 2.557847023010254\n",
      "Iteration 2400, Loss: 2.5517592430114746\n",
      "Iteration 2500, Loss: 2.546896457672119\n",
      "Iteration 2600, Loss: 2.541882038116455\n",
      "Iteration 2700, Loss: 2.54018235206604\n",
      "Iteration 2800, Loss: 2.5345027446746826\n",
      "Iteration 2900, Loss: 2.531895875930786\n",
      "Iteration 0, Loss: 3.1198883056640625\n",
      "Iteration 100, Loss: 2.905665397644043\n",
      "Iteration 200, Loss: 2.8291327953338623\n",
      "Iteration 300, Loss: 2.7896945476531982\n",
      "Iteration 400, Loss: 2.7239434719085693\n",
      "Iteration 500, Loss: 2.6878554821014404\n",
      "Iteration 600, Loss: 2.6669986248016357\n",
      "Iteration 700, Loss: 2.6249496936798096\n",
      "Iteration 800, Loss: 2.5993659496307373\n",
      "Iteration 900, Loss: 2.5836341381073\n",
      "Iteration 1000, Loss: 2.5644381046295166\n",
      "Iteration 1100, Loss: 2.550400495529175\n",
      "Iteration 1200, Loss: 2.531609296798706\n",
      "Iteration 1300, Loss: 2.5190892219543457\n",
      "Iteration 1400, Loss: 2.5092570781707764\n",
      "Iteration 1500, Loss: 2.497039318084717\n",
      "Iteration 1600, Loss: 2.4877982139587402\n",
      "Iteration 1700, Loss: 2.4772589206695557\n",
      "Iteration 1800, Loss: 2.4688210487365723\n",
      "Iteration 1900, Loss: 2.462061643600464\n",
      "Iteration 2000, Loss: 2.456961154937744\n",
      "Iteration 2100, Loss: 2.4516637325286865\n",
      "Iteration 2200, Loss: 2.4441378116607666\n",
      "Iteration 2300, Loss: 2.435286283493042\n",
      "Iteration 2400, Loss: 2.4285778999328613\n",
      "Iteration 2500, Loss: 2.4203860759735107\n",
      "Iteration 2600, Loss: 2.414088249206543\n",
      "Iteration 2700, Loss: 2.4117517471313477\n",
      "Iteration 2800, Loss: 2.407090663909912\n",
      "Iteration 2900, Loss: 2.3998656272888184\n",
      "Iteration 0, Loss: 3.3201048374176025\n",
      "Iteration 100, Loss: 3.0715949535369873\n",
      "Iteration 200, Loss: 2.987616777420044\n",
      "Iteration 300, Loss: 2.931255340576172\n",
      "Iteration 400, Loss: 2.8883705139160156\n",
      "Iteration 500, Loss: 2.8606371879577637\n",
      "Iteration 600, Loss: 2.8340110778808594\n",
      "Iteration 700, Loss: 2.8103349208831787\n",
      "Iteration 800, Loss: 2.7966461181640625\n",
      "Iteration 900, Loss: 2.7749059200286865\n",
      "Iteration 1000, Loss: 2.7579996585845947\n",
      "Iteration 1100, Loss: 2.745022773742676\n",
      "Iteration 1200, Loss: 2.73170804977417\n",
      "Iteration 1300, Loss: 2.7224173545837402\n",
      "Iteration 1400, Loss: 2.7192301750183105\n",
      "Iteration 1500, Loss: 2.7035346031188965\n",
      "Iteration 1600, Loss: 2.6923623085021973\n",
      "Iteration 1700, Loss: 2.681755781173706\n",
      "Iteration 1800, Loss: 2.6762728691101074\n",
      "Iteration 1900, Loss: 2.670074462890625\n",
      "Iteration 2000, Loss: 2.6613357067108154\n",
      "Iteration 2100, Loss: 2.656118392944336\n",
      "Iteration 2200, Loss: 2.6492409706115723\n",
      "Iteration 2300, Loss: 2.6433236598968506\n",
      "Iteration 2400, Loss: 2.640855550765991\n",
      "Iteration 2500, Loss: 2.632059335708618\n",
      "Iteration 2600, Loss: 2.628605604171753\n",
      "Iteration 2700, Loss: 2.619920492172241\n",
      "Iteration 2800, Loss: 2.618060350418091\n",
      "Iteration 2900, Loss: 2.610576868057251\n",
      "Iteration 0, Loss: 3.2292213439941406\n",
      "Iteration 100, Loss: 3.0141570568084717\n",
      "Iteration 200, Loss: 2.9283313751220703\n",
      "Iteration 300, Loss: 2.876268148422241\n",
      "Iteration 400, Loss: 2.8484482765197754\n",
      "Iteration 500, Loss: 2.8177990913391113\n",
      "Iteration 600, Loss: 2.7863657474517822\n",
      "Iteration 700, Loss: 2.764446973800659\n",
      "Iteration 800, Loss: 2.7462337017059326\n",
      "Iteration 900, Loss: 2.7288098335266113\n",
      "Iteration 1000, Loss: 2.7129132747650146\n",
      "Iteration 1100, Loss: 2.7074568271636963\n",
      "Iteration 1200, Loss: 2.683532238006592\n",
      "Iteration 1300, Loss: 2.6709697246551514\n",
      "Iteration 1400, Loss: 2.6600377559661865\n",
      "Iteration 1500, Loss: 2.6471939086914062\n",
      "Iteration 1600, Loss: 2.645735502243042\n",
      "Iteration 1700, Loss: 2.631655693054199\n",
      "Iteration 1800, Loss: 2.6200664043426514\n",
      "Iteration 1900, Loss: 2.6201999187469482\n",
      "Iteration 2000, Loss: 2.6142213344573975\n",
      "Iteration 2100, Loss: 2.597181797027588\n",
      "Iteration 2200, Loss: 2.6003289222717285\n",
      "Iteration 2300, Loss: 2.590283155441284\n",
      "Iteration 2400, Loss: 2.58630633354187\n",
      "Iteration 2500, Loss: 2.5777878761291504\n",
      "Iteration 2600, Loss: 2.569094657897949\n",
      "Iteration 2700, Loss: 2.569049119949341\n",
      "Iteration 2800, Loss: 2.5596699714660645\n",
      "Iteration 2900, Loss: 2.5570573806762695\n",
      "Iteration 0, Loss: 3.306490182876587\n",
      "Iteration 100, Loss: 3.059652805328369\n",
      "Iteration 200, Loss: 2.979445695877075\n",
      "Iteration 300, Loss: 2.9298174381256104\n",
      "Iteration 400, Loss: 2.894681215286255\n",
      "Iteration 500, Loss: 2.865215301513672\n",
      "Iteration 600, Loss: 2.8441591262817383\n",
      "Iteration 700, Loss: 2.8175783157348633\n",
      "Iteration 800, Loss: 2.8035776615142822\n",
      "Iteration 900, Loss: 2.784553050994873\n",
      "Iteration 1000, Loss: 2.768202781677246\n",
      "Iteration 1100, Loss: 2.7548556327819824\n",
      "Iteration 1200, Loss: 2.7421164512634277\n",
      "Iteration 1300, Loss: 2.73123836517334\n",
      "Iteration 1400, Loss: 2.717909812927246\n",
      "Iteration 1500, Loss: 2.7070953845977783\n",
      "Iteration 1600, Loss: 2.696718692779541\n",
      "Iteration 1700, Loss: 2.688253402709961\n",
      "Iteration 1800, Loss: 2.6796348094940186\n",
      "Iteration 1900, Loss: 2.6741528511047363\n",
      "Iteration 2000, Loss: 2.6646735668182373\n",
      "Iteration 2100, Loss: 2.6586592197418213\n",
      "Iteration 2200, Loss: 2.654723644256592\n",
      "Iteration 2300, Loss: 2.643993377685547\n",
      "Iteration 2400, Loss: 2.6454010009765625\n",
      "Iteration 2500, Loss: 2.6382365226745605\n",
      "Iteration 2600, Loss: 2.6283788681030273\n",
      "Iteration 2700, Loss: 2.621975898742676\n",
      "Iteration 2800, Loss: 2.623699426651001\n",
      "Iteration 2900, Loss: 2.6168925762176514\n",
      "Iteration 0, Loss: 3.0926291942596436\n",
      "Iteration 100, Loss: 2.850670576095581\n",
      "Iteration 200, Loss: 2.764038324356079\n",
      "Iteration 300, Loss: 2.719219923019409\n",
      "Iteration 400, Loss: 2.6776018142700195\n",
      "Iteration 500, Loss: 2.6460888385772705\n",
      "Iteration 600, Loss: 2.6169204711914062\n",
      "Iteration 700, Loss: 2.5968966484069824\n",
      "Iteration 800, Loss: 2.5746853351593018\n",
      "Iteration 900, Loss: 2.5610201358795166\n",
      "Iteration 1000, Loss: 2.540762186050415\n",
      "Iteration 1100, Loss: 2.5225307941436768\n",
      "Iteration 1200, Loss: 2.5130794048309326\n",
      "Iteration 1300, Loss: 2.499673843383789\n",
      "Iteration 1400, Loss: 2.486128330230713\n",
      "Iteration 1500, Loss: 2.476924419403076\n",
      "Iteration 1600, Loss: 2.465766668319702\n",
      "Iteration 1700, Loss: 2.4557275772094727\n",
      "Iteration 1800, Loss: 2.4434680938720703\n",
      "Iteration 1900, Loss: 2.438640832901001\n",
      "Iteration 2000, Loss: 2.4348747730255127\n",
      "Iteration 2100, Loss: 2.424452066421509\n",
      "Iteration 2200, Loss: 2.4119019508361816\n",
      "Iteration 2300, Loss: 2.4070870876312256\n",
      "Iteration 2400, Loss: 2.3998055458068848\n",
      "Iteration 2500, Loss: 2.392784595489502\n",
      "Iteration 2600, Loss: 2.3826327323913574\n",
      "Iteration 2700, Loss: 2.377027750015259\n",
      "Iteration 2800, Loss: 2.374358892440796\n",
      "Iteration 2900, Loss: 2.364631175994873\n",
      "Iteration 0, Loss: 3.2773983478546143\n",
      "Iteration 100, Loss: 3.061647653579712\n",
      "Iteration 200, Loss: 2.9946186542510986\n",
      "Iteration 300, Loss: 2.945042610168457\n",
      "Iteration 400, Loss: 2.905397891998291\n",
      "Iteration 500, Loss: 2.883967876434326\n",
      "Iteration 600, Loss: 2.857095718383789\n",
      "Iteration 700, Loss: 2.825672149658203\n",
      "Iteration 800, Loss: 2.8099212646484375\n",
      "Iteration 900, Loss: 2.7882392406463623\n",
      "Iteration 1000, Loss: 2.7701642513275146\n",
      "Iteration 1100, Loss: 2.7548398971557617\n",
      "Iteration 1200, Loss: 2.7407846450805664\n",
      "Iteration 1300, Loss: 2.7479279041290283\n",
      "Iteration 1400, Loss: 2.7206552028656006\n",
      "Iteration 1500, Loss: 2.7101778984069824\n",
      "Iteration 1600, Loss: 2.700031280517578\n",
      "Iteration 1700, Loss: 2.6845643520355225\n",
      "Iteration 1800, Loss: 2.6837270259857178\n",
      "Iteration 1900, Loss: 2.6748342514038086\n",
      "Iteration 2000, Loss: 2.6616413593292236\n",
      "Iteration 2100, Loss: 2.65903377532959\n",
      "Iteration 2200, Loss: 2.651411533355713\n",
      "Iteration 2300, Loss: 2.6421988010406494\n",
      "Iteration 2400, Loss: 2.634195327758789\n",
      "Iteration 2500, Loss: 2.6297476291656494\n",
      "Iteration 2600, Loss: 2.6225812435150146\n",
      "Iteration 2700, Loss: 2.6180226802825928\n",
      "Iteration 2800, Loss: 2.61246919631958\n",
      "Iteration 2900, Loss: 2.6088340282440186\n",
      "Iteration 0, Loss: 3.263235569000244\n",
      "Iteration 100, Loss: 3.056466817855835\n",
      "Iteration 200, Loss: 3.0353305339813232\n",
      "Iteration 300, Loss: 2.925060510635376\n",
      "Iteration 400, Loss: 2.904867172241211\n",
      "Iteration 500, Loss: 2.8486149311065674\n",
      "Iteration 600, Loss: 2.8215904235839844\n",
      "Iteration 700, Loss: 2.797821521759033\n",
      "Iteration 800, Loss: 2.8060462474823\n",
      "Iteration 900, Loss: 2.7838687896728516\n",
      "Iteration 1000, Loss: 2.7483291625976562\n",
      "Iteration 1100, Loss: 2.7323555946350098\n",
      "Iteration 1200, Loss: 2.716230630874634\n",
      "Iteration 1300, Loss: 2.7036545276641846\n",
      "Iteration 1400, Loss: 2.6934945583343506\n",
      "Iteration 1500, Loss: 2.6813716888427734\n",
      "Iteration 1600, Loss: 2.6718413829803467\n",
      "Iteration 1700, Loss: 2.6613166332244873\n",
      "Iteration 1800, Loss: 2.6507022380828857\n",
      "Iteration 1900, Loss: 2.6427369117736816\n",
      "Iteration 2000, Loss: 2.640061616897583\n",
      "Iteration 2100, Loss: 2.6278750896453857\n",
      "Iteration 2200, Loss: 2.623797655105591\n",
      "Iteration 2300, Loss: 2.616762399673462\n",
      "Iteration 2400, Loss: 2.6065120697021484\n",
      "Iteration 2500, Loss: 2.6038706302642822\n",
      "Iteration 2600, Loss: 2.5963284969329834\n",
      "Iteration 2700, Loss: 2.5942349433898926\n",
      "Iteration 2800, Loss: 2.5845818519592285\n",
      "Iteration 2900, Loss: 2.5797908306121826\n",
      "Iteration 0, Loss: 3.259795904159546\n",
      "Iteration 100, Loss: 3.0322489738464355\n",
      "Iteration 200, Loss: 2.9454855918884277\n",
      "Iteration 300, Loss: 2.911217451095581\n",
      "Iteration 400, Loss: 2.8654377460479736\n",
      "Iteration 500, Loss: 2.8307807445526123\n",
      "Iteration 600, Loss: 2.800794839859009\n",
      "Iteration 700, Loss: 2.7838008403778076\n",
      "Iteration 800, Loss: 2.7647435665130615\n",
      "Iteration 900, Loss: 2.7478647232055664\n",
      "Iteration 1000, Loss: 2.7350525856018066\n",
      "Iteration 1100, Loss: 2.718259334564209\n",
      "Iteration 1200, Loss: 2.711857557296753\n",
      "Iteration 1300, Loss: 2.6964833736419678\n",
      "Iteration 1400, Loss: 2.687833309173584\n",
      "Iteration 1500, Loss: 2.677459716796875\n",
      "Iteration 1600, Loss: 2.6670727729797363\n",
      "Iteration 1700, Loss: 2.660794734954834\n",
      "Iteration 1800, Loss: 2.6537718772888184\n",
      "Iteration 1900, Loss: 2.644196033477783\n",
      "Iteration 2000, Loss: 2.6388754844665527\n",
      "Iteration 2100, Loss: 2.6359241008758545\n",
      "Iteration 2200, Loss: 2.6281349658966064\n",
      "Iteration 2300, Loss: 2.62546443939209\n",
      "Iteration 2400, Loss: 2.6149840354919434\n",
      "Iteration 2500, Loss: 2.607412576675415\n",
      "Iteration 2600, Loss: 2.600141763687134\n",
      "Iteration 2700, Loss: 2.591158866882324\n",
      "Iteration 2800, Loss: 2.591475009918213\n",
      "Iteration 2900, Loss: 2.595552921295166\n",
      "Iteration 0, Loss: 3.2374422550201416\n",
      "Iteration 100, Loss: 2.966684579849243\n",
      "Iteration 200, Loss: 2.895340919494629\n",
      "Iteration 300, Loss: 2.8224754333496094\n",
      "Iteration 400, Loss: 2.803814649581909\n",
      "Iteration 500, Loss: 2.74019193649292\n",
      "Iteration 600, Loss: 2.7152538299560547\n",
      "Iteration 700, Loss: 2.690063953399658\n",
      "Iteration 800, Loss: 2.6704156398773193\n",
      "Iteration 900, Loss: 2.6541571617126465\n",
      "Iteration 1000, Loss: 2.6330671310424805\n",
      "Iteration 1100, Loss: 2.6232728958129883\n",
      "Iteration 1200, Loss: 2.606928825378418\n",
      "Iteration 1300, Loss: 2.599853754043579\n",
      "Iteration 1400, Loss: 2.5828380584716797\n",
      "Iteration 1500, Loss: 2.5750110149383545\n",
      "Iteration 1600, Loss: 2.561770439147949\n",
      "Iteration 1700, Loss: 2.5542523860931396\n",
      "Iteration 1800, Loss: 2.5522899627685547\n",
      "Iteration 1900, Loss: 2.5419797897338867\n",
      "Iteration 2000, Loss: 2.538926124572754\n",
      "Iteration 2100, Loss: 2.5289134979248047\n",
      "Iteration 2200, Loss: 2.521880865097046\n",
      "Iteration 2300, Loss: 2.511837959289551\n",
      "Iteration 2400, Loss: 2.513622283935547\n",
      "Iteration 2500, Loss: 2.5038907527923584\n",
      "Iteration 2600, Loss: 2.498690366744995\n",
      "Iteration 2700, Loss: 2.4961233139038086\n",
      "Iteration 2800, Loss: 2.4920907020568848\n",
      "Iteration 2900, Loss: 2.489377975463867\n",
      "Iteration 0, Loss: 3.254434823989868\n",
      "Iteration 100, Loss: 2.9502065181732178\n",
      "Iteration 200, Loss: 2.8738226890563965\n",
      "Iteration 300, Loss: 2.8206679821014404\n",
      "Iteration 400, Loss: 2.7872846126556396\n",
      "Iteration 500, Loss: 2.7552011013031006\n",
      "Iteration 600, Loss: 2.725116014480591\n",
      "Iteration 700, Loss: 2.6995902061462402\n",
      "Iteration 800, Loss: 2.6815357208251953\n",
      "Iteration 900, Loss: 2.6758954524993896\n",
      "Iteration 1000, Loss: 2.648952007293701\n",
      "Iteration 1100, Loss: 2.633495330810547\n",
      "Iteration 1200, Loss: 2.61596417427063\n",
      "Iteration 1300, Loss: 2.607647657394409\n",
      "Iteration 1400, Loss: 2.5971148014068604\n",
      "Iteration 1500, Loss: 2.582026958465576\n",
      "Iteration 1600, Loss: 2.578474998474121\n",
      "Iteration 1700, Loss: 2.563387870788574\n",
      "Iteration 1800, Loss: 2.5551342964172363\n",
      "Iteration 1900, Loss: 2.5541605949401855\n",
      "Iteration 2000, Loss: 2.5405333042144775\n",
      "Iteration 2100, Loss: 2.5438194274902344\n",
      "Iteration 2200, Loss: 2.5328614711761475\n",
      "Iteration 2300, Loss: 2.5252153873443604\n",
      "Iteration 2400, Loss: 2.522317886352539\n",
      "Iteration 2500, Loss: 2.516460418701172\n",
      "Iteration 2600, Loss: 2.509922981262207\n",
      "Iteration 2700, Loss: 2.504221200942993\n",
      "Iteration 2800, Loss: 2.500195026397705\n",
      "Iteration 2900, Loss: 2.4974188804626465\n",
      "Iteration 0, Loss: 3.152385950088501\n",
      "Iteration 100, Loss: 2.912811517715454\n",
      "Iteration 200, Loss: 2.837507724761963\n",
      "Iteration 300, Loss: 2.7725722789764404\n",
      "Iteration 400, Loss: 2.7352356910705566\n",
      "Iteration 500, Loss: 2.6932480335235596\n",
      "Iteration 600, Loss: 2.665466785430908\n",
      "Iteration 700, Loss: 2.6406850814819336\n",
      "Iteration 800, Loss: 2.6208314895629883\n",
      "Iteration 900, Loss: 2.6084024906158447\n",
      "Iteration 1000, Loss: 2.604149103164673\n",
      "Iteration 1100, Loss: 2.579108715057373\n",
      "Iteration 1200, Loss: 2.5697083473205566\n",
      "Iteration 1300, Loss: 2.5647525787353516\n",
      "Iteration 1400, Loss: 2.5473358631134033\n",
      "Iteration 1500, Loss: 2.5387637615203857\n",
      "Iteration 1600, Loss: 2.5287277698516846\n",
      "Iteration 1700, Loss: 2.521057367324829\n",
      "Iteration 1800, Loss: 2.512179374694824\n",
      "Iteration 1900, Loss: 2.504009485244751\n",
      "Iteration 2000, Loss: 2.5071916580200195\n",
      "Iteration 2100, Loss: 2.4927966594696045\n",
      "Iteration 2200, Loss: 2.4860148429870605\n",
      "Iteration 2300, Loss: 2.479553461074829\n",
      "Iteration 2400, Loss: 2.4777514934539795\n",
      "Iteration 2500, Loss: 2.4688034057617188\n",
      "Iteration 2600, Loss: 2.4610233306884766\n",
      "Iteration 2700, Loss: 2.4638583660125732\n",
      "Iteration 2800, Loss: 2.459444522857666\n",
      "Iteration 2900, Loss: 2.4433114528656006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "\n",
    "C_on_perm=np.empty([116,116,50])\n",
    "loss_on_perm=np.zeros((50))\n",
    "angpermscore=np.zeros((50))\n",
    "for perm in range(50):\n",
    "    Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps.mat')['XA']\n",
    "    Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps.mat')['YA']\n",
    "\n",
    "    X=torch.from_numpy(np.float32(Xall))\n",
    "    n = X.size(0)\n",
    "\n",
    "    #apply rotation using random skew symmetric orthogonal transform\n",
    "    Aa=np.random.randn(n,n)\n",
    "    Yall=cayley_numpy(Aa-Aa.T)*Yall * scipy.linalg.inv(cayley_numpy(Aa-Aa.T))\n",
    "\n",
    "    Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "    # Initialize a skew-symmetric matrix A\n",
    "\n",
    "    A = torch.randn((n, n), requires_grad=True)\n",
    "    A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "    # Use ADAM optimizer\n",
    "    optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "        C = cayley_transform(A)\n",
    "        loss = loss_function(X, Y, C)\n",
    "\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update A using gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "    # Final optimized C\n",
    "    C_perm = cayley_transform(A)\n",
    "    C_perm=C_perm.detach().numpy()\n",
    "    C_on_perm[:,:,perm]=C_perm\n",
    "    losstmp = loss.detach().numpy()\n",
    "    loss_on_perm[perm]=losstmp\n",
    "\n",
    "    #compute angular\n",
    "    num = np.trace(X.detach().numpy().T @ C_perm @ Y.detach().numpy() @ np.linalg.inv(C_perm))\n",
    "\n",
    "\n",
    "    denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "    denom=denom.detach().numpy()\n",
    "    angpermscore[perm] = np.cos(np.arccos(num/denom))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "mdic = {'optimizedC':[C_optimized],'optoloss':[Optimized_loss],'angularoptimal': [angoptimalscore],'loss_on_perm_random': [loss_on_perm],'C_on_perm' : [C_on_perm],'angperscore': [angpermscore]}\n",
    "savemat(DataFold+'/C_optimized_full_dmd_ACC.mat',mdic)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perm with eigen maintained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now do DSA in PMD with A~ high components models with ncomps=197 (80% variance in PODs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_PMD.mat')['XA']\n",
    "Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_PMD.mat')['YA']\n",
    "\n",
    "\n",
    "X=torch.from_numpy(np.float32(Xall))\n",
    "Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "\n",
    "max_iterations=3000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 5.882142543792725\n",
      "Iteration 100, Loss: 4.629274845123291\n",
      "Iteration 200, Loss: 4.01328182220459\n",
      "Iteration 300, Loss: 3.6558966636657715\n",
      "Iteration 400, Loss: 3.4177539348602295\n",
      "Iteration 500, Loss: 3.2521886825561523\n",
      "Iteration 600, Loss: 3.120637893676758\n",
      "Iteration 700, Loss: 3.002737283706665\n",
      "Iteration 800, Loss: 2.9100944995880127\n",
      "Iteration 900, Loss: 2.823728322982788\n",
      "Iteration 1000, Loss: 2.74371075630188\n",
      "Iteration 1100, Loss: 2.6726346015930176\n",
      "Iteration 1200, Loss: 2.610757827758789\n",
      "Iteration 1300, Loss: 2.5532736778259277\n",
      "Iteration 1400, Loss: 2.5018062591552734\n",
      "Iteration 1500, Loss: 2.469520092010498\n",
      "Iteration 1600, Loss: 2.423938751220703\n",
      "Iteration 1700, Loss: 2.3738059997558594\n",
      "Iteration 1800, Loss: 2.338578701019287\n",
      "Iteration 1900, Loss: 2.301952838897705\n",
      "Iteration 2000, Loss: 2.274930715560913\n",
      "Iteration 2100, Loss: 2.2530088424682617\n",
      "Iteration 2200, Loss: 2.2187283039093018\n",
      "Iteration 2300, Loss: 2.189997434616089\n",
      "Iteration 2400, Loss: 2.178333282470703\n",
      "Iteration 2500, Loss: 2.1455063819885254\n",
      "Iteration 2600, Loss: 2.119454860687256\n",
      "Iteration 2700, Loss: 2.098820447921753\n",
      "Iteration 2800, Loss: 2.079981565475464\n",
      "Iteration 2900, Loss: 2.0639402866363525\n"
     ]
    }
   ],
   "source": [
    "n = X.size(0)\n",
    "\n",
    "# Initialize a skew-symmetric matrix A\n",
    "\n",
    "A = torch.randn((n, n), requires_grad=True)\n",
    "A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "# Use ADAM optimizer\n",
    "optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "    C = cayley_transform(A)\n",
    "    loss = loss_function(X, Y, C)\n",
    "\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update A using gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration % 100 == 0:\n",
    "        print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "# Final optimized C\n",
    "C_optimized = cayley_transform(A)\n",
    "C_optimized=C_optimized.detach().numpy()\n",
    "Optimized_loss=loss.detach().numpy()\n",
    "\n",
    "#compute angular\n",
    "num = np.trace(X.detach().numpy().T @ C_optimized @ Y.detach().numpy() @ np.linalg.inv(C_optimized))\n",
    "\n",
    "\n",
    "denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "denom=denom.detach().numpy()\n",
    "angoptimalscore = np.cos(np.arccos(num/denom))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do perm DSA with PMD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 4.674692630767822\n",
      "Iteration 100, Loss: 4.486717700958252\n",
      "Iteration 200, Loss: 4.379359245300293\n",
      "Iteration 300, Loss: 4.318807601928711\n",
      "Iteration 400, Loss: 4.261453628540039\n",
      "Iteration 500, Loss: 4.211609363555908\n",
      "Iteration 600, Loss: 4.183804512023926\n",
      "Iteration 700, Loss: 4.151187896728516\n",
      "Iteration 800, Loss: 4.097973823547363\n",
      "Iteration 900, Loss: 4.079065322875977\n",
      "Iteration 1000, Loss: 4.064431190490723\n",
      "Iteration 1100, Loss: 4.008897304534912\n",
      "Iteration 1200, Loss: 3.9841392040252686\n",
      "Iteration 1300, Loss: 3.9730417728424072\n",
      "Iteration 1400, Loss: 3.956218957901001\n",
      "Iteration 1500, Loss: 3.9541056156158447\n",
      "Iteration 1600, Loss: 3.9185853004455566\n",
      "Iteration 1700, Loss: 3.901047468185425\n",
      "Iteration 1800, Loss: 3.875500440597534\n",
      "Iteration 1900, Loss: 3.853907585144043\n",
      "Iteration 2000, Loss: 3.8470351696014404\n",
      "Iteration 2100, Loss: 3.823117256164551\n",
      "Iteration 2200, Loss: 3.815187692642212\n",
      "Iteration 2300, Loss: 3.802658796310425\n",
      "Iteration 2400, Loss: 3.790266990661621\n",
      "Iteration 2500, Loss: 3.7674083709716797\n",
      "Iteration 2600, Loss: 3.7634365558624268\n",
      "Iteration 2700, Loss: 3.7405917644500732\n",
      "Iteration 2800, Loss: 3.729285955429077\n",
      "Iteration 2900, Loss: 3.7231342792510986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/_yg34tj15s306l4m7k_wf0qw0000gq/T/ipykernel_44290/3053493548.py:54: RuntimeWarning: invalid value encountered in arccos\n",
      "  angpermscore[perm] = np.cos(np.arccos(num/denom))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 4.639807224273682\n",
      "Iteration 100, Loss: 4.458405017852783\n",
      "Iteration 200, Loss: 4.421462059020996\n",
      "Iteration 300, Loss: 4.355259895324707\n",
      "Iteration 400, Loss: 4.329426288604736\n",
      "Iteration 500, Loss: 4.251631736755371\n",
      "Iteration 600, Loss: 4.180776119232178\n",
      "Iteration 700, Loss: 4.139563083648682\n",
      "Iteration 800, Loss: 4.082249164581299\n",
      "Iteration 900, Loss: 4.051419734954834\n",
      "Iteration 1000, Loss: 4.027443885803223\n",
      "Iteration 1100, Loss: 3.9881343841552734\n",
      "Iteration 1200, Loss: 3.954993486404419\n",
      "Iteration 1300, Loss: 3.941052198410034\n",
      "Iteration 1400, Loss: 3.8958261013031006\n",
      "Iteration 1500, Loss: 3.8871712684631348\n",
      "Iteration 1600, Loss: 3.8637006282806396\n",
      "Iteration 1700, Loss: 3.846083402633667\n",
      "Iteration 1800, Loss: 3.823432445526123\n",
      "Iteration 1900, Loss: 3.812854766845703\n",
      "Iteration 2000, Loss: 3.7943272590637207\n",
      "Iteration 2100, Loss: 3.779947280883789\n",
      "Iteration 2200, Loss: 3.7551589012145996\n",
      "Iteration 2300, Loss: 3.7390339374542236\n",
      "Iteration 2400, Loss: 3.7344796657562256\n",
      "Iteration 2500, Loss: 3.7179806232452393\n",
      "Iteration 2600, Loss: 3.699617385864258\n",
      "Iteration 2700, Loss: 3.700669527053833\n",
      "Iteration 2800, Loss: 3.693995952606201\n",
      "Iteration 2900, Loss: 3.665940761566162\n",
      "Iteration 0, Loss: 4.651632785797119\n",
      "Iteration 100, Loss: 4.438968658447266\n",
      "Iteration 200, Loss: 4.394651889801025\n",
      "Iteration 300, Loss: 4.300394058227539\n",
      "Iteration 400, Loss: 4.252998352050781\n",
      "Iteration 500, Loss: 4.191433906555176\n",
      "Iteration 600, Loss: 4.164698123931885\n",
      "Iteration 700, Loss: 4.143253803253174\n",
      "Iteration 800, Loss: 4.096830368041992\n",
      "Iteration 900, Loss: 4.08308219909668\n",
      "Iteration 1000, Loss: 4.028061866760254\n",
      "Iteration 1100, Loss: 4.008701324462891\n",
      "Iteration 1200, Loss: 3.9804892539978027\n",
      "Iteration 1300, Loss: 3.9672341346740723\n",
      "Iteration 1400, Loss: 3.9314827919006348\n",
      "Iteration 1500, Loss: 3.9193663597106934\n",
      "Iteration 1600, Loss: 3.904080867767334\n",
      "Iteration 1700, Loss: 3.8874294757843018\n",
      "Iteration 1800, Loss: 3.857910633087158\n",
      "Iteration 1900, Loss: 3.8314452171325684\n",
      "Iteration 2000, Loss: 3.813765048980713\n",
      "Iteration 2100, Loss: 3.8352723121643066\n",
      "Iteration 2200, Loss: 3.7853281497955322\n",
      "Iteration 2300, Loss: 3.773670196533203\n",
      "Iteration 2400, Loss: 3.7629382610321045\n",
      "Iteration 2500, Loss: 3.7454121112823486\n",
      "Iteration 2600, Loss: 3.7237091064453125\n",
      "Iteration 2700, Loss: 3.720266342163086\n",
      "Iteration 2800, Loss: 3.6984689235687256\n",
      "Iteration 2900, Loss: 3.7078261375427246\n",
      "Iteration 0, Loss: 4.677871227264404\n",
      "Iteration 100, Loss: 4.477049350738525\n",
      "Iteration 200, Loss: 4.43086051940918\n",
      "Iteration 300, Loss: 4.390860557556152\n",
      "Iteration 400, Loss: 4.37794828414917\n",
      "Iteration 500, Loss: 4.3121466636657715\n",
      "Iteration 600, Loss: 4.285996913909912\n",
      "Iteration 700, Loss: 4.224643707275391\n",
      "Iteration 800, Loss: 4.192187786102295\n",
      "Iteration 900, Loss: 4.152449607849121\n",
      "Iteration 1000, Loss: 4.119508743286133\n",
      "Iteration 1100, Loss: 4.093059062957764\n",
      "Iteration 1200, Loss: 4.06024694442749\n",
      "Iteration 1300, Loss: 4.032361030578613\n",
      "Iteration 1400, Loss: 4.014869689941406\n",
      "Iteration 1500, Loss: 3.99350905418396\n",
      "Iteration 1600, Loss: 3.9701812267303467\n",
      "Iteration 1700, Loss: 3.9466848373413086\n",
      "Iteration 1800, Loss: 3.9403162002563477\n",
      "Iteration 1900, Loss: 3.9177937507629395\n",
      "Iteration 2000, Loss: 3.9012858867645264\n",
      "Iteration 2100, Loss: 3.881409168243408\n",
      "Iteration 2200, Loss: 3.8639297485351562\n",
      "Iteration 2300, Loss: 3.8711585998535156\n",
      "Iteration 2400, Loss: 3.8372628688812256\n",
      "Iteration 2500, Loss: 3.8304617404937744\n",
      "Iteration 2600, Loss: 3.8208096027374268\n",
      "Iteration 2700, Loss: 3.8027591705322266\n",
      "Iteration 2800, Loss: 3.782158136367798\n",
      "Iteration 2900, Loss: 3.7769360542297363\n",
      "Iteration 0, Loss: 4.66638708114624\n",
      "Iteration 100, Loss: 4.52669095993042\n",
      "Iteration 200, Loss: 4.456454753875732\n",
      "Iteration 300, Loss: 4.398380756378174\n",
      "Iteration 400, Loss: 4.369646072387695\n",
      "Iteration 500, Loss: 4.263920307159424\n",
      "Iteration 600, Loss: 4.236642360687256\n",
      "Iteration 700, Loss: 4.185298442840576\n",
      "Iteration 800, Loss: 4.135085582733154\n",
      "Iteration 900, Loss: 4.094483375549316\n",
      "Iteration 1000, Loss: 4.05864143371582\n",
      "Iteration 1100, Loss: 4.03948450088501\n",
      "Iteration 1200, Loss: 3.9898383617401123\n",
      "Iteration 1300, Loss: 3.968085527420044\n",
      "Iteration 1400, Loss: 3.958066463470459\n",
      "Iteration 1500, Loss: 3.9205150604248047\n",
      "Iteration 1600, Loss: 3.91528058052063\n",
      "Iteration 1700, Loss: 3.895477771759033\n",
      "Iteration 1800, Loss: 3.885018825531006\n",
      "Iteration 1900, Loss: 3.8492014408111572\n",
      "Iteration 2000, Loss: 3.8454902172088623\n",
      "Iteration 2100, Loss: 3.8165149688720703\n",
      "Iteration 2200, Loss: 3.790531873703003\n",
      "Iteration 2300, Loss: 3.8016607761383057\n",
      "Iteration 2400, Loss: 3.7684271335601807\n",
      "Iteration 2500, Loss: 3.747574806213379\n",
      "Iteration 2600, Loss: 3.7406392097473145\n",
      "Iteration 2700, Loss: 3.7355124950408936\n",
      "Iteration 2800, Loss: 3.717435598373413\n",
      "Iteration 2900, Loss: 3.708775758743286\n",
      "Iteration 0, Loss: 4.650796890258789\n",
      "Iteration 100, Loss: 4.493610382080078\n",
      "Iteration 200, Loss: 4.428783416748047\n",
      "Iteration 300, Loss: 4.363717555999756\n",
      "Iteration 400, Loss: 4.307748317718506\n",
      "Iteration 500, Loss: 4.228851318359375\n",
      "Iteration 600, Loss: 4.173946380615234\n",
      "Iteration 700, Loss: 4.128531455993652\n",
      "Iteration 800, Loss: 4.104108810424805\n",
      "Iteration 900, Loss: 4.074618816375732\n",
      "Iteration 1000, Loss: 4.036635398864746\n",
      "Iteration 1100, Loss: 3.9984827041625977\n",
      "Iteration 1200, Loss: 3.990605115890503\n",
      "Iteration 1300, Loss: 3.9589121341705322\n",
      "Iteration 1400, Loss: 3.935833692550659\n",
      "Iteration 1500, Loss: 3.9317657947540283\n",
      "Iteration 1600, Loss: 3.896756649017334\n",
      "Iteration 1700, Loss: 3.8885650634765625\n",
      "Iteration 1800, Loss: 3.8549752235412598\n",
      "Iteration 1900, Loss: 3.8404288291931152\n",
      "Iteration 2000, Loss: 3.8298439979553223\n",
      "Iteration 2100, Loss: 3.82304048538208\n",
      "Iteration 2200, Loss: 3.792396068572998\n",
      "Iteration 2300, Loss: 3.7832865715026855\n",
      "Iteration 2400, Loss: 3.77587628364563\n",
      "Iteration 2500, Loss: 3.7710988521575928\n",
      "Iteration 2600, Loss: 3.741335391998291\n",
      "Iteration 2700, Loss: 3.7256948947906494\n",
      "Iteration 2800, Loss: 3.719508647918701\n",
      "Iteration 2900, Loss: 3.7087433338165283\n",
      "Iteration 0, Loss: 4.661137104034424\n",
      "Iteration 100, Loss: 4.52533483505249\n",
      "Iteration 200, Loss: 4.420931816101074\n",
      "Iteration 300, Loss: 4.391870498657227\n",
      "Iteration 400, Loss: 4.341494560241699\n",
      "Iteration 500, Loss: 4.306282997131348\n",
      "Iteration 600, Loss: 4.243839263916016\n",
      "Iteration 700, Loss: 4.203715801239014\n",
      "Iteration 800, Loss: 4.155141353607178\n",
      "Iteration 900, Loss: 4.171729564666748\n",
      "Iteration 1000, Loss: 4.084591865539551\n",
      "Iteration 1100, Loss: 4.062302112579346\n",
      "Iteration 1200, Loss: 4.04962158203125\n",
      "Iteration 1300, Loss: 4.028613567352295\n",
      "Iteration 1400, Loss: 3.9915761947631836\n",
      "Iteration 1500, Loss: 3.970461845397949\n",
      "Iteration 1600, Loss: 3.947072982788086\n",
      "Iteration 1700, Loss: 3.9276938438415527\n",
      "Iteration 1800, Loss: 3.9067800045013428\n",
      "Iteration 1900, Loss: 3.894815683364868\n",
      "Iteration 2000, Loss: 3.8656013011932373\n",
      "Iteration 2100, Loss: 3.8571884632110596\n",
      "Iteration 2200, Loss: 3.8387298583984375\n",
      "Iteration 2300, Loss: 3.825568675994873\n",
      "Iteration 2400, Loss: 3.811466932296753\n",
      "Iteration 2500, Loss: 3.794482946395874\n",
      "Iteration 2600, Loss: 3.7760848999023438\n",
      "Iteration 2700, Loss: 3.7754576206207275\n",
      "Iteration 2800, Loss: 3.7452712059020996\n",
      "Iteration 2900, Loss: 3.7550082206726074\n",
      "Iteration 0, Loss: 4.603512763977051\n",
      "Iteration 100, Loss: 4.413995742797852\n",
      "Iteration 200, Loss: 4.430352687835693\n",
      "Iteration 300, Loss: 4.332071781158447\n",
      "Iteration 400, Loss: 4.309823036193848\n",
      "Iteration 500, Loss: 4.31776762008667\n",
      "Iteration 600, Loss: 4.235934257507324\n",
      "Iteration 700, Loss: 4.201299667358398\n",
      "Iteration 800, Loss: 4.1841020584106445\n",
      "Iteration 900, Loss: 4.136419296264648\n",
      "Iteration 1000, Loss: 4.087642669677734\n",
      "Iteration 1100, Loss: 4.0599541664123535\n",
      "Iteration 1200, Loss: 4.0112504959106445\n",
      "Iteration 1300, Loss: 4.0283613204956055\n",
      "Iteration 1400, Loss: 3.953033924102783\n",
      "Iteration 1500, Loss: 3.931421995162964\n",
      "Iteration 1600, Loss: 3.8973662853240967\n",
      "Iteration 1700, Loss: 3.9012386798858643\n",
      "Iteration 1800, Loss: 3.863511085510254\n",
      "Iteration 1900, Loss: 3.827177047729492\n",
      "Iteration 2000, Loss: 3.810880661010742\n",
      "Iteration 2100, Loss: 3.807882070541382\n",
      "Iteration 2200, Loss: 3.7920045852661133\n",
      "Iteration 2300, Loss: 3.7684569358825684\n",
      "Iteration 2400, Loss: 3.746492624282837\n",
      "Iteration 2500, Loss: 3.7256455421447754\n",
      "Iteration 2600, Loss: 3.7428996562957764\n",
      "Iteration 2700, Loss: 3.707061290740967\n",
      "Iteration 2800, Loss: 3.700058698654175\n",
      "Iteration 2900, Loss: 3.6787590980529785\n",
      "Iteration 0, Loss: 4.686853408813477\n",
      "Iteration 100, Loss: 4.463292121887207\n",
      "Iteration 200, Loss: 4.375736713409424\n",
      "Iteration 300, Loss: 4.368869304656982\n",
      "Iteration 400, Loss: 4.296257019042969\n",
      "Iteration 500, Loss: 4.239858150482178\n",
      "Iteration 600, Loss: 4.175887107849121\n",
      "Iteration 700, Loss: 4.143969535827637\n",
      "Iteration 800, Loss: 4.1323113441467285\n",
      "Iteration 900, Loss: 4.084613800048828\n",
      "Iteration 1000, Loss: 4.058934211730957\n",
      "Iteration 1100, Loss: 4.0227813720703125\n",
      "Iteration 1200, Loss: 4.0016937255859375\n",
      "Iteration 1300, Loss: 4.000596046447754\n",
      "Iteration 1400, Loss: 3.955239772796631\n",
      "Iteration 1500, Loss: 3.934664726257324\n",
      "Iteration 1600, Loss: 3.918945789337158\n",
      "Iteration 1700, Loss: 3.9036195278167725\n",
      "Iteration 1800, Loss: 3.8868134021759033\n",
      "Iteration 1900, Loss: 3.860121488571167\n",
      "Iteration 2000, Loss: 3.8409512042999268\n",
      "Iteration 2100, Loss: 3.82401704788208\n",
      "Iteration 2200, Loss: 3.812708616256714\n",
      "Iteration 2300, Loss: 3.7956838607788086\n",
      "Iteration 2400, Loss: 3.781135082244873\n",
      "Iteration 2500, Loss: 3.7730071544647217\n",
      "Iteration 2600, Loss: 3.7564785480499268\n",
      "Iteration 2700, Loss: 3.7436182498931885\n",
      "Iteration 2800, Loss: 3.7387897968292236\n",
      "Iteration 2900, Loss: 3.7258098125457764\n",
      "Iteration 0, Loss: 4.669931888580322\n",
      "Iteration 100, Loss: 4.43149471282959\n",
      "Iteration 200, Loss: 4.366060733795166\n",
      "Iteration 300, Loss: 4.317442417144775\n",
      "Iteration 400, Loss: 4.271674633026123\n",
      "Iteration 500, Loss: 4.230574607849121\n",
      "Iteration 600, Loss: 4.183184623718262\n",
      "Iteration 700, Loss: 4.142214298248291\n",
      "Iteration 800, Loss: 4.125932693481445\n",
      "Iteration 900, Loss: 4.091560363769531\n",
      "Iteration 1000, Loss: 4.077352523803711\n",
      "Iteration 1100, Loss: 4.032629013061523\n",
      "Iteration 1200, Loss: 4.080583572387695\n",
      "Iteration 1300, Loss: 4.009937286376953\n",
      "Iteration 1400, Loss: 3.9791197776794434\n",
      "Iteration 1500, Loss: 3.9545938968658447\n",
      "Iteration 1600, Loss: 3.9388201236724854\n",
      "Iteration 1700, Loss: 3.9019556045532227\n",
      "Iteration 1800, Loss: 3.9004247188568115\n",
      "Iteration 1900, Loss: 3.8762056827545166\n",
      "Iteration 2000, Loss: 3.8820645809173584\n",
      "Iteration 2100, Loss: 3.8365511894226074\n",
      "Iteration 2200, Loss: 3.83500075340271\n",
      "Iteration 2300, Loss: 3.8169825077056885\n",
      "Iteration 2400, Loss: 3.8043506145477295\n",
      "Iteration 2500, Loss: 3.792609453201294\n",
      "Iteration 2600, Loss: 3.786590814590454\n",
      "Iteration 2700, Loss: 3.781040668487549\n",
      "Iteration 2800, Loss: 3.7489113807678223\n",
      "Iteration 2900, Loss: 3.749396562576294\n",
      "Iteration 0, Loss: 4.704282283782959\n",
      "Iteration 100, Loss: 4.523211479187012\n",
      "Iteration 200, Loss: 4.4757866859436035\n",
      "Iteration 300, Loss: 4.4098405838012695\n",
      "Iteration 400, Loss: 4.361085891723633\n",
      "Iteration 500, Loss: 4.323422431945801\n",
      "Iteration 600, Loss: 4.246175765991211\n",
      "Iteration 700, Loss: 4.224941730499268\n",
      "Iteration 800, Loss: 4.210391521453857\n",
      "Iteration 900, Loss: 4.149634838104248\n",
      "Iteration 1000, Loss: 4.183468818664551\n",
      "Iteration 1100, Loss: 4.096785068511963\n",
      "Iteration 1200, Loss: 4.082234859466553\n",
      "Iteration 1300, Loss: 4.050731658935547\n",
      "Iteration 1400, Loss: 4.023287773132324\n",
      "Iteration 1500, Loss: 3.9985687732696533\n",
      "Iteration 1600, Loss: 4.0031280517578125\n",
      "Iteration 1700, Loss: 3.9779741764068604\n",
      "Iteration 1800, Loss: 3.9455859661102295\n",
      "Iteration 1900, Loss: 3.92502498626709\n",
      "Iteration 2000, Loss: 3.9269113540649414\n",
      "Iteration 2100, Loss: 3.882734775543213\n",
      "Iteration 2200, Loss: 3.8891549110412598\n",
      "Iteration 2300, Loss: 3.857696294784546\n",
      "Iteration 2400, Loss: 3.8550055027008057\n",
      "Iteration 2500, Loss: 3.8241848945617676\n",
      "Iteration 2600, Loss: 3.827096462249756\n",
      "Iteration 2700, Loss: 3.8195488452911377\n",
      "Iteration 2800, Loss: 3.8020095825195312\n",
      "Iteration 2900, Loss: 3.7896595001220703\n",
      "Iteration 0, Loss: 4.594069957733154\n",
      "Iteration 100, Loss: 4.44382905960083\n",
      "Iteration 200, Loss: 4.407528877258301\n",
      "Iteration 300, Loss: 4.322818279266357\n",
      "Iteration 400, Loss: 4.39592170715332\n",
      "Iteration 500, Loss: 4.349710464477539\n",
      "Iteration 600, Loss: 4.31347131729126\n",
      "Iteration 700, Loss: 4.280097961425781\n",
      "Iteration 800, Loss: 4.306903839111328\n",
      "Iteration 900, Loss: 4.2583513259887695\n",
      "Iteration 1000, Loss: 4.220923900604248\n",
      "Iteration 1100, Loss: 4.189227104187012\n",
      "Iteration 1200, Loss: 4.17093563079834\n",
      "Iteration 1300, Loss: 4.159426212310791\n",
      "Iteration 1400, Loss: 4.130105495452881\n",
      "Iteration 1500, Loss: 4.116610527038574\n",
      "Iteration 1600, Loss: 4.076217174530029\n",
      "Iteration 1700, Loss: 4.089412689208984\n",
      "Iteration 1800, Loss: 4.035752773284912\n",
      "Iteration 1900, Loss: 4.038877010345459\n",
      "Iteration 2000, Loss: 4.011995315551758\n",
      "Iteration 2100, Loss: 3.988997459411621\n",
      "Iteration 2200, Loss: 3.9545845985412598\n",
      "Iteration 2300, Loss: 3.936763048171997\n",
      "Iteration 2400, Loss: 3.9217143058776855\n",
      "Iteration 2500, Loss: 3.9251902103424072\n",
      "Iteration 2600, Loss: 3.8912618160247803\n",
      "Iteration 2700, Loss: 3.869389772415161\n",
      "Iteration 2800, Loss: 3.855541706085205\n",
      "Iteration 2900, Loss: 3.8401224613189697\n",
      "Iteration 0, Loss: 4.624836444854736\n",
      "Iteration 100, Loss: 4.418625354766846\n",
      "Iteration 200, Loss: 4.358739376068115\n",
      "Iteration 300, Loss: 4.3175129890441895\n",
      "Iteration 400, Loss: 4.228209972381592\n",
      "Iteration 500, Loss: 4.182368755340576\n",
      "Iteration 600, Loss: 4.126359939575195\n",
      "Iteration 700, Loss: 4.095171928405762\n",
      "Iteration 800, Loss: 4.05665922164917\n",
      "Iteration 900, Loss: 4.0314555168151855\n",
      "Iteration 1000, Loss: 4.013667106628418\n",
      "Iteration 1100, Loss: 3.9744956493377686\n",
      "Iteration 1200, Loss: 3.945481777191162\n",
      "Iteration 1300, Loss: 3.949673652648926\n",
      "Iteration 1400, Loss: 3.905742883682251\n",
      "Iteration 1500, Loss: 3.8775811195373535\n",
      "Iteration 1600, Loss: 3.8616573810577393\n",
      "Iteration 1700, Loss: 3.8347525596618652\n",
      "Iteration 1800, Loss: 3.81866717338562\n",
      "Iteration 1900, Loss: 3.81101131439209\n",
      "Iteration 2000, Loss: 3.7954444885253906\n",
      "Iteration 2100, Loss: 3.7701497077941895\n",
      "Iteration 2200, Loss: 3.7583272457122803\n",
      "Iteration 2300, Loss: 3.745619297027588\n",
      "Iteration 2400, Loss: 3.7336745262145996\n",
      "Iteration 2500, Loss: 3.7321345806121826\n",
      "Iteration 2600, Loss: 3.702951669692993\n",
      "Iteration 2700, Loss: 3.7113921642303467\n",
      "Iteration 2800, Loss: 3.693408250808716\n",
      "Iteration 2900, Loss: 3.674121141433716\n",
      "Iteration 0, Loss: 4.734565258026123\n",
      "Iteration 100, Loss: 4.534395694732666\n",
      "Iteration 200, Loss: 4.4541850090026855\n",
      "Iteration 300, Loss: 4.398787021636963\n",
      "Iteration 400, Loss: 4.395054340362549\n",
      "Iteration 500, Loss: 4.289379119873047\n",
      "Iteration 600, Loss: 4.237848281860352\n",
      "Iteration 700, Loss: 4.2016191482543945\n",
      "Iteration 800, Loss: 4.176240921020508\n",
      "Iteration 900, Loss: 4.124151706695557\n",
      "Iteration 1000, Loss: 4.088901042938232\n",
      "Iteration 1100, Loss: 4.074753761291504\n",
      "Iteration 1200, Loss: 4.04431676864624\n",
      "Iteration 1300, Loss: 4.010285377502441\n",
      "Iteration 1400, Loss: 3.985812187194824\n",
      "Iteration 1500, Loss: 3.9620823860168457\n",
      "Iteration 1600, Loss: 3.943173885345459\n",
      "Iteration 1700, Loss: 3.928884267807007\n",
      "Iteration 1800, Loss: 3.911282539367676\n",
      "Iteration 1900, Loss: 3.8997483253479004\n",
      "Iteration 2000, Loss: 3.8678536415100098\n",
      "Iteration 2100, Loss: 3.8689754009246826\n",
      "Iteration 2200, Loss: 3.8424413204193115\n",
      "Iteration 2300, Loss: 3.82700777053833\n",
      "Iteration 2400, Loss: 3.8130056858062744\n",
      "Iteration 2500, Loss: 3.8048245906829834\n",
      "Iteration 2600, Loss: 3.790376901626587\n",
      "Iteration 2700, Loss: 3.779503345489502\n",
      "Iteration 2800, Loss: 3.7773454189300537\n",
      "Iteration 2900, Loss: 3.7705888748168945\n",
      "Iteration 0, Loss: 4.594520568847656\n",
      "Iteration 100, Loss: 4.47166633605957\n",
      "Iteration 200, Loss: 4.424476146697998\n",
      "Iteration 300, Loss: 4.337654113769531\n",
      "Iteration 400, Loss: 4.261804103851318\n",
      "Iteration 500, Loss: 4.194397449493408\n",
      "Iteration 600, Loss: 4.18589973449707\n",
      "Iteration 700, Loss: 4.109823226928711\n",
      "Iteration 800, Loss: 4.069671154022217\n",
      "Iteration 900, Loss: 4.0333356857299805\n",
      "Iteration 1000, Loss: 3.989114761352539\n",
      "Iteration 1100, Loss: 3.9821598529815674\n",
      "Iteration 1200, Loss: 3.9409427642822266\n",
      "Iteration 1300, Loss: 3.916193723678589\n",
      "Iteration 1400, Loss: 3.8788046836853027\n",
      "Iteration 1500, Loss: 3.859999418258667\n",
      "Iteration 1600, Loss: 3.8323545455932617\n",
      "Iteration 1700, Loss: 3.8141958713531494\n",
      "Iteration 1800, Loss: 3.7930514812469482\n",
      "Iteration 1900, Loss: 3.7850303649902344\n",
      "Iteration 2000, Loss: 3.754944086074829\n",
      "Iteration 2100, Loss: 3.738020658493042\n",
      "Iteration 2200, Loss: 3.7236521244049072\n",
      "Iteration 2300, Loss: 3.703895092010498\n",
      "Iteration 2400, Loss: 3.68558406829834\n",
      "Iteration 2500, Loss: 3.6726789474487305\n",
      "Iteration 2600, Loss: 3.6637933254241943\n",
      "Iteration 2700, Loss: 3.648334264755249\n",
      "Iteration 2800, Loss: 3.6469264030456543\n",
      "Iteration 2900, Loss: 3.6213345527648926\n",
      "Iteration 0, Loss: 4.633070945739746\n",
      "Iteration 100, Loss: 4.481552600860596\n",
      "Iteration 200, Loss: 4.32857084274292\n",
      "Iteration 300, Loss: 4.3152852058410645\n",
      "Iteration 400, Loss: 4.232568740844727\n",
      "Iteration 500, Loss: 4.203181266784668\n",
      "Iteration 600, Loss: 4.126584529876709\n",
      "Iteration 700, Loss: 4.0810770988464355\n",
      "Iteration 800, Loss: 4.0579094886779785\n",
      "Iteration 900, Loss: 4.036017417907715\n",
      "Iteration 1000, Loss: 3.9841485023498535\n",
      "Iteration 1100, Loss: 3.969606637954712\n",
      "Iteration 1200, Loss: 3.9644582271575928\n",
      "Iteration 1300, Loss: 3.913125991821289\n",
      "Iteration 1400, Loss: 3.8970298767089844\n",
      "Iteration 1500, Loss: 3.8779096603393555\n",
      "Iteration 1600, Loss: 3.8531148433685303\n",
      "Iteration 1700, Loss: 3.8344478607177734\n",
      "Iteration 1800, Loss: 3.8163745403289795\n",
      "Iteration 1900, Loss: 3.7962112426757812\n",
      "Iteration 2000, Loss: 3.7851922512054443\n",
      "Iteration 2100, Loss: 3.764320135116577\n",
      "Iteration 2200, Loss: 3.760587453842163\n",
      "Iteration 2300, Loss: 3.740612506866455\n",
      "Iteration 2400, Loss: 3.722078323364258\n",
      "Iteration 2500, Loss: 3.717190980911255\n",
      "Iteration 2600, Loss: 3.697483777999878\n",
      "Iteration 2700, Loss: 3.6816322803497314\n",
      "Iteration 2800, Loss: 3.6811070442199707\n",
      "Iteration 2900, Loss: 3.6663568019866943\n",
      "Iteration 0, Loss: 4.667344570159912\n",
      "Iteration 100, Loss: 4.484816074371338\n",
      "Iteration 200, Loss: 4.462433815002441\n",
      "Iteration 300, Loss: 4.47266960144043\n",
      "Iteration 400, Loss: 4.634390354156494\n",
      "Iteration 500, Loss: 4.406076908111572\n",
      "Iteration 600, Loss: 4.426730155944824\n",
      "Iteration 700, Loss: 4.402475357055664\n",
      "Iteration 800, Loss: 4.364087104797363\n",
      "Iteration 900, Loss: 4.310831546783447\n",
      "Iteration 1000, Loss: 4.257295608520508\n",
      "Iteration 1100, Loss: 4.228023052215576\n",
      "Iteration 1200, Loss: 4.205639362335205\n",
      "Iteration 1300, Loss: 4.140112400054932\n",
      "Iteration 1400, Loss: 4.1603193283081055\n",
      "Iteration 1500, Loss: 4.15588903427124\n",
      "Iteration 1600, Loss: 4.082322120666504\n",
      "Iteration 1700, Loss: 4.073136806488037\n",
      "Iteration 1800, Loss: 4.0481133460998535\n",
      "Iteration 1900, Loss: 3.9955227375030518\n",
      "Iteration 2000, Loss: 4.006831645965576\n",
      "Iteration 2100, Loss: 3.9472951889038086\n",
      "Iteration 2200, Loss: 3.9391262531280518\n",
      "Iteration 2300, Loss: 3.9323744773864746\n",
      "Iteration 2400, Loss: 3.900693416595459\n",
      "Iteration 2500, Loss: 3.888303756713867\n",
      "Iteration 2600, Loss: 3.8765463829040527\n",
      "Iteration 2700, Loss: 3.862673044204712\n",
      "Iteration 2800, Loss: 3.8456413745880127\n",
      "Iteration 2900, Loss: 3.837864875793457\n",
      "Iteration 0, Loss: 4.678108215332031\n",
      "Iteration 100, Loss: 4.551700115203857\n",
      "Iteration 200, Loss: 4.521113395690918\n",
      "Iteration 300, Loss: 4.478752613067627\n",
      "Iteration 400, Loss: 4.522912502288818\n",
      "Iteration 500, Loss: 4.466070175170898\n",
      "Iteration 600, Loss: 4.417880535125732\n",
      "Iteration 700, Loss: 4.396642684936523\n",
      "Iteration 800, Loss: 4.370286464691162\n",
      "Iteration 900, Loss: 4.299264907836914\n",
      "Iteration 1000, Loss: 4.2659831047058105\n",
      "Iteration 1100, Loss: 4.238768100738525\n",
      "Iteration 1200, Loss: 4.21378231048584\n",
      "Iteration 1300, Loss: 4.15897274017334\n",
      "Iteration 1400, Loss: 4.1362080574035645\n",
      "Iteration 1500, Loss: 4.122838020324707\n",
      "Iteration 1600, Loss: 4.081307411193848\n",
      "Iteration 1700, Loss: 4.073631286621094\n",
      "Iteration 1800, Loss: 4.040279388427734\n",
      "Iteration 1900, Loss: 4.005363941192627\n",
      "Iteration 2000, Loss: 3.9850096702575684\n",
      "Iteration 2100, Loss: 3.9908764362335205\n",
      "Iteration 2200, Loss: 3.9355244636535645\n",
      "Iteration 2300, Loss: 3.9306464195251465\n",
      "Iteration 2400, Loss: 3.902656078338623\n",
      "Iteration 2500, Loss: 3.8862082958221436\n",
      "Iteration 2600, Loss: 3.884671926498413\n",
      "Iteration 2700, Loss: 3.855987548828125\n",
      "Iteration 2800, Loss: 3.850618362426758\n",
      "Iteration 2900, Loss: 3.8225820064544678\n",
      "Iteration 0, Loss: 4.702111721038818\n",
      "Iteration 100, Loss: 4.544483661651611\n",
      "Iteration 200, Loss: 4.47463321685791\n",
      "Iteration 300, Loss: 4.459081649780273\n",
      "Iteration 400, Loss: 4.395084381103516\n",
      "Iteration 500, Loss: 4.333324432373047\n",
      "Iteration 600, Loss: 4.29039192199707\n",
      "Iteration 700, Loss: 4.2373576164245605\n",
      "Iteration 800, Loss: 4.207263946533203\n",
      "Iteration 900, Loss: 4.158928394317627\n",
      "Iteration 1000, Loss: 4.149324893951416\n",
      "Iteration 1100, Loss: 4.115724086761475\n",
      "Iteration 1200, Loss: 4.087838172912598\n",
      "Iteration 1300, Loss: 4.049209117889404\n",
      "Iteration 1400, Loss: 4.032715797424316\n",
      "Iteration 1500, Loss: 4.00902795791626\n",
      "Iteration 1600, Loss: 3.9947988986968994\n",
      "Iteration 1700, Loss: 3.9734890460968018\n",
      "Iteration 1800, Loss: 3.9421651363372803\n",
      "Iteration 1900, Loss: 3.935391426086426\n",
      "Iteration 2000, Loss: 3.9217441082000732\n",
      "Iteration 2100, Loss: 3.900967836380005\n",
      "Iteration 2200, Loss: 3.882580518722534\n",
      "Iteration 2300, Loss: 3.8690412044525146\n",
      "Iteration 2400, Loss: 3.860031843185425\n",
      "Iteration 2500, Loss: 3.8442680835723877\n",
      "Iteration 2600, Loss: 3.838531255722046\n",
      "Iteration 2700, Loss: 3.8219621181488037\n",
      "Iteration 2800, Loss: 3.8010895252227783\n",
      "Iteration 2900, Loss: 3.7914984226226807\n",
      "Iteration 0, Loss: 4.635446071624756\n",
      "Iteration 100, Loss: 4.468589782714844\n",
      "Iteration 200, Loss: 4.442112445831299\n",
      "Iteration 300, Loss: 4.391992568969727\n",
      "Iteration 400, Loss: 4.355863094329834\n",
      "Iteration 500, Loss: 4.382299423217773\n",
      "Iteration 600, Loss: 4.278065204620361\n",
      "Iteration 700, Loss: 4.227222442626953\n",
      "Iteration 800, Loss: 4.193249702453613\n",
      "Iteration 900, Loss: 4.133918285369873\n",
      "Iteration 1000, Loss: 4.095321178436279\n",
      "Iteration 1100, Loss: 4.06992244720459\n",
      "Iteration 1200, Loss: 4.036905288696289\n",
      "Iteration 1300, Loss: 4.022577285766602\n",
      "Iteration 1400, Loss: 3.983933925628662\n",
      "Iteration 1500, Loss: 3.9552559852600098\n",
      "Iteration 1600, Loss: 3.9381330013275146\n",
      "Iteration 1700, Loss: 3.9228861331939697\n",
      "Iteration 1800, Loss: 3.893481492996216\n",
      "Iteration 1900, Loss: 3.869239330291748\n",
      "Iteration 2000, Loss: 3.8509840965270996\n",
      "Iteration 2100, Loss: 3.8385403156280518\n",
      "Iteration 2200, Loss: 3.815760612487793\n",
      "Iteration 2300, Loss: 3.785579204559326\n",
      "Iteration 2400, Loss: 3.7803587913513184\n",
      "Iteration 2500, Loss: 3.7726964950561523\n",
      "Iteration 2600, Loss: 3.7537312507629395\n",
      "Iteration 2700, Loss: 3.7553226947784424\n",
      "Iteration 2800, Loss: 3.73984432220459\n",
      "Iteration 2900, Loss: 3.7099502086639404\n",
      "Iteration 0, Loss: 4.617917060852051\n",
      "Iteration 100, Loss: 4.473569393157959\n",
      "Iteration 200, Loss: 4.410272121429443\n",
      "Iteration 300, Loss: 4.3452301025390625\n",
      "Iteration 400, Loss: 4.39528226852417\n",
      "Iteration 500, Loss: 4.431027889251709\n",
      "Iteration 600, Loss: 4.317767143249512\n",
      "Iteration 700, Loss: 4.277937889099121\n",
      "Iteration 800, Loss: 4.229603290557861\n",
      "Iteration 900, Loss: 4.207343578338623\n",
      "Iteration 1000, Loss: 4.179620742797852\n",
      "Iteration 1100, Loss: 4.136166572570801\n",
      "Iteration 1200, Loss: 4.101322650909424\n",
      "Iteration 1300, Loss: 4.098721504211426\n",
      "Iteration 1400, Loss: 4.045397758483887\n",
      "Iteration 1500, Loss: 4.0765838623046875\n",
      "Iteration 1600, Loss: 4.0066304206848145\n",
      "Iteration 1700, Loss: 3.9815776348114014\n",
      "Iteration 1800, Loss: 3.9647655487060547\n",
      "Iteration 1900, Loss: 3.9484310150146484\n",
      "Iteration 2000, Loss: 3.938950777053833\n",
      "Iteration 2100, Loss: 3.913058042526245\n",
      "Iteration 2200, Loss: 3.9079370498657227\n",
      "Iteration 2300, Loss: 3.880333423614502\n",
      "Iteration 2400, Loss: 3.8724684715270996\n",
      "Iteration 2500, Loss: 3.8470194339752197\n",
      "Iteration 2600, Loss: 3.842322587966919\n",
      "Iteration 2700, Loss: 3.807072639465332\n",
      "Iteration 2800, Loss: 3.805572748184204\n",
      "Iteration 2900, Loss: 3.787961959838867\n",
      "Iteration 0, Loss: 4.662410259246826\n",
      "Iteration 100, Loss: 4.495189189910889\n",
      "Iteration 200, Loss: 4.387424468994141\n",
      "Iteration 300, Loss: 4.369227886199951\n",
      "Iteration 400, Loss: 4.329776287078857\n",
      "Iteration 500, Loss: 4.295792102813721\n",
      "Iteration 600, Loss: 4.231022834777832\n",
      "Iteration 700, Loss: 4.176828384399414\n",
      "Iteration 800, Loss: 4.156894683837891\n",
      "Iteration 900, Loss: 4.1211652755737305\n",
      "Iteration 1000, Loss: 4.080256462097168\n",
      "Iteration 1100, Loss: 4.086657524108887\n",
      "Iteration 1200, Loss: 4.036294937133789\n",
      "Iteration 1300, Loss: 4.007532119750977\n",
      "Iteration 1400, Loss: 3.9811220169067383\n",
      "Iteration 1500, Loss: 3.962355375289917\n",
      "Iteration 1600, Loss: 3.925912857055664\n",
      "Iteration 1700, Loss: 3.9116811752319336\n",
      "Iteration 1800, Loss: 3.9014883041381836\n",
      "Iteration 1900, Loss: 3.872993230819702\n",
      "Iteration 2000, Loss: 3.8601560592651367\n",
      "Iteration 2100, Loss: 3.8489413261413574\n",
      "Iteration 2200, Loss: 3.830348014831543\n",
      "Iteration 2300, Loss: 3.814180850982666\n",
      "Iteration 2400, Loss: 3.80263614654541\n",
      "Iteration 2500, Loss: 3.778841257095337\n",
      "Iteration 2600, Loss: 3.750049591064453\n",
      "Iteration 2700, Loss: 3.7459309101104736\n",
      "Iteration 2800, Loss: 3.725831985473633\n",
      "Iteration 2900, Loss: 3.714218854904175\n",
      "Iteration 0, Loss: 4.630344390869141\n",
      "Iteration 100, Loss: 4.449244022369385\n",
      "Iteration 200, Loss: 4.484368801116943\n",
      "Iteration 300, Loss: 4.3383331298828125\n",
      "Iteration 400, Loss: 4.272961616516113\n",
      "Iteration 500, Loss: 4.243566036224365\n",
      "Iteration 600, Loss: 4.235202312469482\n",
      "Iteration 700, Loss: 4.144895553588867\n",
      "Iteration 800, Loss: 4.116934776306152\n",
      "Iteration 900, Loss: 4.0894904136657715\n",
      "Iteration 1000, Loss: 4.057653903961182\n",
      "Iteration 1100, Loss: 4.037858486175537\n",
      "Iteration 1200, Loss: 4.010847568511963\n",
      "Iteration 1300, Loss: 3.9824719429016113\n",
      "Iteration 1400, Loss: 3.9511423110961914\n",
      "Iteration 1500, Loss: 3.9437453746795654\n",
      "Iteration 1600, Loss: 3.907741069793701\n",
      "Iteration 1700, Loss: 3.8952949047088623\n",
      "Iteration 1800, Loss: 3.880727767944336\n",
      "Iteration 1900, Loss: 3.8579838275909424\n",
      "Iteration 2000, Loss: 3.856635332107544\n",
      "Iteration 2100, Loss: 3.8241188526153564\n",
      "Iteration 2200, Loss: 3.821167469024658\n",
      "Iteration 2300, Loss: 3.7985403537750244\n",
      "Iteration 2400, Loss: 3.774942398071289\n",
      "Iteration 2500, Loss: 3.766812562942505\n",
      "Iteration 2600, Loss: 3.748790740966797\n",
      "Iteration 2700, Loss: 3.7412614822387695\n",
      "Iteration 2800, Loss: 3.731351852416992\n",
      "Iteration 2900, Loss: 3.7320234775543213\n",
      "Iteration 0, Loss: 4.607143402099609\n",
      "Iteration 100, Loss: 4.403162956237793\n",
      "Iteration 200, Loss: 4.344465255737305\n",
      "Iteration 300, Loss: 4.276107311248779\n",
      "Iteration 400, Loss: 4.260429382324219\n",
      "Iteration 500, Loss: 4.200058937072754\n",
      "Iteration 600, Loss: 4.186070919036865\n",
      "Iteration 700, Loss: 4.13897705078125\n",
      "Iteration 800, Loss: 4.094761848449707\n",
      "Iteration 900, Loss: 4.065169811248779\n",
      "Iteration 1000, Loss: 4.022477149963379\n",
      "Iteration 1100, Loss: 3.9989993572235107\n",
      "Iteration 1200, Loss: 3.975785970687866\n",
      "Iteration 1300, Loss: 3.9404919147491455\n",
      "Iteration 1400, Loss: 3.9320216178894043\n",
      "Iteration 1500, Loss: 3.877795457839966\n",
      "Iteration 1600, Loss: 3.890031576156616\n",
      "Iteration 1700, Loss: 3.8486456871032715\n",
      "Iteration 1800, Loss: 3.823363780975342\n",
      "Iteration 1900, Loss: 3.8274588584899902\n",
      "Iteration 2000, Loss: 3.8092215061187744\n",
      "Iteration 2100, Loss: 3.7935738563537598\n",
      "Iteration 2200, Loss: 3.752347230911255\n",
      "Iteration 2300, Loss: 3.742504835128784\n",
      "Iteration 2400, Loss: 3.722484827041626\n",
      "Iteration 2500, Loss: 3.7172257900238037\n",
      "Iteration 2600, Loss: 3.7033016681671143\n",
      "Iteration 2700, Loss: 3.702280282974243\n",
      "Iteration 2800, Loss: 3.6714248657226562\n",
      "Iteration 2900, Loss: 3.666748046875\n",
      "Iteration 0, Loss: 4.621157646179199\n",
      "Iteration 100, Loss: 4.452845096588135\n",
      "Iteration 200, Loss: 4.424104690551758\n",
      "Iteration 300, Loss: 4.312626838684082\n",
      "Iteration 400, Loss: 4.239404201507568\n",
      "Iteration 500, Loss: 4.192381381988525\n",
      "Iteration 600, Loss: 4.178529262542725\n",
      "Iteration 700, Loss: 4.147812843322754\n",
      "Iteration 800, Loss: 4.08447265625\n",
      "Iteration 900, Loss: 4.055238246917725\n",
      "Iteration 1000, Loss: 4.016296863555908\n",
      "Iteration 1100, Loss: 3.9986233711242676\n",
      "Iteration 1200, Loss: 3.9663479328155518\n",
      "Iteration 1300, Loss: 3.930663824081421\n",
      "Iteration 1400, Loss: 3.92073917388916\n",
      "Iteration 1500, Loss: 3.890519142150879\n",
      "Iteration 1600, Loss: 3.871384382247925\n",
      "Iteration 1700, Loss: 3.853931427001953\n",
      "Iteration 1800, Loss: 3.8473308086395264\n",
      "Iteration 1900, Loss: 3.810098171234131\n",
      "Iteration 2000, Loss: 3.8175768852233887\n",
      "Iteration 2100, Loss: 3.7902705669403076\n",
      "Iteration 2200, Loss: 3.7834908962249756\n",
      "Iteration 2300, Loss: 3.758174180984497\n",
      "Iteration 2400, Loss: 3.7385003566741943\n",
      "Iteration 2500, Loss: 3.7328524589538574\n",
      "Iteration 2600, Loss: 3.7298331260681152\n",
      "Iteration 2700, Loss: 3.730947494506836\n",
      "Iteration 2800, Loss: 3.6969900131225586\n",
      "Iteration 2900, Loss: 3.6799960136413574\n",
      "Iteration 0, Loss: 4.647496700286865\n",
      "Iteration 100, Loss: 4.485986709594727\n",
      "Iteration 200, Loss: 4.505785942077637\n",
      "Iteration 300, Loss: 4.409984588623047\n",
      "Iteration 400, Loss: 4.4113006591796875\n",
      "Iteration 500, Loss: 4.369832515716553\n",
      "Iteration 600, Loss: 4.2619171142578125\n",
      "Iteration 700, Loss: 4.280395030975342\n",
      "Iteration 800, Loss: 4.27120304107666\n",
      "Iteration 900, Loss: 4.184391498565674\n",
      "Iteration 1000, Loss: 4.130135536193848\n",
      "Iteration 1100, Loss: 4.115616321563721\n",
      "Iteration 1200, Loss: 4.0746283531188965\n",
      "Iteration 1300, Loss: 4.044262886047363\n",
      "Iteration 1400, Loss: 4.039876937866211\n",
      "Iteration 1500, Loss: 4.031131744384766\n",
      "Iteration 1600, Loss: 3.9877583980560303\n",
      "Iteration 1700, Loss: 3.9679107666015625\n",
      "Iteration 1800, Loss: 3.9418606758117676\n",
      "Iteration 1900, Loss: 3.958092212677002\n",
      "Iteration 2000, Loss: 3.9320037364959717\n",
      "Iteration 2100, Loss: 3.8962032794952393\n",
      "Iteration 2200, Loss: 3.884641647338867\n",
      "Iteration 2300, Loss: 3.8607678413391113\n",
      "Iteration 2400, Loss: 3.844803810119629\n",
      "Iteration 2500, Loss: 3.838369131088257\n",
      "Iteration 2600, Loss: 3.8336069583892822\n",
      "Iteration 2700, Loss: 3.8232688903808594\n",
      "Iteration 2800, Loss: 3.7910399436950684\n",
      "Iteration 2900, Loss: 3.77837872505188\n",
      "Iteration 0, Loss: 4.601789951324463\n",
      "Iteration 100, Loss: 4.447464942932129\n",
      "Iteration 200, Loss: 4.411207675933838\n",
      "Iteration 300, Loss: 4.381187438964844\n",
      "Iteration 400, Loss: 4.317736625671387\n",
      "Iteration 500, Loss: 4.292402267456055\n",
      "Iteration 600, Loss: 4.224974155426025\n",
      "Iteration 700, Loss: 4.215612411499023\n",
      "Iteration 800, Loss: 4.1440887451171875\n",
      "Iteration 900, Loss: 4.141420841217041\n",
      "Iteration 1000, Loss: 4.047317028045654\n",
      "Iteration 1100, Loss: 4.016608715057373\n",
      "Iteration 1200, Loss: 3.9763572216033936\n",
      "Iteration 1300, Loss: 3.963433265686035\n",
      "Iteration 1400, Loss: 3.9462876319885254\n",
      "Iteration 1500, Loss: 3.9091484546661377\n",
      "Iteration 1600, Loss: 3.895857810974121\n",
      "Iteration 1700, Loss: 3.8638806343078613\n",
      "Iteration 1800, Loss: 3.8357601165771484\n",
      "Iteration 1900, Loss: 3.8168082237243652\n",
      "Iteration 2000, Loss: 3.7998578548431396\n",
      "Iteration 2100, Loss: 3.787299156188965\n",
      "Iteration 2200, Loss: 3.762004852294922\n",
      "Iteration 2300, Loss: 3.752121686935425\n",
      "Iteration 2400, Loss: 3.7385413646698\n",
      "Iteration 2500, Loss: 3.724057674407959\n",
      "Iteration 2600, Loss: 3.7050623893737793\n",
      "Iteration 2700, Loss: 3.689807653427124\n",
      "Iteration 2800, Loss: 3.6686127185821533\n",
      "Iteration 2900, Loss: 3.6592047214508057\n",
      "Iteration 0, Loss: 4.648765563964844\n",
      "Iteration 100, Loss: 4.4354987144470215\n",
      "Iteration 200, Loss: 4.467199325561523\n",
      "Iteration 300, Loss: 4.403075695037842\n",
      "Iteration 400, Loss: 4.325230121612549\n",
      "Iteration 500, Loss: 4.294790744781494\n",
      "Iteration 600, Loss: 4.233004570007324\n",
      "Iteration 700, Loss: 4.194313049316406\n",
      "Iteration 800, Loss: 4.161043643951416\n",
      "Iteration 900, Loss: 4.1437506675720215\n",
      "Iteration 1000, Loss: 4.092837810516357\n",
      "Iteration 1100, Loss: 4.12520170211792\n",
      "Iteration 1200, Loss: 4.060314655303955\n",
      "Iteration 1300, Loss: 4.040307521820068\n",
      "Iteration 1400, Loss: 4.017430782318115\n",
      "Iteration 1500, Loss: 3.9945998191833496\n",
      "Iteration 1600, Loss: 3.966071844100952\n",
      "Iteration 1700, Loss: 3.948733329772949\n",
      "Iteration 1800, Loss: 3.9213690757751465\n",
      "Iteration 1900, Loss: 3.902214288711548\n",
      "Iteration 2000, Loss: 3.8856701850891113\n",
      "Iteration 2100, Loss: 3.863330602645874\n",
      "Iteration 2200, Loss: 3.8638219833374023\n",
      "Iteration 2300, Loss: 3.828202486038208\n",
      "Iteration 2400, Loss: 3.8212363719940186\n",
      "Iteration 2500, Loss: 3.805748701095581\n",
      "Iteration 2600, Loss: 3.7853362560272217\n",
      "Iteration 2700, Loss: 3.773313045501709\n",
      "Iteration 2800, Loss: 3.7599987983703613\n",
      "Iteration 2900, Loss: 3.7440106868743896\n",
      "Iteration 0, Loss: 4.5798540115356445\n",
      "Iteration 100, Loss: 4.382842063903809\n",
      "Iteration 200, Loss: 4.299442291259766\n",
      "Iteration 300, Loss: 4.218156337738037\n",
      "Iteration 400, Loss: 4.164393424987793\n",
      "Iteration 500, Loss: 4.167778968811035\n",
      "Iteration 600, Loss: 4.10172700881958\n",
      "Iteration 700, Loss: 4.070616245269775\n",
      "Iteration 800, Loss: 4.0022382736206055\n",
      "Iteration 900, Loss: 3.9678611755371094\n",
      "Iteration 1000, Loss: 3.9115512371063232\n",
      "Iteration 1100, Loss: 3.8808698654174805\n",
      "Iteration 1200, Loss: 3.852935314178467\n",
      "Iteration 1300, Loss: 3.842181921005249\n",
      "Iteration 1400, Loss: 3.815778970718384\n",
      "Iteration 1500, Loss: 3.770040988922119\n",
      "Iteration 1600, Loss: 3.7486813068389893\n",
      "Iteration 1700, Loss: 3.732097625732422\n",
      "Iteration 1800, Loss: 3.730553388595581\n",
      "Iteration 1900, Loss: 3.6981124877929688\n",
      "Iteration 2000, Loss: 3.682558059692383\n",
      "Iteration 2100, Loss: 3.6718456745147705\n",
      "Iteration 2200, Loss: 3.6553659439086914\n",
      "Iteration 2300, Loss: 3.6415579319000244\n",
      "Iteration 2400, Loss: 3.6136412620544434\n",
      "Iteration 2500, Loss: 3.598257064819336\n",
      "Iteration 2600, Loss: 3.5858314037323\n",
      "Iteration 2700, Loss: 3.573441505432129\n",
      "Iteration 2800, Loss: 3.560464859008789\n",
      "Iteration 2900, Loss: 3.553351402282715\n",
      "Iteration 0, Loss: 4.628669738769531\n",
      "Iteration 100, Loss: 4.423008441925049\n",
      "Iteration 200, Loss: 4.360128402709961\n",
      "Iteration 300, Loss: 4.302192211151123\n",
      "Iteration 400, Loss: 4.253720283508301\n",
      "Iteration 500, Loss: 4.187180519104004\n",
      "Iteration 600, Loss: 4.144697189331055\n",
      "Iteration 700, Loss: 4.170984268188477\n",
      "Iteration 800, Loss: 4.08461332321167\n",
      "Iteration 900, Loss: 4.04855489730835\n",
      "Iteration 1000, Loss: 4.009954929351807\n",
      "Iteration 1100, Loss: 3.9813148975372314\n",
      "Iteration 1200, Loss: 3.9634737968444824\n",
      "Iteration 1300, Loss: 3.923464775085449\n",
      "Iteration 1400, Loss: 3.9024975299835205\n",
      "Iteration 1500, Loss: 3.890089511871338\n",
      "Iteration 1600, Loss: 3.8564517498016357\n",
      "Iteration 1700, Loss: 3.835581064224243\n",
      "Iteration 1800, Loss: 3.822528123855591\n",
      "Iteration 1900, Loss: 3.794698715209961\n",
      "Iteration 2000, Loss: 3.7757925987243652\n",
      "Iteration 2100, Loss: 3.7674407958984375\n",
      "Iteration 2200, Loss: 3.7587497234344482\n",
      "Iteration 2300, Loss: 3.7313661575317383\n",
      "Iteration 2400, Loss: 3.722788095474243\n",
      "Iteration 2500, Loss: 3.7119102478027344\n",
      "Iteration 2600, Loss: 3.6948626041412354\n",
      "Iteration 2700, Loss: 3.696746587753296\n",
      "Iteration 2800, Loss: 3.676577568054199\n",
      "Iteration 2900, Loss: 3.6546871662139893\n",
      "Iteration 0, Loss: 4.65047550201416\n",
      "Iteration 100, Loss: 4.519835948944092\n",
      "Iteration 200, Loss: 4.439731121063232\n",
      "Iteration 300, Loss: 4.431849479675293\n",
      "Iteration 400, Loss: 4.317386627197266\n",
      "Iteration 500, Loss: 4.259369850158691\n",
      "Iteration 600, Loss: 4.2330002784729\n",
      "Iteration 700, Loss: 4.1595778465271\n",
      "Iteration 800, Loss: 4.128105640411377\n",
      "Iteration 900, Loss: 4.08829927444458\n",
      "Iteration 1000, Loss: 4.0573930740356445\n",
      "Iteration 1100, Loss: 4.013913154602051\n",
      "Iteration 1200, Loss: 3.9828338623046875\n",
      "Iteration 1300, Loss: 3.974055767059326\n",
      "Iteration 1400, Loss: 3.9307801723480225\n",
      "Iteration 1500, Loss: 3.911172389984131\n",
      "Iteration 1600, Loss: 3.8970370292663574\n",
      "Iteration 1700, Loss: 3.8792262077331543\n",
      "Iteration 1800, Loss: 3.8386905193328857\n",
      "Iteration 1900, Loss: 3.8249433040618896\n",
      "Iteration 2000, Loss: 3.8242239952087402\n",
      "Iteration 2100, Loss: 3.7948215007781982\n",
      "Iteration 2200, Loss: 3.7784371376037598\n",
      "Iteration 2300, Loss: 3.769853353500366\n",
      "Iteration 2400, Loss: 3.753241539001465\n",
      "Iteration 2500, Loss: 3.738323450088501\n",
      "Iteration 2600, Loss: 3.7312963008880615\n",
      "Iteration 2700, Loss: 3.7161855697631836\n",
      "Iteration 2800, Loss: 3.6962950229644775\n",
      "Iteration 2900, Loss: 3.6861233711242676\n",
      "Iteration 0, Loss: 4.649229526519775\n",
      "Iteration 100, Loss: 4.42191219329834\n",
      "Iteration 200, Loss: 4.494840621948242\n",
      "Iteration 300, Loss: 4.370965480804443\n",
      "Iteration 400, Loss: 4.336573123931885\n",
      "Iteration 500, Loss: 4.303234100341797\n",
      "Iteration 600, Loss: 4.223001003265381\n",
      "Iteration 700, Loss: 4.205353260040283\n",
      "Iteration 800, Loss: 4.194986343383789\n",
      "Iteration 900, Loss: 4.137157917022705\n",
      "Iteration 1000, Loss: 4.093783855438232\n",
      "Iteration 1100, Loss: 4.083005905151367\n",
      "Iteration 1200, Loss: 4.065067291259766\n",
      "Iteration 1300, Loss: 4.024740695953369\n",
      "Iteration 1400, Loss: 4.007613658905029\n",
      "Iteration 1500, Loss: 3.969496488571167\n",
      "Iteration 1600, Loss: 3.9581663608551025\n",
      "Iteration 1700, Loss: 3.9356472492218018\n",
      "Iteration 1800, Loss: 3.9294044971466064\n",
      "Iteration 1900, Loss: 3.9202094078063965\n",
      "Iteration 2000, Loss: 3.890063762664795\n",
      "Iteration 2100, Loss: 3.9010543823242188\n",
      "Iteration 2200, Loss: 3.8506217002868652\n",
      "Iteration 2300, Loss: 3.835761547088623\n",
      "Iteration 2400, Loss: 3.82501220703125\n",
      "Iteration 2500, Loss: 3.812145471572876\n",
      "Iteration 2600, Loss: 3.803496837615967\n",
      "Iteration 2700, Loss: 3.7769694328308105\n",
      "Iteration 2800, Loss: 3.766479969024658\n",
      "Iteration 2900, Loss: 3.770045757293701\n",
      "Iteration 0, Loss: 4.68684196472168\n",
      "Iteration 100, Loss: 4.478902339935303\n",
      "Iteration 200, Loss: 4.506224155426025\n",
      "Iteration 300, Loss: 4.381533622741699\n",
      "Iteration 400, Loss: 4.331462383270264\n",
      "Iteration 500, Loss: 4.273118019104004\n",
      "Iteration 600, Loss: 4.26547908782959\n",
      "Iteration 700, Loss: 4.182984828948975\n",
      "Iteration 800, Loss: 4.154595851898193\n",
      "Iteration 900, Loss: 4.131007671356201\n",
      "Iteration 1000, Loss: 4.082194805145264\n",
      "Iteration 1100, Loss: 4.046619892120361\n",
      "Iteration 1200, Loss: 4.011337757110596\n",
      "Iteration 1300, Loss: 3.9866461753845215\n",
      "Iteration 1400, Loss: 3.962217330932617\n",
      "Iteration 1500, Loss: 3.9329240322113037\n",
      "Iteration 1600, Loss: 3.9212844371795654\n",
      "Iteration 1700, Loss: 3.8984534740448\n",
      "Iteration 1800, Loss: 3.8696699142456055\n",
      "Iteration 1900, Loss: 3.8494205474853516\n",
      "Iteration 2000, Loss: 3.832685947418213\n",
      "Iteration 2100, Loss: 3.806013345718384\n",
      "Iteration 2200, Loss: 3.8011515140533447\n",
      "Iteration 2300, Loss: 3.779658079147339\n",
      "Iteration 2400, Loss: 3.7671563625335693\n",
      "Iteration 2500, Loss: 3.765756130218506\n",
      "Iteration 2600, Loss: 3.7380974292755127\n",
      "Iteration 2700, Loss: 3.726872444152832\n",
      "Iteration 2800, Loss: 3.7137696743011475\n",
      "Iteration 2900, Loss: 3.7039756774902344\n",
      "Iteration 0, Loss: 4.689238548278809\n",
      "Iteration 100, Loss: 4.447955131530762\n",
      "Iteration 200, Loss: 4.375913619995117\n",
      "Iteration 300, Loss: 4.291037082672119\n",
      "Iteration 400, Loss: 4.246973037719727\n",
      "Iteration 500, Loss: 4.229583263397217\n",
      "Iteration 600, Loss: 4.184236526489258\n",
      "Iteration 700, Loss: 4.135814666748047\n",
      "Iteration 800, Loss: 4.093319892883301\n",
      "Iteration 900, Loss: 4.059324264526367\n",
      "Iteration 1000, Loss: 4.040731430053711\n",
      "Iteration 1100, Loss: 4.010201930999756\n",
      "Iteration 1200, Loss: 3.9946722984313965\n",
      "Iteration 1300, Loss: 3.976682662963867\n",
      "Iteration 1400, Loss: 3.943814277648926\n",
      "Iteration 1500, Loss: 3.9528462886810303\n",
      "Iteration 1600, Loss: 3.91194224357605\n",
      "Iteration 1700, Loss: 3.8913397789001465\n",
      "Iteration 1800, Loss: 3.882601261138916\n",
      "Iteration 1900, Loss: 3.8531606197357178\n",
      "Iteration 2000, Loss: 3.8426601886749268\n",
      "Iteration 2100, Loss: 3.8453962802886963\n",
      "Iteration 2200, Loss: 3.8262126445770264\n",
      "Iteration 2300, Loss: 3.8085360527038574\n",
      "Iteration 2400, Loss: 3.7889339923858643\n",
      "Iteration 2500, Loss: 3.777679920196533\n",
      "Iteration 2600, Loss: 3.7711265087127686\n",
      "Iteration 2700, Loss: 3.7519450187683105\n",
      "Iteration 2800, Loss: 3.7424261569976807\n",
      "Iteration 2900, Loss: 3.73170804977417\n",
      "Iteration 0, Loss: 4.638052463531494\n",
      "Iteration 100, Loss: 4.457742691040039\n",
      "Iteration 200, Loss: 4.393813133239746\n",
      "Iteration 300, Loss: 4.36820125579834\n",
      "Iteration 400, Loss: 4.283753871917725\n",
      "Iteration 500, Loss: 4.2355875968933105\n",
      "Iteration 600, Loss: 4.213975429534912\n",
      "Iteration 700, Loss: 4.156571865081787\n",
      "Iteration 800, Loss: 4.122708320617676\n",
      "Iteration 900, Loss: 4.1015238761901855\n",
      "Iteration 1000, Loss: 4.0579962730407715\n",
      "Iteration 1100, Loss: 4.017167568206787\n",
      "Iteration 1200, Loss: 3.998145818710327\n",
      "Iteration 1300, Loss: 3.9633548259735107\n",
      "Iteration 1400, Loss: 3.941272020339966\n",
      "Iteration 1500, Loss: 3.926157236099243\n",
      "Iteration 1600, Loss: 3.9000511169433594\n",
      "Iteration 1700, Loss: 3.8822290897369385\n",
      "Iteration 1800, Loss: 3.8539984226226807\n",
      "Iteration 1900, Loss: 3.833268165588379\n",
      "Iteration 2000, Loss: 3.8235905170440674\n",
      "Iteration 2100, Loss: 3.8027002811431885\n",
      "Iteration 2200, Loss: 3.7888965606689453\n",
      "Iteration 2300, Loss: 3.7775914669036865\n",
      "Iteration 2400, Loss: 3.763996124267578\n",
      "Iteration 2500, Loss: 3.745453119277954\n",
      "Iteration 2600, Loss: 3.7297439575195312\n",
      "Iteration 2700, Loss: 3.732292652130127\n",
      "Iteration 2800, Loss: 3.6983137130737305\n",
      "Iteration 2900, Loss: 3.7042500972747803\n",
      "Iteration 0, Loss: 4.643857955932617\n",
      "Iteration 100, Loss: 4.49144983291626\n",
      "Iteration 200, Loss: 4.47723388671875\n",
      "Iteration 300, Loss: 4.439131259918213\n",
      "Iteration 400, Loss: 4.427219867706299\n",
      "Iteration 500, Loss: 4.5178914070129395\n",
      "Iteration 600, Loss: 4.4722676277160645\n",
      "Iteration 700, Loss: 4.447750091552734\n",
      "Iteration 800, Loss: 4.430322170257568\n",
      "Iteration 900, Loss: 4.413630962371826\n",
      "Iteration 1000, Loss: 4.396955490112305\n",
      "Iteration 1100, Loss: 4.3808817863464355\n",
      "Iteration 1200, Loss: 4.3656005859375\n",
      "Iteration 1300, Loss: 4.3509016036987305\n",
      "Iteration 1400, Loss: 4.336522102355957\n",
      "Iteration 1500, Loss: 4.322218894958496\n",
      "Iteration 1600, Loss: 4.30789852142334\n",
      "Iteration 1700, Loss: 4.293612957000732\n",
      "Iteration 1800, Loss: 4.280392169952393\n",
      "Iteration 1900, Loss: 4.267384052276611\n",
      "Iteration 2000, Loss: 4.261688232421875\n",
      "Iteration 2100, Loss: 4.249056816101074\n",
      "Iteration 2200, Loss: 4.229754447937012\n",
      "Iteration 2300, Loss: 4.267037391662598\n",
      "Iteration 2400, Loss: 4.2197418212890625\n",
      "Iteration 2500, Loss: 4.209120750427246\n",
      "Iteration 2600, Loss: 4.193571090698242\n",
      "Iteration 2700, Loss: 4.170678615570068\n",
      "Iteration 2800, Loss: 4.1720051765441895\n",
      "Iteration 2900, Loss: 4.153886318206787\n",
      "Iteration 0, Loss: 4.665974140167236\n",
      "Iteration 100, Loss: 4.477223873138428\n",
      "Iteration 200, Loss: 4.446076393127441\n",
      "Iteration 300, Loss: 4.437106132507324\n",
      "Iteration 400, Loss: 4.434724807739258\n",
      "Iteration 500, Loss: 4.38353157043457\n",
      "Iteration 600, Loss: 4.313593864440918\n",
      "Iteration 700, Loss: 4.246316909790039\n",
      "Iteration 800, Loss: 4.203800678253174\n",
      "Iteration 900, Loss: 4.1847052574157715\n",
      "Iteration 1000, Loss: 4.137694835662842\n",
      "Iteration 1100, Loss: 4.11694860458374\n",
      "Iteration 1200, Loss: 4.079604625701904\n",
      "Iteration 1300, Loss: 4.055549621582031\n",
      "Iteration 1400, Loss: 4.02138614654541\n",
      "Iteration 1500, Loss: 3.9934580326080322\n",
      "Iteration 1600, Loss: 3.9752957820892334\n",
      "Iteration 1700, Loss: 3.9487082958221436\n",
      "Iteration 1800, Loss: 3.946988582611084\n",
      "Iteration 1900, Loss: 3.9118599891662598\n",
      "Iteration 2000, Loss: 3.9025955200195312\n",
      "Iteration 2100, Loss: 3.892782211303711\n",
      "Iteration 2200, Loss: 3.852304220199585\n",
      "Iteration 2300, Loss: 3.8374485969543457\n",
      "Iteration 2400, Loss: 3.8279805183410645\n",
      "Iteration 2500, Loss: 3.816161632537842\n",
      "Iteration 2600, Loss: 3.8226988315582275\n",
      "Iteration 2700, Loss: 3.7930855751037598\n",
      "Iteration 2800, Loss: 3.785675525665283\n",
      "Iteration 2900, Loss: 3.8000125885009766\n",
      "Iteration 0, Loss: 4.664000988006592\n",
      "Iteration 100, Loss: 4.469565391540527\n",
      "Iteration 200, Loss: 4.485313415527344\n",
      "Iteration 300, Loss: 4.429059028625488\n",
      "Iteration 400, Loss: 4.402062892913818\n",
      "Iteration 500, Loss: 4.385293483734131\n",
      "Iteration 600, Loss: 4.371429443359375\n",
      "Iteration 700, Loss: 4.358713150024414\n",
      "Iteration 800, Loss: 4.346311569213867\n",
      "Iteration 900, Loss: 4.333758354187012\n",
      "Iteration 1000, Loss: 4.320870876312256\n",
      "Iteration 1100, Loss: 4.307618618011475\n",
      "Iteration 1200, Loss: 4.2939910888671875\n",
      "Iteration 1300, Loss: 4.280231952667236\n",
      "Iteration 1400, Loss: 4.2668914794921875\n",
      "Iteration 1500, Loss: 4.252895832061768\n",
      "Iteration 1600, Loss: 4.267934322357178\n",
      "Iteration 1700, Loss: 4.227513313293457\n",
      "Iteration 1800, Loss: 4.215193271636963\n",
      "Iteration 1900, Loss: 4.206127643585205\n",
      "Iteration 2000, Loss: 4.21196174621582\n",
      "Iteration 2100, Loss: 4.177725791931152\n",
      "Iteration 2200, Loss: 4.169682502746582\n",
      "Iteration 2300, Loss: 4.157365798950195\n",
      "Iteration 2400, Loss: 4.15046501159668\n",
      "Iteration 2500, Loss: 4.217320919036865\n",
      "Iteration 2600, Loss: 4.133122444152832\n",
      "Iteration 2700, Loss: 4.143449783325195\n",
      "Iteration 2800, Loss: 4.1000165939331055\n",
      "Iteration 2900, Loss: 4.1043243408203125\n",
      "Iteration 0, Loss: 4.685610771179199\n",
      "Iteration 100, Loss: 4.540792942047119\n",
      "Iteration 200, Loss: 4.493334770202637\n",
      "Iteration 300, Loss: 4.426148414611816\n",
      "Iteration 400, Loss: 4.409976482391357\n",
      "Iteration 500, Loss: 4.337894916534424\n",
      "Iteration 600, Loss: 4.306811809539795\n",
      "Iteration 700, Loss: 4.235693454742432\n",
      "Iteration 800, Loss: 4.214061737060547\n",
      "Iteration 900, Loss: 4.177053928375244\n",
      "Iteration 1000, Loss: 4.145064353942871\n",
      "Iteration 1100, Loss: 4.105296611785889\n",
      "Iteration 1200, Loss: 4.1009202003479\n",
      "Iteration 1300, Loss: 4.063328266143799\n",
      "Iteration 1400, Loss: 4.040457248687744\n",
      "Iteration 1500, Loss: 4.007585048675537\n",
      "Iteration 1600, Loss: 3.976316213607788\n",
      "Iteration 1700, Loss: 3.9681684970855713\n",
      "Iteration 1800, Loss: 3.948767900466919\n",
      "Iteration 1900, Loss: 3.929882287979126\n",
      "Iteration 2000, Loss: 3.9159367084503174\n",
      "Iteration 2100, Loss: 3.908053398132324\n",
      "Iteration 2200, Loss: 3.8721532821655273\n",
      "Iteration 2300, Loss: 3.8886611461639404\n",
      "Iteration 2400, Loss: 3.841611862182617\n",
      "Iteration 2500, Loss: 3.8311667442321777\n",
      "Iteration 2600, Loss: 3.828705072402954\n",
      "Iteration 2700, Loss: 3.8215911388397217\n",
      "Iteration 2800, Loss: 3.7874972820281982\n",
      "Iteration 2900, Loss: 3.777742624282837\n",
      "Iteration 0, Loss: 4.619411468505859\n",
      "Iteration 100, Loss: 4.434617519378662\n",
      "Iteration 200, Loss: 4.412631988525391\n",
      "Iteration 300, Loss: 4.326489448547363\n",
      "Iteration 400, Loss: 4.262992858886719\n",
      "Iteration 500, Loss: 4.2180938720703125\n",
      "Iteration 600, Loss: 4.171075344085693\n",
      "Iteration 700, Loss: 4.109729290008545\n",
      "Iteration 800, Loss: 4.110232830047607\n",
      "Iteration 900, Loss: 4.043410301208496\n",
      "Iteration 1000, Loss: 4.0142621994018555\n",
      "Iteration 1100, Loss: 3.9951581954956055\n",
      "Iteration 1200, Loss: 3.9523000717163086\n",
      "Iteration 1300, Loss: 3.933962821960449\n",
      "Iteration 1400, Loss: 3.9069101810455322\n",
      "Iteration 1500, Loss: 3.8972132205963135\n",
      "Iteration 1600, Loss: 3.868626356124878\n",
      "Iteration 1700, Loss: 3.8530399799346924\n",
      "Iteration 1800, Loss: 3.8323001861572266\n",
      "Iteration 1900, Loss: 3.8147284984588623\n",
      "Iteration 2000, Loss: 3.791445255279541\n",
      "Iteration 2100, Loss: 3.7810566425323486\n",
      "Iteration 2200, Loss: 3.754990816116333\n",
      "Iteration 2300, Loss: 3.753742218017578\n",
      "Iteration 2400, Loss: 3.727130174636841\n",
      "Iteration 2500, Loss: 3.714082717895508\n",
      "Iteration 2600, Loss: 3.70104718208313\n",
      "Iteration 2700, Loss: 3.690614700317383\n",
      "Iteration 2800, Loss: 3.6856467723846436\n",
      "Iteration 2900, Loss: 3.6689929962158203\n",
      "Iteration 0, Loss: 4.680213451385498\n",
      "Iteration 100, Loss: 4.517926216125488\n",
      "Iteration 200, Loss: 4.484493255615234\n",
      "Iteration 300, Loss: 4.392463207244873\n",
      "Iteration 400, Loss: 4.3435235023498535\n",
      "Iteration 500, Loss: 4.283283710479736\n",
      "Iteration 600, Loss: 4.261054992675781\n",
      "Iteration 700, Loss: 4.223938465118408\n",
      "Iteration 800, Loss: 4.175285339355469\n",
      "Iteration 900, Loss: 4.138970375061035\n",
      "Iteration 1000, Loss: 4.121545314788818\n",
      "Iteration 1100, Loss: 4.077200889587402\n",
      "Iteration 1200, Loss: 4.04749870300293\n",
      "Iteration 1300, Loss: 4.0263142585754395\n",
      "Iteration 1400, Loss: 4.015562057495117\n",
      "Iteration 1500, Loss: 3.983227252960205\n",
      "Iteration 1600, Loss: 3.966047763824463\n",
      "Iteration 1700, Loss: 3.9453835487365723\n",
      "Iteration 1800, Loss: 3.930655002593994\n",
      "Iteration 1900, Loss: 3.905893087387085\n",
      "Iteration 2000, Loss: 3.8988611698150635\n",
      "Iteration 2100, Loss: 3.878380060195923\n",
      "Iteration 2200, Loss: 3.8590891361236572\n",
      "Iteration 2300, Loss: 3.8464293479919434\n",
      "Iteration 2400, Loss: 3.8252220153808594\n",
      "Iteration 2500, Loss: 3.8194010257720947\n",
      "Iteration 2600, Loss: 3.8020341396331787\n",
      "Iteration 2700, Loss: 3.7960236072540283\n",
      "Iteration 2800, Loss: 3.778108835220337\n",
      "Iteration 2900, Loss: 3.767300844192505\n",
      "Iteration 0, Loss: 4.702220439910889\n",
      "Iteration 100, Loss: 4.481367111206055\n",
      "Iteration 200, Loss: 4.450824737548828\n",
      "Iteration 300, Loss: 4.378472805023193\n",
      "Iteration 400, Loss: 4.332364559173584\n",
      "Iteration 500, Loss: 4.279627323150635\n",
      "Iteration 600, Loss: 4.220817565917969\n",
      "Iteration 700, Loss: 4.17341947555542\n",
      "Iteration 800, Loss: 4.145954132080078\n",
      "Iteration 900, Loss: 4.118535995483398\n",
      "Iteration 1000, Loss: 4.081969738006592\n",
      "Iteration 1100, Loss: 4.066817760467529\n",
      "Iteration 1200, Loss: 4.041972637176514\n",
      "Iteration 1300, Loss: 4.013883590698242\n",
      "Iteration 1400, Loss: 3.997271776199341\n",
      "Iteration 1500, Loss: 3.988104820251465\n",
      "Iteration 1600, Loss: 3.9562132358551025\n",
      "Iteration 1700, Loss: 3.9482226371765137\n",
      "Iteration 1800, Loss: 3.916699171066284\n",
      "Iteration 1900, Loss: 3.9042434692382812\n",
      "Iteration 2000, Loss: 3.888352870941162\n",
      "Iteration 2100, Loss: 3.8798911571502686\n",
      "Iteration 2200, Loss: 3.862614870071411\n",
      "Iteration 2300, Loss: 3.8532376289367676\n",
      "Iteration 2400, Loss: 3.8372185230255127\n",
      "Iteration 2500, Loss: 3.8228096961975098\n",
      "Iteration 2600, Loss: 3.81459379196167\n",
      "Iteration 2700, Loss: 3.8016724586486816\n",
      "Iteration 2800, Loss: 3.7904396057128906\n",
      "Iteration 2900, Loss: 3.7845637798309326\n",
      "Iteration 0, Loss: 4.607972621917725\n",
      "Iteration 100, Loss: 4.464655876159668\n",
      "Iteration 200, Loss: 4.399665832519531\n",
      "Iteration 300, Loss: 4.380550384521484\n",
      "Iteration 400, Loss: 4.368652820587158\n",
      "Iteration 500, Loss: 4.335608959197998\n",
      "Iteration 600, Loss: 4.2916178703308105\n",
      "Iteration 700, Loss: 4.267099380493164\n",
      "Iteration 800, Loss: 4.191884517669678\n",
      "Iteration 900, Loss: 4.128978252410889\n",
      "Iteration 1000, Loss: 4.086996555328369\n",
      "Iteration 1100, Loss: 4.082773685455322\n",
      "Iteration 1200, Loss: 4.040125846862793\n",
      "Iteration 1300, Loss: 4.01483154296875\n",
      "Iteration 1400, Loss: 3.990100383758545\n",
      "Iteration 1500, Loss: 3.9582180976867676\n",
      "Iteration 1600, Loss: 3.9301135540008545\n",
      "Iteration 1700, Loss: 3.8977222442626953\n",
      "Iteration 1800, Loss: 3.9228527545928955\n",
      "Iteration 1900, Loss: 3.865602731704712\n",
      "Iteration 2000, Loss: 3.8911314010620117\n",
      "Iteration 2100, Loss: 3.8359434604644775\n",
      "Iteration 2200, Loss: 3.8013181686401367\n",
      "Iteration 2300, Loss: 3.7839314937591553\n",
      "Iteration 2400, Loss: 3.7634005546569824\n",
      "Iteration 2500, Loss: 3.7565267086029053\n",
      "Iteration 2600, Loss: 3.734513759613037\n",
      "Iteration 2700, Loss: 3.7341365814208984\n",
      "Iteration 2800, Loss: 3.7167673110961914\n",
      "Iteration 2900, Loss: 3.6879706382751465\n",
      "Iteration 0, Loss: 4.710756301879883\n",
      "Iteration 100, Loss: 4.5521111488342285\n",
      "Iteration 200, Loss: 4.522553443908691\n",
      "Iteration 300, Loss: 4.536157131195068\n",
      "Iteration 400, Loss: 4.468783378601074\n",
      "Iteration 500, Loss: 4.411475658416748\n",
      "Iteration 600, Loss: 4.3772077560424805\n",
      "Iteration 700, Loss: 4.365536689758301\n",
      "Iteration 800, Loss: 4.365654468536377\n",
      "Iteration 900, Loss: 4.3028717041015625\n",
      "Iteration 1000, Loss: 4.255660533905029\n",
      "Iteration 1100, Loss: 4.2438645362854\n",
      "Iteration 1200, Loss: 4.201809406280518\n",
      "Iteration 1300, Loss: 4.194583892822266\n",
      "Iteration 1400, Loss: 4.144625663757324\n",
      "Iteration 1500, Loss: 4.119787693023682\n",
      "Iteration 1600, Loss: 4.12312126159668\n",
      "Iteration 1700, Loss: 4.086320400238037\n",
      "Iteration 1800, Loss: 4.068910598754883\n",
      "Iteration 1900, Loss: 4.034988880157471\n",
      "Iteration 2000, Loss: 4.026109218597412\n",
      "Iteration 2100, Loss: 3.9998939037323\n",
      "Iteration 2200, Loss: 3.992323160171509\n",
      "Iteration 2300, Loss: 3.96669602394104\n",
      "Iteration 2400, Loss: 3.949892044067383\n",
      "Iteration 2500, Loss: 3.935410737991333\n",
      "Iteration 2600, Loss: 3.9240782260894775\n",
      "Iteration 2700, Loss: 3.903002977371216\n",
      "Iteration 2800, Loss: 3.9013772010803223\n",
      "Iteration 2900, Loss: 3.8776628971099854\n",
      "Iteration 0, Loss: 4.696440696716309\n",
      "Iteration 100, Loss: 4.4879231452941895\n",
      "Iteration 200, Loss: 4.418246746063232\n",
      "Iteration 300, Loss: 4.3902716636657715\n",
      "Iteration 400, Loss: 4.289277076721191\n",
      "Iteration 500, Loss: 4.320582389831543\n",
      "Iteration 600, Loss: 4.291555881500244\n",
      "Iteration 700, Loss: 4.223391056060791\n",
      "Iteration 800, Loss: 4.17450475692749\n",
      "Iteration 900, Loss: 4.177404403686523\n",
      "Iteration 1000, Loss: 4.119627475738525\n",
      "Iteration 1100, Loss: 4.086410045623779\n",
      "Iteration 1200, Loss: 4.070072650909424\n",
      "Iteration 1300, Loss: 4.028740406036377\n",
      "Iteration 1400, Loss: 4.014129161834717\n",
      "Iteration 1500, Loss: 4.000056743621826\n",
      "Iteration 1600, Loss: 3.9939112663269043\n",
      "Iteration 1700, Loss: 3.953054428100586\n",
      "Iteration 1800, Loss: 3.9467966556549072\n",
      "Iteration 1900, Loss: 3.9157044887542725\n",
      "Iteration 2000, Loss: 3.906010150909424\n",
      "Iteration 2100, Loss: 3.8911867141723633\n",
      "Iteration 2200, Loss: 3.882678985595703\n",
      "Iteration 2300, Loss: 3.8778088092803955\n",
      "Iteration 2400, Loss: 3.8412556648254395\n",
      "Iteration 2500, Loss: 3.8254692554473877\n",
      "Iteration 2600, Loss: 3.811408519744873\n",
      "Iteration 2700, Loss: 3.80842661857605\n",
      "Iteration 2800, Loss: 3.8075168132781982\n",
      "Iteration 2900, Loss: 3.7693779468536377\n",
      "Iteration 0, Loss: 4.700205326080322\n",
      "Iteration 100, Loss: 4.47885799407959\n",
      "Iteration 200, Loss: 4.430882453918457\n",
      "Iteration 300, Loss: 4.373242378234863\n",
      "Iteration 400, Loss: 4.311290740966797\n",
      "Iteration 500, Loss: 4.260146617889404\n",
      "Iteration 600, Loss: 4.21310567855835\n",
      "Iteration 700, Loss: 4.178662300109863\n",
      "Iteration 800, Loss: 4.151925563812256\n",
      "Iteration 900, Loss: 4.130541801452637\n",
      "Iteration 1000, Loss: 4.1159515380859375\n",
      "Iteration 1100, Loss: 4.0994181632995605\n",
      "Iteration 1200, Loss: 4.0409111976623535\n",
      "Iteration 1300, Loss: 4.017134189605713\n",
      "Iteration 1400, Loss: 4.009633541107178\n",
      "Iteration 1500, Loss: 3.98640775680542\n",
      "Iteration 1600, Loss: 3.951467514038086\n",
      "Iteration 1700, Loss: 3.942819833755493\n",
      "Iteration 1800, Loss: 3.9358012676239014\n",
      "Iteration 1900, Loss: 3.9233689308166504\n",
      "Iteration 2000, Loss: 3.891463279724121\n",
      "Iteration 2100, Loss: 3.8858654499053955\n",
      "Iteration 2200, Loss: 3.870192289352417\n",
      "Iteration 2300, Loss: 3.8521339893341064\n",
      "Iteration 2400, Loss: 3.8514881134033203\n",
      "Iteration 2500, Loss: 3.8177032470703125\n",
      "Iteration 2600, Loss: 3.819276809692383\n",
      "Iteration 2700, Loss: 3.7990987300872803\n",
      "Iteration 2800, Loss: 3.785429000854492\n",
      "Iteration 2900, Loss: 3.773422956466675\n",
      "Iteration 0, Loss: 4.705493450164795\n",
      "Iteration 100, Loss: 4.5547075271606445\n",
      "Iteration 200, Loss: 4.528797626495361\n",
      "Iteration 300, Loss: 4.4780683517456055\n",
      "Iteration 400, Loss: 4.446743488311768\n",
      "Iteration 500, Loss: 4.393758773803711\n",
      "Iteration 600, Loss: 4.3621110916137695\n",
      "Iteration 700, Loss: 4.319769382476807\n",
      "Iteration 800, Loss: 4.281523704528809\n",
      "Iteration 900, Loss: 4.241572380065918\n",
      "Iteration 1000, Loss: 4.202592372894287\n",
      "Iteration 1100, Loss: 4.163292407989502\n",
      "Iteration 1200, Loss: 4.127320289611816\n",
      "Iteration 1300, Loss: 4.10258150100708\n",
      "Iteration 1400, Loss: 4.074760913848877\n",
      "Iteration 1500, Loss: 4.05601167678833\n",
      "Iteration 1600, Loss: 4.020751953125\n",
      "Iteration 1700, Loss: 4.008633613586426\n",
      "Iteration 1800, Loss: 4.050318241119385\n",
      "Iteration 1900, Loss: 3.982241153717041\n",
      "Iteration 2000, Loss: 3.9657793045043945\n",
      "Iteration 2100, Loss: 3.9320497512817383\n",
      "Iteration 2200, Loss: 3.9133594036102295\n",
      "Iteration 2300, Loss: 3.89483380317688\n",
      "Iteration 2400, Loss: 3.889788866043091\n",
      "Iteration 2500, Loss: 3.865220785140991\n",
      "Iteration 2600, Loss: 3.8433918952941895\n",
      "Iteration 2700, Loss: 3.845118999481201\n",
      "Iteration 2800, Loss: 3.8379318714141846\n",
      "Iteration 2900, Loss: 3.831235885620117\n",
      "Iteration 0, Loss: 4.673794269561768\n",
      "Iteration 100, Loss: 4.531965732574463\n",
      "Iteration 200, Loss: 4.443742275238037\n",
      "Iteration 300, Loss: 4.37385368347168\n",
      "Iteration 400, Loss: 4.335558891296387\n",
      "Iteration 500, Loss: 4.245181560516357\n",
      "Iteration 600, Loss: 4.202897071838379\n",
      "Iteration 700, Loss: 4.160679340362549\n",
      "Iteration 800, Loss: 4.1157612800598145\n",
      "Iteration 900, Loss: 4.109020709991455\n",
      "Iteration 1000, Loss: 4.061546802520752\n",
      "Iteration 1100, Loss: 4.0331130027771\n",
      "Iteration 1200, Loss: 4.009209156036377\n",
      "Iteration 1300, Loss: 3.9921324253082275\n",
      "Iteration 1400, Loss: 4.002410888671875\n",
      "Iteration 1500, Loss: 3.934875726699829\n",
      "Iteration 1600, Loss: 3.9080638885498047\n",
      "Iteration 1700, Loss: 3.8964738845825195\n",
      "Iteration 1800, Loss: 3.8634321689605713\n",
      "Iteration 1900, Loss: 3.847874641418457\n",
      "Iteration 2000, Loss: 3.856071949005127\n",
      "Iteration 2100, Loss: 3.820732831954956\n",
      "Iteration 2200, Loss: 3.795316457748413\n",
      "Iteration 2300, Loss: 3.7896153926849365\n",
      "Iteration 2400, Loss: 3.762810707092285\n",
      "Iteration 2500, Loss: 3.7563135623931885\n",
      "Iteration 2600, Loss: 3.7315170764923096\n",
      "Iteration 2700, Loss: 3.723346710205078\n",
      "Iteration 2800, Loss: 3.7222461700439453\n",
      "Iteration 2900, Loss: 3.695293426513672\n",
      "Iteration 0, Loss: 4.730917453765869\n",
      "Iteration 100, Loss: 4.501320838928223\n",
      "Iteration 200, Loss: 4.457132816314697\n",
      "Iteration 300, Loss: 4.418453693389893\n",
      "Iteration 400, Loss: 4.348479270935059\n",
      "Iteration 500, Loss: 4.278131484985352\n",
      "Iteration 600, Loss: 4.271592617034912\n",
      "Iteration 700, Loss: 4.220670700073242\n",
      "Iteration 800, Loss: 4.179027557373047\n",
      "Iteration 900, Loss: 4.14385461807251\n",
      "Iteration 1000, Loss: 4.149641990661621\n",
      "Iteration 1100, Loss: 4.102086067199707\n",
      "Iteration 1200, Loss: 4.077627182006836\n",
      "Iteration 1300, Loss: 4.057766914367676\n",
      "Iteration 1400, Loss: 4.053277492523193\n",
      "Iteration 1500, Loss: 4.0276689529418945\n",
      "Iteration 1600, Loss: 4.002335071563721\n",
      "Iteration 1700, Loss: 3.982891798019409\n",
      "Iteration 1800, Loss: 3.973515510559082\n",
      "Iteration 1900, Loss: 3.9419639110565186\n",
      "Iteration 2000, Loss: 3.9414095878601074\n",
      "Iteration 2100, Loss: 3.91401743888855\n",
      "Iteration 2200, Loss: 3.904836893081665\n",
      "Iteration 2300, Loss: 3.8976430892944336\n",
      "Iteration 2400, Loss: 3.874444007873535\n",
      "Iteration 2500, Loss: 3.868536949157715\n",
      "Iteration 2600, Loss: 3.8476648330688477\n",
      "Iteration 2700, Loss: 3.8358120918273926\n",
      "Iteration 2800, Loss: 3.8336281776428223\n",
      "Iteration 2900, Loss: 3.7996785640716553\n",
      "Iteration 0, Loss: 4.683190822601318\n",
      "Iteration 100, Loss: 4.544771671295166\n",
      "Iteration 200, Loss: 4.457700729370117\n",
      "Iteration 300, Loss: 4.464420318603516\n",
      "Iteration 400, Loss: 4.40753173828125\n",
      "Iteration 500, Loss: 4.373678207397461\n",
      "Iteration 600, Loss: 4.359921932220459\n",
      "Iteration 700, Loss: 4.357565402984619\n",
      "Iteration 800, Loss: 4.33449649810791\n",
      "Iteration 900, Loss: 4.2618207931518555\n",
      "Iteration 1000, Loss: 4.264573097229004\n",
      "Iteration 1100, Loss: 4.20004415512085\n",
      "Iteration 1200, Loss: 4.198631763458252\n",
      "Iteration 1300, Loss: 4.120206356048584\n",
      "Iteration 1400, Loss: 4.087418079376221\n",
      "Iteration 1500, Loss: 4.0657196044921875\n",
      "Iteration 1600, Loss: 4.0288801193237305\n",
      "Iteration 1700, Loss: 4.040181636810303\n",
      "Iteration 1800, Loss: 3.9843075275421143\n",
      "Iteration 1900, Loss: 3.97707200050354\n",
      "Iteration 2000, Loss: 3.973681926727295\n",
      "Iteration 2100, Loss: 3.9294912815093994\n",
      "Iteration 2200, Loss: 3.908818483352661\n",
      "Iteration 2300, Loss: 3.8934245109558105\n",
      "Iteration 2400, Loss: 3.8870620727539062\n",
      "Iteration 2500, Loss: 3.8803887367248535\n",
      "Iteration 2600, Loss: 3.86216139793396\n",
      "Iteration 2700, Loss: 3.8466250896453857\n",
      "Iteration 2800, Loss: 3.8331284523010254\n",
      "Iteration 2900, Loss: 3.800957441329956\n"
     ]
    }
   ],
   "source": [
    "DataFold='/Users/user/PycharmProjects/PacManMain/data/DMDmat/UPDATED/AllComponents/'\n",
    "\n",
    "C_on_perm=np.empty([197,197,50])\n",
    "loss_on_perm=np.zeros((50))\n",
    "angpermscore=np.zeros((50))\n",
    "for perm in range(50):\n",
    "    Xall=loadmat(DataFold+'/X_Amatrix_fullAllComps_PMD.mat')['XA']\n",
    "    Yall=loadmat(DataFold+'/Y_Amatrix_fullAllComps_PMD.mat')['YA']\n",
    "\n",
    "    X=torch.from_numpy(np.float32(Xall))\n",
    "    n = X.size(0)\n",
    "\n",
    "    #apply rotation using random skew symmetric orthogonal transform\n",
    "    Aa=np.random.randn(n,n)\n",
    "    Yall=cayley_numpy(Aa-Aa.T)*Yall * scipy.linalg.inv(cayley_numpy(Aa-Aa.T))\n",
    "\n",
    "    Y=torch.from_numpy(np.float32(Yall))\n",
    "\n",
    "    # Initialize a skew-symmetric matrix A\n",
    "\n",
    "    A = torch.randn((n, n), requires_grad=True)\n",
    "    A.data = A.data - A.data.T  # Making A skew-symmetric but preserving leaf status\n",
    "    # Use ADAM optimizer\n",
    "    optimizer = Adam([A], lr=learning_rate)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure C is orthogonal via Cayley transform of skew-symmetric A\n",
    "        C = cayley_transform(A)\n",
    "        loss = loss_function(X, Y, C)\n",
    "\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update A using gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(f'Iteration {iteration}, Loss: {loss.item()}')\n",
    "\n",
    "    # Final optimized C\n",
    "    C_perm = cayley_transform(A)\n",
    "    C_perm=C_perm.detach().numpy()\n",
    "    C_on_perm[:,:,perm]=C_perm\n",
    "    losstmp = loss.detach().numpy()\n",
    "    loss_on_perm[perm]=losstmp\n",
    "    #compute angular\n",
    "    num = np.trace(X.detach().numpy().T @ C_perm @ Y.detach().numpy() @ np.linalg.inv(C_perm))\n",
    "\n",
    "\n",
    "    denom = torch.norm(X,p = 'fro')*torch.norm(Y,p = 'fro')\n",
    "    denom=denom.detach().numpy()\n",
    "    angpermscore[perm] = np.cos(np.arccos(num/denom))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "mdic = {'optimizedC':[C_optimized],'optoloss':[Optimized_loss],'angularoptimal': [angoptimalscore],'loss_on_perm_random': [loss_on_perm],'C_on_perm' : [C_on_perm],'angperscore': [angpermscore]}\n",
    "savemat(DataFold+'/C_optimized_full_dmd_PMD.mat',mdic)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
