{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PacTimeOrig.DataHandling as DH\n",
    "import PacTimeOrig.Methods.utils as pacutils\n",
    "from PacTimeOrig.Methods.Clusteresque import recusiveCDF, EMDRecursive,getvarforclustering,loadEMDmatrices,EMDfast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "#set some analysis variables that'll stay fixed\n",
    "winlength=10\n",
    "n_sessions=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11593/11593 [00:00<00:00, 17656.06it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.16s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 17579.99it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.13s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 17458.70it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.13s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 17980.24it/s]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 18290.41it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.04s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 18196.24it/s]\n",
      "100%|██████████| 8/8 [00:25<00:00,  3.15s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 15346.21it/s]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.14s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 18415.19it/s]\n",
      "100%|██████████| 6/6 [00:18<00:00,  3.09s/it]\n",
      "100%|██████████| 11593/11593 [00:00<00:00, 18533.64it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load each pikcled datum and concatante the P1 trials\n",
    "datall=dict()\n",
    "for i in range(5):\n",
    "    session=i+1\n",
    "    file = open('C:\\\\Users\\\\Justin\\\\Documents\\\\GitHub\\\\PacManHuman\\\\Results\\\\datum'+str(session)+'.pkl', 'rb')\n",
    "    emdmatrices = pickle.load(file)\n",
    "    datall[str(session)]=emdmatrices\n",
    "\n",
    "# Then compute recursive Earth movers across all and store matrices for clustering.\n",
    "#Fewer bins\n",
    "histrange=dict()\n",
    "\n",
    "histrange['speed']=np.arange(0,1400+300,400) # 4bins\n",
    "histrange['speedgrad']=np.arange(-200,200+50,100) # 4bins\n",
    "histrange['accelmag']=np.arange(0,20000+5000,5000) # 4bins\n",
    "histrange['prey1reldistance']=np.arange(0,2000+400,400) # 5bins\n",
    "histrange['prey1reldistancegrad']=np.arange(-40,40+10,20) #4 bins\n",
    "histrange['prey1relangularhead']= np.arange(-180,180+45,45)\n",
    "histrange['prey1relangularheadgrad']= np.arange(-30,30+30,15)\n",
    "histrange['prey1_scalar_projection']=np.arange(-1500,1500+500,500)\n",
    "histrange['prey1_scalar_projection_gradient']=np.arange(-200,200+100,100)\n",
    "\n",
    "emdmats=dict()\n",
    "\n",
    "\n",
    "allvars=['speed','speedgrad','accelmag','prey1reldistance','prey1reldistancegrad','prey1relangularhead','prey1relangularheadgrad','prey1_scalar_projection','prey1_scalar_projection_gradient']\n",
    "\n",
    "\n",
    "#Compute recursive EMD for all above variables. It's fast afuck now\n",
    "for varname in allvars: #Loop over variables\n",
    "    dattmp=[] #list of dataframes\n",
    "    for i in range(n_sessions): #loop over sessions and retrieve data\n",
    "        session=i+1\n",
    "        dat=getvarforclustering(datall[str(session)]['p1trialdat'],varname,winlength)\n",
    "        dattmp.append([pd.DataFrame(dat)])\n",
    "\n",
    "    #Now combine all sessions\n",
    "    datcombo=pd.DataFrame()\n",
    "\n",
    "    for i in range(n_sessions):\n",
    "        datcombo=pd.concat((datcombo,dattmp[i][0]),axis=1)\n",
    "\n",
    "    #Now compute CDFs as prep for wasserstein distance\n",
    "    recdf = recusiveCDF(datcombo.to_numpy(),histrange,varname=varname)\n",
    "    #Now compute earthmovers distance\n",
    "    emdmat=EMDfast(recdf,normalize=False)\n",
    "    emdmatrices[varname]=emdmat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Do affinity clustering\n",
    "A=(emdmatrices['speed']*-1)/np.max(emdmatrices['speed'])\n",
    "B=(emdmatrices['speedgrad']*-1)/np.max(emdmatrices['speedgrad'])\n",
    "C=(emdmatrices['prey1_scalar_projection']*-1)/np.max(emdmatrices['prey1_scalar_projection'])\n",
    "D=(emdmatrices['prey1_scalar_projection_gradient']*-1)/np.max(emdmatrices['prey1_scalar_projection_gradient'])\n",
    "\n",
    "E=(emdmatrices['prey1relangularhead']*-1)/np.max(emdmatrices['prey1relangularhead'])\n",
    "\n",
    "F=(emdmatrices['prey1reldistancegrad']*-1)/np.max(emdmatrices['prey1reldistancegrad'])\n",
    "\n",
    "afmat=((A+B+C+D+F)/5)\n",
    "af = AffinityPropagation(random_state=0,affinity='precomputed',damping=0.95).fit(afmat*-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "#UMAP plot with cluster labels\n",
    "reducer = umap.UMAP(metric='precomputed',n_components=2,n_neighbors=25)\n",
    "embedding=reducer.fit_transform(afmat*-1)\n",
    "\n",
    "#OLD\n",
    "\n",
    "\n",
    "afmat=((A+B+C+D+E+F)/6)\n",
    "#afmat=((A+B+C+D+E)/5)\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(embedding[:,0],\n",
    "            embedding[:,1],\n",
    "            c=af.labels_,\n",
    "            s=0.1,\n",
    "            cmap='Spectral')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:33:33<00:00, 1403.28s/it]\n",
      "100%|██████████| 4/4 [1:15:57<00:00, 1139.43s/it]\n",
      "100%|██████████| 4/4 [1:18:54<00:00, 1183.53s/it]\n",
      "100%|██████████| 4/4 [1:20:25<00:00, 1206.35s/it]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ARI, Mutual informaiton, Silhouette score\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('C:\\\\Users\\\\Justin\\\\Documents\\\\GitHub\\\\PacManHuman\\\\Results\\\\affinityPropResultsMonkeyHWin10.pkl', 'rb')\n",
    "# dump information to that file\n",
    "data = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get data after clustering and group for mean, variance, and joint kernel density maps\n",
    "allvars=['speed','speedgrad','accelmag','prey1reldistance','prey1reldistancegrad','prey1relangularhead','prey1relangularheadgrad','prey1_scalar_projection','prey1_scalar_projection_gradient']\n",
    "datvar=dict()\n",
    "for varname in allvars:\n",
    "    dattmp=[] #list of dataframes\n",
    "    for i in range(n_sessions): #loop over sessions and retrieve data\n",
    "        session=i+1\n",
    "        dat=getvarforclustering(datall[str(session)]['p1trialdat'],varname,winlength)\n",
    "        dattmp.append([pd.DataFrame(dat)])\n",
    "\n",
    "    #Now combine all sessions\n",
    "    datcombo=pd.DataFrame()\n",
    "\n",
    "    for i in range(n_sessions):\n",
    "        datcombo=pd.concat((datcombo,dattmp[i][0]),axis=1)\n",
    "\n",
    "    datvar[varname]=datcombo\n",
    "\n",
    "\n",
    "\n",
    "A=pd.DataFrame(datvar['prey1_scalar_projection'].to_numpy()[:,np.where(af.labels_==1)[0]].transpose().flatten())\n",
    "B=pd.DataFrame(datvar['prey1_scalar_projection_gradient'].to_numpy()[:,np.where(af.labels_==1)[0]].transpose().flatten())\n",
    "\n",
    "B.rename(columns={0:1},inplace=True)\n",
    "sns.kdeplot(data=pd.concat((A,B),axis=1),x=0,y=1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#How to flatten out for plotting\n",
    "datvar['prey1_scalar_projection'].to_numpy()[:,np.where(af.labels_==0)[0]].transpose().flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Flat KDE plot\n",
    "#plots of traces that are like distributional (you know, the ones like multiple reaches with shading as farther from mean at each point)\n",
    "#Joint KDE plot"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
