{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GLM\n",
    "1. Do GLMs\n",
    "2. Cluster on WT\n",
    "3. Do generalization test of wt (separate GLMs) \n"
   ],
   "id": "bd8c7a1d8f35c9d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "from ChangeOfMind.functions import processing as proc\n",
    "from ChangeOfMind.Figures import Figure_Maker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.stats as stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import procrustes\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/AllData/workspace.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "\n",
    "\n",
    "metadata={}\n",
    "metadata['base_folder']='/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/NeuronGLM/'\n",
    "metadata['vars']={'x1':'speed','x2':'reldist','x3':'relspeed','x4':'reltime','x5':'wt'}\n",
    "metadata['zthresh']=2.57 #99% interval\n",
    "metadata['emu']={}\n",
    "metadata['nhp']={}\n",
    "\n",
    "\n",
    "#list usable sessions\n",
    "for subject in dat['psth_sess_emu'].keys():\n",
    "    metadata['emu'][subject]={}\n",
    "    metadata['emu'][subject]['session']=[1]\n",
    "    \n"
   ],
   "id": "c6e8ad6d06bd0da0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get mean tuning of neurons and tuning from GLM\n",
   "id": "6f866fe433c2b617"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Figure_Maker.Fig_2_neural_glm(params={'plottype':'getFR','cred_interval':'95','model_z_thresh':2.0,'full_model':False,'folder':'/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Fig/'})\n",
    "\n",
    "Figure_Maker.Fig_2_neural_glm(params={'plottype':'tuning','cred_interval':'95','model_z_thresh':2.0,'full_model':False,'folder':'/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Fig/'})"
   ],
   "id": "60cf5d4cb7594659"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualize Geometry comparison via tuning",
   "id": "d3e9c922ee966598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/tuning_mu.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "\n",
    "X=np.vstack(dat[(dat.variable=='wt') & (dat.area=='acc')].tuning_mu.values)\n",
    "Y=np.vstack(dat[(dat.variable=='wt') & (dat.area=='hpc')].tuning_mu.values)\n",
    "\n",
    "X=np.apply_along_axis(gaussian_filter1d,axis=1,arr=X,sigma=0.6)\n",
    "Y=np.apply_along_axis(gaussian_filter1d,axis=1,arr=X,sigma=0.6)\n",
    "                  \n",
    "\n",
    "X=X-np.mean(X,axis=1,keepdims=True)\n",
    "Y=Y-np.mean(Y,axis=1,keepdims=True)\n",
    "pca=PCA(n_components=8)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "pca_X=pca.fit_transform(X.transpose())\n",
    "pca_Y=pca.fit_transform(Y.transpose())\n",
    "ax.scatter(pca_X[:,0],pca_X[:,1],pca_X[:,2],c=np.linspace(0,10,10),cmap='viridis')\n",
    "ax.scatter(pca_Y[:,0],pca_Y[:,1],pca_Y[:,2],c=np.linspace(0,10,10),cmap='viridis',marker=\">\")\n",
    "ax.view_init(elev=45, azim=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mtx,mty,disparity=procrustes(pca_X,pca_Y)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(mtx[:,0],mtx[:,1],mtx[:,2],c=np.linspace(0,10,10),cmap='viridis')\n",
    "ax.scatter(mty[:,0],mty[:,1],mty[:,2],c=np.linspace(0,10,10),cmap='viridis',marker=\">\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.diagonal(cdist(X.transpose(),X.transpose()),offset=1))\n",
    "plt.plot(np.diagonal(cdist(Y.transpose(),Y.transpose()),offset=1))\n",
    "plt.title('fisher information')\n",
    "plt.show()\n",
    "#Do using GLMs\n",
    "var='wt'\n",
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/tuning_GLM.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "\n",
    "X=np.stack(dat['emu']['acc'][var])\n",
    "Y=np.stack(dat['emu']['hpc'][var])\n",
    "\n",
    "\n",
    "X=X-np.mean(X,axis=1,keepdims=True)\n",
    "Y=Y-np.mean(Y,axis=1,keepdims=True)\n",
    "pca=PCA(n_components=8)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "pca_X=pca.fit_transform(X.transpose())\n",
    "pca_Y=pca.fit_transform(Y.transpose())\n",
    "ax.scatter(pca_X[:,0],pca_X[:,1],pca_X[:,2],c=np.linspace(0,20,20),cmap='viridis')\n",
    "ax.scatter(pca_Y[:,0],pca_Y[:,1],pca_Y[:,2],c=np.linspace(0,20,20),cmap='viridis',marker=\">\")\n",
    "plt.show()\n",
    "\n",
    "mtx,mty,disparity=procrustes(pca_X,pca_Y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(mtx[:,0],mtx[:,1],mtx[:,2],c=np.linspace(0,20,20),cmap='viridis')\n",
    "ax.scatter(mty[:,0],mty[:,1],mty[:,2],c=np.linspace(0,20,20),cmap='viridis',marker=\">\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.diagonal(cdist(X.transpose(),X.transpose()),offset=1))\n",
    "plt.plot(np.diagonal(cdist(Y.transpose(),Y.transpose()),offset=1))\n",
    "plt.title('fisher information')\n",
    "plt.show()\n"
   ],
   "id": "272c04d4bb277a13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6190b048ee5910b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/AllData/workspace.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "bin_edges = np.linspace(0, 1, 10)  # Define common bin edges\n",
    "\n",
    "X_train={}\n",
    "Y_train={}\n",
    "wt_out={}\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    X_train[subj]=[]\n",
    "    Y_train[subj]=[]\n",
    "    wt_out[subj]={}\n",
    "    psth = dat['psth_sess_emu'][subj]\n",
    "    Xd = dat['Xd_sess_emu'][subj]\n",
    "    wt = dat['outputs_sess_emu'][subj]\n",
    "    X,Y = proc.split_for_dec(psth, Xd, wt, sess=1, split_on={'relspeed': [20,80]})\n",
    "    X_train[subj]=X\n",
    "    Y_train[subj]=Y\n",
    "    wt_out[subj][0]=X_train[subj][0][['wt']]\n",
    "    wt_out[subj][1]=X_train[subj][1][['wt']]\n",
    "\n",
    "    wt_out[subj][0]['wt']=wt_out[subj][0].wt.apply(lambda x: 1 if 0.45 <= x <= 0.5 else (-1 if -0.5 <= x <= -0.45 else 0))\n",
    "    wt_out[subj][1]['wt']=wt_out[subj][1].wt.apply(lambda x: 1 if 0.45 <= x <= 0.5 else (-1 if -0.5 <= x <= -0.45 else 0))\n",
    "\n",
    "counts=[]\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    counts.append(np.array([np.sum(wt_out[subj][0]['wt'] == 1),np.sum(wt_out[subj][0]['wt'] == -1)]))\n",
    "\n",
    "train_n=(np.min(np.stack(counts),axis=1).min()*0.8).astype(int)\n",
    "test_n=(np.min(np.stack(counts),axis=1).min()*0.2).astype(int)\n",
    "\n",
    "areaidx=[]\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    for neuron in Y_train[subj].keys():\n",
    "        #Get brain region to sort\n",
    "        if (np.where(np.char.find(dat['brain_region_emu'][subj][1][neuron], 'hpc') != -1))[0].shape[\n",
    "            0] == 1:\n",
    "            areaidx.append('hpc')\n",
    "        elif (np.where(np.char.find(dat['brain_region_emu'][subj][1][neuron], 'acc') != -1))[0].shape[\n",
    "            0] == 1:\n",
    "            areaidx.append('acc')\n",
    "        else:\n",
    "            areaidx.append('other')\n",
    "            \n",
    "areaidx=np.array(areaidx) \n",
    "        \n",
    "\n",
    "# Total decoding\n",
    "scores=[]\n",
    "acc_corr=[]\n",
    "hpc_corr=[]\n",
    "\n",
    "for sc in range(1000):\n",
    "    print(sc)\n",
    "    X_dec = []\n",
    "    A_dec_train = {'0':[],'1':[]}\n",
    "    A_dec_test = {'0':[],'1':[]}\n",
    "    B_dec_train = {'0':[],'1':[]}\n",
    "    B_dec_test = {'0':[],'1':[]}\n",
    "\n",
    "\n",
    "    for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "        #A_1\n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][0]['wt'] == 1)[0],train_n+test_n)\n",
    "        train_idx_a1 = xtmp_a[:train_n]\n",
    "        test_idx_a1 = xtmp_a[train_n:]\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][0]['wt'] == -1)[0],train_n+test_n)\n",
    "        train_idx_a2 = xtmp_b[:train_n]\n",
    "        test_idx_a2 = xtmp_b[train_n:]\n",
    "        \n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][1]['wt'] == 1)[0],train_n+test_n)\n",
    "        train_idx_b1 = xtmp_a[:train_n]\n",
    "        test_idx_b1 = xtmp_a[train_n:]\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][1]['wt'] == -1)[0],train_n+test_n)\n",
    "        train_idx_b2 = xtmp_b[:train_n]\n",
    "        test_idx_b2 = xtmp_b[train_n:]\n",
    "        \n",
    "        for i in Y_train[subj].keys():\n",
    "            A_dec_train['0'].append(Y_train[subj][i][0][train_idx_a1].flatten())\n",
    "            A_dec_train['1'].append(Y_train[subj][i][0][train_idx_a2].flatten())\n",
    "            B_dec_train['0'].append(Y_train[subj][i][1][train_idx_b1].flatten())\n",
    "            B_dec_train['1'].append(Y_train[subj][i][1][train_idx_b2].flatten())\n",
    "           \n",
    "    # Stack, area split, make subspace weights and correlate\n",
    "    sigmaA=np.diag(0.5*((np.var(np.stack(A_dec_train['0']),axis=1)+1e-10)+(np.var(np.stack(A_dec_train['1']),axis=1))+1e-10))\n",
    "    sigmaB=np.diag(0.5*((np.var(np.stack(B_dec_train['0']),axis=1)+1e-10)+(np.var(np.stack(B_dec_train['1']),axis=1))+1e-10))\n",
    "    muA=np.mean(A_dec_train['0'],axis=1)-np.mean(A_dec_train['1'],axis=1)\n",
    "    muB=np.mean(B_dec_train['0'],axis=1)-np.mean(B_dec_train['1'],axis=1)\n",
    "    wA=(np.linalg.inv(sigmaA) @ muA)\n",
    "    wB=(np.linalg.inv(sigmaB) @ muB)\n",
    "    wA=muA\n",
    "    wB=muB\n",
    "    \n",
    "    acc_corr.append(np.corrcoef(wA[np.where(areaidx=='acc')[0]],wB[np.where(areaidx=='acc')[0]])[0,1])\n",
    "    hpc_corr.append(np.corrcoef(wA[np.where(areaidx=='hpc')[0]],wB[np.where(areaidx=='hpc')[0]])[0,1])\n"
   ],
   "id": "a6ef4927d3ddcb4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cross-cond generalize",
   "id": "4eb44147581b7b3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/AllData/workspace.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "bin_edges = np.linspace(0, 1, 10)  # Define common bin edges\n",
    "\n",
    "X_train={}\n",
    "Y_train={}\n",
    "wt_out={}\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    X_train[subj]=[]\n",
    "    Y_train[subj]=[]\n",
    "    wt_out[subj]={}\n",
    "    psth = dat['psth_sess_emu'][subj]\n",
    "    Xd = dat['Xd_sess_emu'][subj]\n",
    "    wt = dat['outputs_sess_emu'][subj]\n",
    "    X,Y = proc.split_for_dec(psth, Xd, wt, sess=1, split_on={'relspeed': [20,80]})\n",
    "    X_train[subj]=X\n",
    "    Y_train[subj]=Y\n",
    "    wt_out[subj][0]=X_train[subj][0][['wt']]\n",
    "    wt_out[subj][1]=X_train[subj][1][['wt']]\n",
    "\n",
    "    wt_out[subj][0]['wt']=wt_out[subj][0].wt.apply(lambda x: 1 if 0.45 <= x <= 0.5 else (-1 if -0.5 <= x <= -0.45 else 0))\n",
    "    wt_out[subj][1]['wt']=wt_out[subj][1].wt.apply(lambda x: 1 if 0.45 <= x <= 0.5 else (-1 if -0.5 <= x <= -0.45 else 0))\n",
    "\n",
    "counts=[]\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    counts.append(np.array([np.sum(wt_out[subj][0]['wt'] == 1),np.sum(wt_out[subj][0]['wt'] == -1)]))\n",
    "\n",
    "train_n=(np.min(np.stack(counts),axis=1).min()*0.8).astype(int)\n",
    "test_n=(np.min(np.stack(counts),axis=1).min()*0.2).astype(int)\n",
    "\n",
    "areaidx=[]\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    for neuron in Y_train[subj].keys():\n",
    "        #Get brain region to sort\n",
    "        if (np.where(np.char.find(dat['brain_region_emu'][subj][1][neuron], 'hpc') != -1))[0].shape[\n",
    "            0] == 1:\n",
    "            areaidx.append('hpc')\n",
    "        elif (np.where(np.char.find(dat['brain_region_emu'][subj][1][neuron], 'acc') != -1))[0].shape[\n",
    "            0] == 1:\n",
    "            areaidx.append('acc')\n",
    "        else:\n",
    "            areaidx.append('other')\n",
    "            \n",
    "areaidx=np.array(areaidx) \n",
    "        \n",
    "\n",
    "# Total decoding\n",
    "scores=[]\n",
    "svc_acc=[]\n",
    "svc_hpc=[]\n",
    "mlp_acc=[]\n",
    "mlp_hpc=[]\n",
    "svc_acc_ccgp=[]\n",
    "svc_hpc_ccgp=[]\n",
    "for sc in range(500):\n",
    "    print(sc)\n",
    "    X_dec = []\n",
    "    X_dec_train = []\n",
    "    X_dec_test = []\n",
    "    X_ccgp_test=[]\n",
    "    \n",
    "    for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "        #A_1\n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][1]['wt'] == 1)[0],train_n+test_n)\n",
    "        train_idx_a = xtmp_a[:train_n]\n",
    "        test_idx_a = xtmp_a[train_n:]\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][1]['wt'] == -1)[0],train_n+test_n)\n",
    "        train_idx_b = xtmp_b[:train_n]\n",
    "        test_idx_b = xtmp_b[train_n:]\n",
    "        \n",
    "        \n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][0]['wt'] == 1)[0],train_n+test_n)\n",
    "        test_idx_a_ccgp = xtmp_a\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][0]['wt'] == -1)[0],train_n+test_n)\n",
    "        test_idx_b_ccgp = xtmp_b\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in Y_train[subj].keys():\n",
    "            X_dec_train.append(np.concatenate([Y_train[subj][i][1][train_idx_a].flatten(),\n",
    "                                               Y_train[subj][i][1][train_idx_b].flatten()]).reshape(-1,1))\n",
    "            \n",
    "            X_dec_test.append(np.concatenate([Y_train[subj][i][1][test_idx_a].flatten(),\n",
    "            Y_train[subj][i][1][test_idx_b].flatten()]).reshape(-1,1))\n",
    "            \n",
    "            X_ccgp_test.append(np.concatenate([Y_train[subj][i][0][test_idx_a_ccgp].flatten(),\n",
    "            Y_train[subj][i][0][test_idx_b_ccgp].flatten()]).reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    X_dec_train=np.hstack(X_dec_train)\n",
    "    xmu=X_dec_train.mean(axis=0)\n",
    "    \n",
    "    X_dec_test=np.hstack(X_dec_test)\n",
    "    X_dec_train=X_dec_train-xmu\n",
    "    X_dec_test=X_dec_test-xmu\n",
    "    \n",
    "    X_ccgp_test=np.hstack(X_ccgp_test)\n",
    "    X_ccgp_test=X_ccgp_test-np.mean(X_ccgp_test,axis=0)\n",
    "\n",
    "    Y_train_lda=np.concatenate([np.ones(train_n),np.zeros(train_n)])\n",
    "    Y_test_lda=np.concatenate([np.ones(test_n),np.zeros(test_n)])\n",
    "    \n",
    "    ylabccgp=int(X_ccgp_test.shape[0]/2)\n",
    "    Y_ccgp_lda=np.concatenate([np.ones(ylabccgp),np.zeros(ylabccgp)])\n",
    "    \n",
    "    svc = SVC(gamma='auto',kernel='rbf',C=3)\n",
    "    \n",
    "    svc.fit(X_dec_train[:,np.where(areaidx=='acc')[0]], Y_train_lda)\n",
    "    svc_acc.append(svc.score(X_dec_test[:,np.where(areaidx=='acc')[0]],Y_test_lda))\n",
    "    svc_acc_ccgp.append(svc.score(X_ccgp_test[:,np.where(areaidx=='acc')[0]],Y_ccgp_lda))\n",
    "    \n",
    "    \n",
    "    svc.fit(X_dec_train[:,np.where(areaidx=='hpc')[0]], Y_train_lda)\n",
    "    svc_hpc.append(svc.score(X_dec_test[:,np.where(areaidx=='hpc')[0]],Y_test_lda))\n",
    "    svc_hpc_ccgp.append(svc.score(X_ccgp_test[:,np.where(areaidx=='hpc')[0]],Y_ccgp_lda))\n",
    "    \n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_dec_train[:,np.where(areaidx=='acc')[0]], Y_train_lda)\n",
    "    mlp_acc.append(clf.score(X_dec_test[:,np.where(areaidx=='acc')[0]],Y_test_lda))\n",
    "    \n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_dec_train[:,np.where(areaidx=='hpc')[0]], Y_train_lda)\n",
    "    mlp_hpc.append(clf.score(X_dec_test[:,np.where(areaidx=='hpc')[0]],Y_test_lda))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "svc_acc_perm=[]\n",
    "svc_hpc_perm=[]\n",
    "mlp_acc_perm=[]\n",
    "mlp_hpc_perm=[]\n",
    "\n",
    "for sc in range(500):\n",
    "    print(sc)\n",
    "    X_dec = []\n",
    "    X_dec_train = []\n",
    "    X_dec_test = []\n",
    "    X_ccgp_test=[]\n",
    "    \n",
    "    for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "        #A_1\n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][1]['wt'] == 1)[0],train_n+test_n)\n",
    "        train_idx_a = xtmp_a[:train_n]\n",
    "        test_idx_a = xtmp_a[train_n:]\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][1]['wt'] == -1)[0],train_n+test_n)\n",
    "        train_idx_b = xtmp_b[:train_n]\n",
    "        test_idx_b = xtmp_b[train_n:]\n",
    "        \n",
    "        \n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][0]['wt'] == 1)[0],train_n+test_n)\n",
    "        test_idx_a_ccgp = xtmp_a\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][0]['wt'] == -1)[0],train_n+test_n)\n",
    "        test_idx_b_ccgp = xtmp_b\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in Y_train[subj].keys():\n",
    "            X_dec_train.append(np.concatenate([Y_train[subj][i][1][train_idx_a].flatten(),\n",
    "                                               Y_train[subj][i][1][train_idx_b].flatten()]).reshape(-1,1))\n",
    "            \n",
    "            X_dec_test.append(np.concatenate([Y_train[subj][i][1][test_idx_a].flatten(),\n",
    "            Y_train[subj][i][1][test_idx_b].flatten()]).reshape(-1,1))\n",
    "            \n",
    "            X_ccgp_test.append(np.concatenate([Y_train[subj][i][0][test_idx_a_ccgp].flatten(),\n",
    "            Y_train[subj][i][0][test_idx_b_ccgp].flatten()]).reshape(-1,1))\n",
    "    \n",
    "    X_dec_train = np.apply_along_axis(np.random.permutation, axis=0, arr=X_dec_train)\n",
    "\n",
    "    X_dec_train=np.hstack(X_dec_train)\n",
    "    xmu=X_dec_train.mean(axis=0)\n",
    "    \n",
    "    X_dec_test=np.hstack(X_dec_test)\n",
    "    X_dec_train=X_dec_train-xmu\n",
    "    X_dec_test=X_dec_test-xmu\n",
    "    \n",
    "    X_ccgp_test=np.hstack(X_ccgp_test)\n",
    "    X_ccgp_test=X_ccgp_test-np.mean(X_ccgp_test,axis=0)\n",
    "\n",
    "    Y_train_lda=np.concatenate([np.ones(train_n),np.zeros(train_n)])\n",
    "    Y_test_lda=np.concatenate([np.ones(test_n),np.zeros(test_n)])\n",
    "    \n",
    "    ylabccgp=int(X_ccgp_test.shape[0]/2)\n",
    "    Y_ccgp_lda=np.concatenate([np.ones(ylabccgp),np.zeros(ylabccgp)])\n",
    "    \n",
    "    svc = SVC(gamma='auto',kernel='rbf',C=3)\n",
    "    \n",
    "    svc.fit(X_dec_train[:,np.where(areaidx=='acc')[0]], Y_train_lda)\n",
    "    svc_acc_perm.append(svc.score(X_dec_test[:,np.where(areaidx=='acc')[0]],Y_test_lda))\n",
    "    \n",
    "    svc.fit(X_dec_train[:,np.where(areaidx=='hpc')[0]], Y_train_lda)\n",
    "    svc_hpc_perm.append(svc.score(X_dec_test[:,np.where(areaidx=='hpc')[0]],Y_test_lda))\n",
    "    \n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_dec_train[:,np.where(areaidx=='acc')[0]], Y_train_lda)\n",
    "    mlp_acc_perm.append(clf.score(X_dec_test[:,np.where(areaidx=='acc')[0]],Y_test_lda))\n",
    "    \n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_dec_train[:,np.where(areaidx=='hpc')[0]], Y_train_lda)\n",
    "    mlp_hpc_perm.append(clf.score(X_dec_test[:,np.where(areaidx=='hpc')[0]],Y_test_lda))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ],
   "id": "2feaf181f5f79f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/AllData/workspace.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "bin_edges = np.linspace(0, 1, 10)  # Define common bin edges\n",
    "\n",
    "X_train={}\n",
    "Y_train={}\n",
    "wt_out={}\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    X_train[subj]=[]\n",
    "    Y_train[subj]=[]\n",
    "    wt_out[subj]={}\n",
    "    psth = dat['psth_sess_emu'][subj]\n",
    "    Xd = dat['Xd_sess_emu'][subj]\n",
    "    wt = dat['outputs_sess_emu'][subj]\n",
    "    Y = np.concatenate(psth[1])\n",
    "\n",
    "    X_train[subj]=X\n",
    "    Y_train[subj]=Y\n",
    "    wt_out[subj][0]=X_train[subj][0][['wt']]\n",
    "    wt_out[subj][1]=X_train[subj][1][['wt']]\n",
    "\n",
    "    wt_out[subj][0]['wt']=wt_out[subj][0].wt.apply(lambda x: 1 if 0.45 <= x <= 0.5 else (-1 if -0.5 <= x <= -0.45 else 0))\n",
    "    wt_out[subj][1]['wt']=wt_out[subj][1].wt.apply(lambda x: 1 if 0.45 <= x <= 0.5 else (-1 if -0.5 <= x <= -0.45 else 0))\n",
    "\n",
    "counts=[]\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    counts.append(np.array([np.sum(wt_out[subj][0]['wt'] == 1),np.sum(wt_out[subj][0]['wt'] == -1)]))\n",
    "\n",
    "train_n=(np.min(np.stack(counts),axis=1).min()*0.8).astype(int)\n",
    "test_n=(np.min(np.stack(counts),axis=1).min()*0.2).astype(int)\n",
    "\n",
    "areaidx=[]\n",
    "for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "    for neuron in Y_train[subj].keys():\n",
    "        #Get brain region to sort\n",
    "        if (np.where(np.char.find(dat['brain_region_emu'][subj][1][neuron], 'hpc') != -1))[0].shape[\n",
    "            0] == 1:\n",
    "            areaidx.append('hpc')\n",
    "        elif (np.where(np.char.find(dat['brain_region_emu'][subj][1][neuron], 'acc') != -1))[0].shape[\n",
    "            0] == 1:\n",
    "            areaidx.append('acc')\n",
    "        else:\n",
    "            areaidx.append('other')\n",
    "            \n",
    "areaidx=np.array(areaidx) \n",
    "        \n",
    "\n",
    "# Total decoding\n",
    "scores=[]\n",
    "svc_acc=[]\n",
    "svc_hpc=[]\n",
    "mlp_acc=[]\n",
    "mlp_hpc=[]\n",
    "svc_acc_ccgp=[]\n",
    "svc_hpc_ccgp=[]\n",
    "for sc in range(500):\n",
    "    print(sc)\n",
    "    X_dec = []\n",
    "    X_dec_train = []\n",
    "    X_dec_test = []\n",
    "    X_ccgp_test=[]\n",
    "    \n",
    "    for _, subj in enumerate(dat['psth_sess_emu'].keys()):\n",
    "        #A_1\n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][1]['wt'] == 1)[0],train_n+test_n)\n",
    "        train_idx_a = xtmp_a[:train_n]\n",
    "        test_idx_a = xtmp_a[train_n:]\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][1]['wt'] == -1)[0],train_n+test_n)\n",
    "        train_idx_b = xtmp_b[:train_n]\n",
    "        test_idx_b = xtmp_b[train_n:]\n",
    "        \n",
    "        \n",
    "        xtmp_a = np.random.choice(np.where(wt_out[subj][0]['wt'] == 1)[0],train_n+test_n)\n",
    "        test_idx_a_ccgp = xtmp_a\n",
    "        xtmp_b = np.random.choice(np.where(wt_out[subj][0]['wt'] == -1)[0],train_n+test_n)\n",
    "        test_idx_b_ccgp = xtmp_b\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in Y_train[subj].keys():\n",
    "            X_dec_train.append(np.concatenate([Y_train[subj][i][1][train_idx_a].flatten(),\n",
    "                                               Y_train[subj][i][1][train_idx_b].flatten()]).reshape(-1,1))\n",
    "            \n",
    "            X_dec_test.append(np.concatenate([Y_train[subj][i][1][test_idx_a].flatten(),\n",
    "            Y_train[subj][i][1][test_idx_b].flatten()]).reshape(-1,1))\n",
    "            \n",
    "            X_ccgp_test.append(np.concatenate([Y_train[subj][i][0][test_idx_a_ccgp].flatten(),\n",
    "            Y_train[subj][i][0][test_idx_b_ccgp].flatten()]).reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    X_dec_train=np.hstack(X_dec_train)\n",
    "    xmu=X_dec_train.mean(axis=0)\n",
    "    \n",
    "    X_dec_test=np.hstack(X_dec_test)\n",
    "    X_dec_train=X_dec_train-xmu\n",
    "    X_dec_test=X_dec_test-xmu\n",
    "    \n",
    "    X_ccgp_test=np.hstack(X_ccgp_test)\n",
    "    X_ccgp_test=X_ccgp_test-np.mean(X_ccgp_test,axis=0)\n",
    "\n",
    "    Y_train_lda=np.concatenate([np.ones(train_n),np.zeros(train_n)])\n",
    "    Y_test_lda=np.concatenate([np.ones(test_n),np.zeros(test_n)])\n",
    "    \n",
    "    ylabccgp=int(X_ccgp_test.shape[0]/2)\n",
    "    Y_ccgp_lda=np.concatenate([np.ones(ylabccgp),np.zeros(ylabccgp)])\n",
    "    \n",
    "    svc = SVC(gamma='auto',kernel='rbf',C=3)\n",
    "    \n",
    "    svc.fit(X_dec_train[:,np.where(areaidx=='acc')[0]], Y_train_lda)\n",
    "    svc_acc.append(svc.score(X_dec_test[:,np.where(areaidx=='acc')[0]],Y_test_lda))\n",
    "    svc_acc_ccgp.append(svc.score(X_ccgp_test[:,np.where(areaidx=='acc')[0]],Y_ccgp_lda))\n",
    "    \n",
    "    \n",
    "    svc.fit(X_dec_train[:,np.where(areaidx=='hpc')[0]], Y_train_lda)\n",
    "    svc_hpc.append(svc.score(X_dec_test[:,np.where(areaidx=='hpc')[0]],Y_test_lda))\n",
    "    svc_hpc_ccgp.append(svc.score(X_ccgp_test[:,np.where(areaidx=='hpc')[0]],Y_ccgp_lda))\n",
    "    \n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_dec_train[:,np.where(areaidx=='acc')[0]], Y_train_lda)\n",
    "    mlp_acc.append(clf.score(X_dec_test[:,np.where(areaidx=='acc')[0]],Y_test_lda))\n",
    "    \n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_dec_train[:,np.where(areaidx=='hpc')[0]], Y_train_lda)\n",
    "    mlp_hpc.append(clf.score(X_dec_test[:,np.where(areaidx=='hpc')[0]],Y_test_lda))\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "cc1f10fb832ad039"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
