{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PacTimeOrig.controllers import simulator as sim\n",
    "from PacTimeOrig.controllers import JaxMod as jm\n",
    "from PacTimeOrig.controllers import models as mods\n",
    "\n",
    "from PacTimeOrig.controllers import utils as ut\n",
    "from PacTimeOrig.data import scripts\n",
    "from PacTimeOrig.controllers.Scripts import SimulationScript as simrun\n",
    "\n",
    "\n",
    "cfgparams={'area':'dACC'}\n",
    "cfgparams['session']=1\n",
    "cfgparams['subj']='H'\n",
    "cfgparams['rbfs']=[15,20,28]\n",
    "cfgparams['models']=['p','pv','pf','pvi','pif','pvf']\n",
    "cfgparams['gpscaler']=[1,3,8]\n",
    "cfgparams['restarts']=3\n",
    "cfgparams['slack']=False\n",
    "cfgparams['trials']=10 #TODO use this to select N integer trials\n",
    "cfgparams['ngains']=[1,2,2,3,3,3] #TODO: Use this to generate gains for simulation\n",
    "cfgparams['opttype']=['first','second']# Adam and Lbfgs\n",
    "cfgparams['opttype']=['first']# Adam and Lbfgs\n",
    "\n",
    "cfgparams['confusiontest']=True# Adam and Lbfgs\n",
    "\n",
    "simrun.simulate_mp(cfgparams)\n",
    "simrun.simulate(cfgparams)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simulate N trials, N-RBFs, N-optimizations, N-runs per, N swtiching types, N random gains, Model type\n",
   "id": "c0aae719c6e97b99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "DiffE+ Adam",
   "id": "a7577bd6d03da3df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Set diff e loss\n",
    "loss_function = mods.create_loss_function_pvi(ut.generate_rbf_basis)\n",
    "\n",
    "#Set grad  loss\n",
    "grad_loss = ut.compute_loss_gradient(loss_function)\n",
    "\n",
    "#Runn diffEV\n",
    "(L1_opt, L2_opt), best_params, best_loss = mods.outer_optimization_pvi(inputs, mods.inner_optimization_pvi, loss_function, grad_loss,maxiter=1,tolerance=1e-3,opttype='global')\n",
    "\n",
    "#initialize parameters for ADAM\n",
    "params=(jnp.array(best_params[0]),jnp.array(best_params[1]),jnp.array(L1_opt),jnp.array(L2_opt))\n",
    "\n",
    "#setup ADam optimizer\n",
    "# Set up the optimizer\n",
    "optimizer, opt_state = jm.setup_optimizer(params, learning_rate=1e-2,slack_model=False,optimizer='amsgrad')\n",
    "\n",
    "# Number of optimization steps\n",
    "num_steps = 15000\n",
    "\n",
    "loss_function = jm.create_loss_function_pvi(ut.generate_rbf_basis,inputs['num_rbfs'],ut.generate_smoothing_penalty,lambda_reg=0.00002)\n",
    "\n",
    "grad_loss = ut.compute_loss_gradient(loss_function)\n",
    "\n",
    "\n",
    "\n",
    "# Optimization loop\n",
    "for step in range(num_steps):\n",
    "    params, opt_state, loss = jm.optimization_step(params, opt_state, optimizer, loss_function, inputs,ctrltype='pvi',slack_model=False)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss}\")\n",
    "        "
   ],
   "id": "dfb144462e8ec207"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Jax - trust region ",
   "id": "5a460f6522714f31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loss_function = jm.create_loss_function_pvi_lbfgs(ut.generate_rbf_basis,num_rbfs)\n",
    "grad_loss = ut.compute_loss_gradient(loss_function)\n",
    "hess_loss = ut.compute_hessian(loss_function)\n",
    "\n",
    "\n",
    "pp,best_params_flat, best_loss = jm.outer_optimization_lbfgs(inputs, loss_function, grad_loss, hess_loss,randomize_weights=False,ctrltype='pvi',maxiter=3000,tolerance=1e-3,optimizer='trust',slack_model=False)\n",
    "\n",
    "L1_fit=pp[0]\n",
    "L2_fit=pp[1]\n",
    "\n",
    "weights = pp[2]\n",
    "widths = pp[3]\n",
    "wtout=ut.generate_sim_switch(inputs, widths, weights)\n",
    "\n",
    "shift=np.vstack((wtout[0],wtout[1]))\n",
    "\n",
    "pred_out=sim.controller_sim_pvi_post(shift,outputs['x'][:,:2],outputs['x'][:,2:],tdat['pry1_pos'],tdat['pry1_vel'],tdat['pry2_pos'],tdat['pry2_vel'],L1_fit,L2_fit,A=None,B=None)\n",
    "\n",
    "plt.plot(tmp,outputs['x'][:,:2],linewidth=4)\n",
    "plt.plot(tmp,pred_out['x'][:,:2],'--',linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(tmp,outputs['shift'].transpose(),linewidth=4)\n",
    "plt.plot(tmp,shift.transpose(),'--',linewidth=4)\n",
    "plt.show()"
   ],
   "id": "7569be77fdf5b07c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c5c6588107a61471"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adam Only",
   "id": "397f17cde58abdf4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loss_function = jm.create_loss_function_pvi(ut.generate_rbf_basis,inputs['num_rbfs'],ut.generate_smoothing_penalty,lambda_reg=0.00002)\n",
    "\n",
    "grad_loss = ut.compute_loss_gradient(loss_function)\n",
    "\n",
    "params=jm.initialize_parameters(inputs, ctrltype='pvi', slack_model=False)\n",
    "\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer, opt_state = jm.setup_optimizer(params, learning_rate=1e-2,slack_model=False,optimizer='amsgrad')\n",
    "\n",
    "# Number of optimization steps\n",
    "num_steps = 30000\n",
    "\n",
    "# Optimization loop\n",
    "for step in range(num_steps):\n",
    "    params, opt_state, loss = jm.optimization_step(params, opt_state, optimizer, loss_function, inputs,ctrltype='pvi',slack_model=False)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "#transform paramteres to correct domain\n",
    "L1_fit=jnp.log(1+jnp.exp(params[2]))\n",
    "L2_fit=jnp.log(1+jnp.exp(params[3]))\n",
    "\n",
    "weights = params[0]\n",
    "widths = params[1]\n",
    "wtout=ut.generate_sim_switch(inputs, widths, weights,slack_model=False)\n",
    "\n",
    "shift=np.vstack((wtout[0],wtout[1]))\n",
    "\n",
    "pred_out=sim.controller_sim_pvi_post(shift,outputs['x'][:,:2],outputs['x'][:,2:],tdat['pry1_pos'],tdat['pry1_vel'],tdat['pry2_pos'],tdat['pry2_vel'],L1_fit,L2_fit,A=None,B=None)\n",
    "\n",
    "plt.plot(tmp,outputs['x'][:,:2],linewidth=4)\n",
    "plt.plot(tmp,pred_out['x'][:,:2],'--',linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(tmp,outputs['shift'].transpose(),linewidth=4)\n",
    "plt.plot(tmp,shift.transpose(),'--',linewidth=4)\n",
    "plt.show()"
   ],
   "id": "4c2295cb543e5ed4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
